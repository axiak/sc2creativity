{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import sys\n",
    "import bisect\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [15, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import umap.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_start</th>\n",
       "      <th>game_duration</th>\n",
       "      <th>self_won</th>\n",
       "      <th>self_name</th>\n",
       "      <th>self_race_is_protoss</th>\n",
       "      <th>self_race_is_zerg</th>\n",
       "      <th>self_race_is_terran</th>\n",
       "      <th>opponent_name</th>\n",
       "      <th>opponent_race_is_protoss</th>\n",
       "      <th>opponent_race_is_zerg</th>\n",
       "      <th>...</th>\n",
       "      <th>ZergMeleeWeaponsLevel2_start</th>\n",
       "      <th>ZergMeleeWeaponsLevel2_weight</th>\n",
       "      <th>ZergMissileWeaponsLevel1_start</th>\n",
       "      <th>ZergMissileWeaponsLevel1_weight</th>\n",
       "      <th>ZergMissileWeaponsLevel2_start</th>\n",
       "      <th>ZergMissileWeaponsLevel2_weight</th>\n",
       "      <th>Zergling_start</th>\n",
       "      <th>Zergling_weight</th>\n",
       "      <th>overlordspeed_start</th>\n",
       "      <th>overlordspeed_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>045eeb4f0df4c471d53c4f1db5eea0294279e0d69fad7af2c2624e914806a2ba_1</th>\n",
       "      <td>2020-02-02 14:59:40</td>\n",
       "      <td>318</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ragnarok</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DPGCure</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.301775</td>\n",
       "      <td>2.234511</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e5628efc602591574bb20c3bb83ee50cfc8705d3b6ea244aee60613b5a124fbc_0</th>\n",
       "      <td>2020-02-02 11:28:58</td>\n",
       "      <td>442</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ragnarok</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TSGSolar</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.498681</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.780220</td>\n",
       "      <td>7.266902</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e5628efc602591574bb20c3bb83ee50cfc8705d3b6ea244aee60613b5a124fbc_1</th>\n",
       "      <td>2020-02-02 11:28:58</td>\n",
       "      <td>442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TSGSolar</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Ragnarok</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.342629</td>\n",
       "      <td>9.691492</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6637fd076f528b86d4_0</th>\n",
       "      <td>2020-02-02 11:58:49</td>\n",
       "      <td>450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TSGSolar</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Ragnarok</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.484407</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.176471</td>\n",
       "      <td>3.198894</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6637fd076f528b86d4_1</th>\n",
       "      <td>2020-02-02 11:58:49</td>\n",
       "      <td>450</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ragnarok</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TSGSolar</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.708779</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.090452</td>\n",
       "      <td>9.517000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            game_start  \\\n",
       "045eeb4f0df4c471d53c4f1db5eea0294279e0d69fad7af... 2020-02-02 14:59:40   \n",
       "e5628efc602591574bb20c3bb83ee50cfc8705d3b6ea244... 2020-02-02 11:28:58   \n",
       "e5628efc602591574bb20c3bb83ee50cfc8705d3b6ea244... 2020-02-02 11:28:58   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6... 2020-02-02 11:58:49   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6... 2020-02-02 11:58:49   \n",
       "\n",
       "                                                    game_duration  self_won  \\\n",
       "045eeb4f0df4c471d53c4f1db5eea0294279e0d69fad7af...            318       1.0   \n",
       "e5628efc602591574bb20c3bb83ee50cfc8705d3b6ea244...            442       1.0   \n",
       "e5628efc602591574bb20c3bb83ee50cfc8705d3b6ea244...            442       0.0   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...            450       0.0   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...            450       1.0   \n",
       "\n",
       "                                                   self_name  \\\n",
       "045eeb4f0df4c471d53c4f1db5eea0294279e0d69fad7af...  Ragnarok   \n",
       "e5628efc602591574bb20c3bb83ee50cfc8705d3b6ea244...  Ragnarok   \n",
       "e5628efc602591574bb20c3bb83ee50cfc8705d3b6ea244...  TSGSolar   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...  TSGSolar   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...  Ragnarok   \n",
       "\n",
       "                                                    self_race_is_protoss  \\\n",
       "045eeb4f0df4c471d53c4f1db5eea0294279e0d69fad7af...                   0.0   \n",
       "e5628efc602591574bb20c3bb83ee50cfc8705d3b6ea244...                   0.0   \n",
       "e5628efc602591574bb20c3bb83ee50cfc8705d3b6ea244...                   0.0   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                   0.0   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                   0.0   \n",
       "\n",
       "                                                    self_race_is_zerg  \\\n",
       "045eeb4f0df4c471d53c4f1db5eea0294279e0d69fad7af...                1.0   \n",
       "e5628efc602591574bb20c3bb83ee50cfc8705d3b6ea244...                1.0   \n",
       "e5628efc602591574bb20c3bb83ee50cfc8705d3b6ea244...                1.0   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                1.0   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                1.0   \n",
       "\n",
       "                                                    self_race_is_terran  \\\n",
       "045eeb4f0df4c471d53c4f1db5eea0294279e0d69fad7af...                  0.0   \n",
       "e5628efc602591574bb20c3bb83ee50cfc8705d3b6ea244...                  0.0   \n",
       "e5628efc602591574bb20c3bb83ee50cfc8705d3b6ea244...                  0.0   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                  0.0   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                  0.0   \n",
       "\n",
       "                                                   opponent_name  \\\n",
       "045eeb4f0df4c471d53c4f1db5eea0294279e0d69fad7af...       DPGCure   \n",
       "e5628efc602591574bb20c3bb83ee50cfc8705d3b6ea244...      TSGSolar   \n",
       "e5628efc602591574bb20c3bb83ee50cfc8705d3b6ea244...      Ragnarok   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...      Ragnarok   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...      TSGSolar   \n",
       "\n",
       "                                                    opponent_race_is_protoss  \\\n",
       "045eeb4f0df4c471d53c4f1db5eea0294279e0d69fad7af...                       0.0   \n",
       "e5628efc602591574bb20c3bb83ee50cfc8705d3b6ea244...                       0.0   \n",
       "e5628efc602591574bb20c3bb83ee50cfc8705d3b6ea244...                       0.0   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                       0.0   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                       0.0   \n",
       "\n",
       "                                                    opponent_race_is_zerg  \\\n",
       "045eeb4f0df4c471d53c4f1db5eea0294279e0d69fad7af...                    0.0   \n",
       "e5628efc602591574bb20c3bb83ee50cfc8705d3b6ea244...                    1.0   \n",
       "e5628efc602591574bb20c3bb83ee50cfc8705d3b6ea244...                    1.0   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                    1.0   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                    1.0   \n",
       "\n",
       "                                                    ...  \\\n",
       "045eeb4f0df4c471d53c4f1db5eea0294279e0d69fad7af...  ...   \n",
       "e5628efc602591574bb20c3bb83ee50cfc8705d3b6ea244...  ...   \n",
       "e5628efc602591574bb20c3bb83ee50cfc8705d3b6ea244...  ...   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...  ...   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...  ...   \n",
       "\n",
       "                                                    ZergMeleeWeaponsLevel2_start  \\\n",
       "045eeb4f0df4c471d53c4f1db5eea0294279e0d69fad7af...                           1.0   \n",
       "e5628efc602591574bb20c3bb83ee50cfc8705d3b6ea244...                           1.0   \n",
       "e5628efc602591574bb20c3bb83ee50cfc8705d3b6ea244...                           1.0   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                           1.0   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                           1.0   \n",
       "\n",
       "                                                    ZergMeleeWeaponsLevel2_weight  \\\n",
       "045eeb4f0df4c471d53c4f1db5eea0294279e0d69fad7af...                            0.0   \n",
       "e5628efc602591574bb20c3bb83ee50cfc8705d3b6ea244...                            0.0   \n",
       "e5628efc602591574bb20c3bb83ee50cfc8705d3b6ea244...                            0.0   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                            0.0   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                            0.0   \n",
       "\n",
       "                                                    ZergMissileWeaponsLevel1_start  \\\n",
       "045eeb4f0df4c471d53c4f1db5eea0294279e0d69fad7af...                        1.000000   \n",
       "e5628efc602591574bb20c3bb83ee50cfc8705d3b6ea244...                        9.498681   \n",
       "e5628efc602591574bb20c3bb83ee50cfc8705d3b6ea244...                        1.000000   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                        7.484407   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                        7.708779   \n",
       "\n",
       "                                                    ZergMissileWeaponsLevel1_weight  \\\n",
       "045eeb4f0df4c471d53c4f1db5eea0294279e0d69fad7af...                              0.0   \n",
       "e5628efc602591574bb20c3bb83ee50cfc8705d3b6ea244...                              1.0   \n",
       "e5628efc602591574bb20c3bb83ee50cfc8705d3b6ea244...                              0.0   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                              1.0   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                              1.0   \n",
       "\n",
       "                                                    ZergMissileWeaponsLevel2_start  \\\n",
       "045eeb4f0df4c471d53c4f1db5eea0294279e0d69fad7af...                             1.0   \n",
       "e5628efc602591574bb20c3bb83ee50cfc8705d3b6ea244...                             1.0   \n",
       "e5628efc602591574bb20c3bb83ee50cfc8705d3b6ea244...                             1.0   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                             1.0   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                             1.0   \n",
       "\n",
       "                                                    ZergMissileWeaponsLevel2_weight  \\\n",
       "045eeb4f0df4c471d53c4f1db5eea0294279e0d69fad7af...                              0.0   \n",
       "e5628efc602591574bb20c3bb83ee50cfc8705d3b6ea244...                              0.0   \n",
       "e5628efc602591574bb20c3bb83ee50cfc8705d3b6ea244...                              0.0   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                              0.0   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                              0.0   \n",
       "\n",
       "                                                    Zergling_start  \\\n",
       "045eeb4f0df4c471d53c4f1db5eea0294279e0d69fad7af...       21.301775   \n",
       "e5628efc602591574bb20c3bb83ee50cfc8705d3b6ea244...       19.780220   \n",
       "e5628efc602591574bb20c3bb83ee50cfc8705d3b6ea244...       14.342629   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...       21.176471   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...       18.090452   \n",
       "\n",
       "                                                    Zergling_weight  \\\n",
       "045eeb4f0df4c471d53c4f1db5eea0294279e0d69fad7af...         2.234511   \n",
       "e5628efc602591574bb20c3bb83ee50cfc8705d3b6ea244...         7.266902   \n",
       "e5628efc602591574bb20c3bb83ee50cfc8705d3b6ea244...         9.691492   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...         3.198894   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...         9.517000   \n",
       "\n",
       "                                                    overlordspeed_start  \\\n",
       "045eeb4f0df4c471d53c4f1db5eea0294279e0d69fad7af...                  1.0   \n",
       "e5628efc602591574bb20c3bb83ee50cfc8705d3b6ea244...                  1.0   \n",
       "e5628efc602591574bb20c3bb83ee50cfc8705d3b6ea244...                  1.0   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                  1.0   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                  1.0   \n",
       "\n",
       "                                                    overlordspeed_weight  \n",
       "045eeb4f0df4c471d53c4f1db5eea0294279e0d69fad7af...                   0.0  \n",
       "e5628efc602591574bb20c3bb83ee50cfc8705d3b6ea244...                   0.0  \n",
       "e5628efc602591574bb20c3bb83ee50cfc8705d3b6ea244...                   0.0  \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                   0.0  \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                   0.0  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df = pd.read_hdf(\"../data/processed/summaries_zerg.hdf\", \"summaries\")\n",
    "raw_df = raw_df[raw_df.game_duration > 280]\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_columns = \"\"\"\n",
    "self_won\n",
    "game_start\n",
    "game_duration\n",
    "self_name self_race_is_protoss self_race_is_zerg self_race_is_terran\n",
    "opponent_name\n",
    "\"\"\".split()\n",
    "weight_columns = [col for col in raw_df.columns if col.endswith(\"_weight\")]\n",
    "\n",
    "data_columns = [col for col in raw_df.columns if col not in metadata_columns and col not in weight_columns]\n",
    "\n",
    "df = raw_df[data_columns]\n",
    "\n",
    "encoding_dim = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.sort_values('DarkTemplar_start').tail(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = Input(shape=(len(df.columns),))\n",
    "\n",
    "encoded = Dense(64, activation='relu')(input_data)\n",
    "encoded = Dense(24, activation='relu')(input_data)\n",
    "#encoded = Dense(24, activation='relu')(input_data)\n",
    "\n",
    "encoded = Dense(encoding_dim, activation='relu',\n",
    "                    activity_regularizer=regularizers.l1(10e-3))(encoded)\n",
    "\n",
    "\n",
    "#decoded = Dense(24, activation='relu')(encoded)\n",
    "decoded = Dense(24, activation='relu')(encoded)\n",
    "decoded = Dense(64, activation='relu')(decoded)\n",
    "decoded = Dense(len(df.columns), activation='linear')(decoded)\n",
    "\n",
    "autoencoder = Model(input_data, decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(input_data, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 2800 samples. Testing on 312.\n"
     ]
    }
   ],
   "source": [
    "x_all = df.sample(frac=1.0).values\n",
    "num_samples = int(0.9 * x_all.shape[0])\n",
    "x_train, x_test = x_all[:num_samples, :], x_all[num_samples:, :]\n",
    "print(\"Training on {} samples. Testing on {}.\".format(\n",
    "    num_samples, x_all.shape[0] - num_samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2800 samples, validate on 312 samples\n",
      "Epoch 1/2500\n",
      "2800/2800 [==============================] - 0s 54us/step - loss: 12931889.4971 - val_loss: 12653872.0000\n",
      "Epoch 2/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 12160153.5600 - val_loss: 10358260.0000\n",
      "Epoch 3/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 7133958.4600 - val_loss: 3434517.0000\n",
      "Epoch 4/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 2391666.8779 - val_loss: 1584914.0000\n",
      "Epoch 5/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 1238225.7550 - val_loss: 1651390.7500\n",
      "Epoch 6/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 1029065.0836 - val_loss: 435327.6875\n",
      "Epoch 7/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 425262.0659 - val_loss: 507501.0625\n",
      "Epoch 8/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 591944.1329 - val_loss: 266185.0312\n",
      "Epoch 9/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 317972.7491 - val_loss: 245542.4531\n",
      "Epoch 10/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 227510.1137 - val_loss: 140939.0156\n",
      "Epoch 11/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 128253.3309 - val_loss: 135439.7188\n",
      "Epoch 12/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 132862.8591 - val_loss: 87445.2031\n",
      "Epoch 13/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 88348.3035 - val_loss: 50366.1797\n",
      "Epoch 14/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 56085.7249 - val_loss: 38366.8867\n",
      "Epoch 15/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 44128.2315 - val_loss: 32650.3711\n",
      "Epoch 16/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 39604.0719 - val_loss: 31178.8594\n",
      "Epoch 17/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 37365.8352 - val_loss: 33198.3047\n",
      "Epoch 18/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 40806.5090 - val_loss: 29267.7500\n",
      "Epoch 19/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35896.6541 - val_loss: 27252.8398\n",
      "Epoch 20/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35427.1418 - val_loss: 24853.7656\n",
      "Epoch 21/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32395.7798 - val_loss: 24806.2500\n",
      "Epoch 22/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 33823.6064 - val_loss: 23941.7637\n",
      "Epoch 23/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 31362.2830 - val_loss: 27762.1680\n",
      "Epoch 24/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39757.2676 - val_loss: 24980.5449\n",
      "Epoch 25/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34805.1962 - val_loss: 28577.6016\n",
      "Epoch 26/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40262.7852 - val_loss: 30718.8203\n",
      "Epoch 27/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 41965.1945 - val_loss: 26286.9297\n",
      "Epoch 28/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36985.1066 - val_loss: 33904.6953\n",
      "Epoch 29/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 43975.4704 - val_loss: 28433.9160\n",
      "Epoch 30/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37034.5273 - val_loss: 29720.7070\n",
      "Epoch 31/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37941.6323 - val_loss: 34177.3984\n",
      "Epoch 32/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 45557.9251 - val_loss: 26234.7578\n",
      "Epoch 33/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35244.7355 - val_loss: 27886.2031\n",
      "Epoch 34/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 35996.6522 - val_loss: 31425.8594\n",
      "Epoch 35/2500\n",
      "2800/2800 [==============================] - 0s 10us/step - loss: 40054.3440 - val_loss: 28625.3828\n",
      "Epoch 36/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 37624.6505 - val_loss: 33663.6719\n",
      "Epoch 37/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 44788.5773 - val_loss: 33312.7148\n",
      "Epoch 38/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 44609.0422 - val_loss: 28426.6816\n",
      "Epoch 39/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 42615.5757 - val_loss: 24357.7148\n",
      "Epoch 40/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 35297.7663 - val_loss: 26150.3477\n",
      "Epoch 41/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38428.6589 - val_loss: 29440.8672\n",
      "Epoch 42/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 40170.1416 - val_loss: 37874.9688\n",
      "Epoch 43/2500\n",
      "2800/2800 [==============================] - 0s 11us/step - loss: 49046.1983 - val_loss: 42037.1680\n",
      "Epoch 44/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 53307.8844 - val_loss: 34157.1641\n",
      "Epoch 45/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 46052.3556 - val_loss: 35591.6445\n",
      "Epoch 46/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 49139.2813 - val_loss: 32715.2695\n",
      "Epoch 47/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 44124.7835 - val_loss: 29887.6562\n",
      "Epoch 48/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 39583.1958 - val_loss: 33359.2500\n",
      "Epoch 49/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42879.7467 - val_loss: 41166.9961\n",
      "Epoch 50/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 49911.0314 - val_loss: 39799.7656\n",
      "Epoch 51/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 48688.9064 - val_loss: 40135.0977\n",
      "Epoch 52/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 50735.0547 - val_loss: 38294.0586\n",
      "Epoch 53/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 47459.3136 - val_loss: 39374.8945\n",
      "Epoch 54/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 48078.0852 - val_loss: 41574.4062\n",
      "Epoch 55/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 55642.1445 - val_loss: 35243.3281\n",
      "Epoch 56/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 46624.3060 - val_loss: 43841.9609\n",
      "Epoch 57/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 52880.2019 - val_loss: 49436.2422\n",
      "Epoch 58/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 60242.0152 - val_loss: 41785.5586\n",
      "Epoch 59/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 51153.2968 - val_loss: 37652.2891\n",
      "Epoch 60/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 51559.5263 - val_loss: 38101.0117\n",
      "Epoch 61/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 48114.1317 - val_loss: 41343.6328\n",
      "Epoch 62/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 54630.0453 - val_loss: 30332.8750\n",
      "Epoch 63/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 38837.2082 - val_loss: 37500.6250\n",
      "Epoch 64/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 48647.6249 - val_loss: 37887.2773\n",
      "Epoch 65/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 51196.4346 - val_loss: 39276.8203\n",
      "Epoch 66/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 50364.6530 - val_loss: 31547.5840\n",
      "Epoch 67/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 39580.8135 - val_loss: 40750.9297\n",
      "Epoch 68/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 52048.3973 - val_loss: 46499.3516\n",
      "Epoch 69/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 57099.6795 - val_loss: 33756.2109\n",
      "Epoch 70/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 45896.7621 - val_loss: 39646.6484\n",
      "Epoch 71/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 51729.6617 - val_loss: 41030.4766\n",
      "Epoch 72/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 49328.0683 - val_loss: 46394.5469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 55492.5602 - val_loss: 41825.1562\n",
      "Epoch 74/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 50354.8836 - val_loss: 32622.9102\n",
      "Epoch 75/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 45673.1603 - val_loss: 39621.2070\n",
      "Epoch 76/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 50791.3674 - val_loss: 50049.3320\n",
      "Epoch 77/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 55717.1566 - val_loss: 64605.6367\n",
      "Epoch 78/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 74792.6049 - val_loss: 37678.0664\n",
      "Epoch 79/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 49404.2507 - val_loss: 40510.7031\n",
      "Epoch 80/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 54422.7636 - val_loss: 39392.0938\n",
      "Epoch 81/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 53021.3464 - val_loss: 45746.2734\n",
      "Epoch 82/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 58550.1223 - val_loss: 41759.7305\n",
      "Epoch 83/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 53388.8790 - val_loss: 35631.4492\n",
      "Epoch 84/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 43529.2537 - val_loss: 47324.5312\n",
      "Epoch 85/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 55578.7635 - val_loss: 59698.5625\n",
      "Epoch 86/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 65819.2066 - val_loss: 58959.5781\n",
      "Epoch 87/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 58139.4420 - val_loss: 68815.4766\n",
      "Epoch 88/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 84693.4296 - val_loss: 38523.7891\n",
      "Epoch 89/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 48281.8313 - val_loss: 39527.6016\n",
      "Epoch 90/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 45883.4857 - val_loss: 51728.4570\n",
      "Epoch 91/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 61778.8855 - val_loss: 49646.9688\n",
      "Epoch 92/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 62263.4704 - val_loss: 49477.6445\n",
      "Epoch 93/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 54884.2733 - val_loss: 61167.9609\n",
      "Epoch 94/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 65864.3478 - val_loss: 58165.1016\n",
      "Epoch 95/2500\n",
      "2800/2800 [==============================] - 0s 10us/step - loss: 67472.1575 - val_loss: 40252.5117\n",
      "Epoch 96/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 49210.2270 - val_loss: 50032.5781\n",
      "Epoch 97/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 59177.1217 - val_loss: 55523.0742\n",
      "Epoch 98/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 61780.3259 - val_loss: 62479.4375\n",
      "Epoch 99/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 74082.1421 - val_loss: 46868.6094\n",
      "Epoch 100/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 56097.4816 - val_loss: 45020.4258\n",
      "Epoch 101/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 54552.8017 - val_loss: 47685.2383\n",
      "Epoch 102/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 53977.7812 - val_loss: 47725.6328\n",
      "Epoch 103/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 67315.9056 - val_loss: 35462.0430\n",
      "Epoch 104/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 48664.1334 - val_loss: 41195.6406\n",
      "Epoch 105/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 51205.6672 - val_loss: 43928.8359\n",
      "Epoch 106/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 57031.7820 - val_loss: 45930.2656\n",
      "Epoch 107/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 58707.3259 - val_loss: 61169.6953\n",
      "Epoch 108/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 76316.2577 - val_loss: 47465.3672\n",
      "Epoch 109/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 53608.2404 - val_loss: 52009.0859\n",
      "Epoch 110/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 64851.1883 - val_loss: 51056.7500\n",
      "Epoch 111/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 61312.6941 - val_loss: 47749.9844\n",
      "Epoch 112/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 56161.3550 - val_loss: 53684.7422\n",
      "Epoch 113/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 60876.0846 - val_loss: 47723.0469\n",
      "Epoch 114/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 60246.4216 - val_loss: 53744.4844\n",
      "Epoch 115/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 69871.0148 - val_loss: 49393.2812\n",
      "Epoch 116/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 57546.1411 - val_loss: 53042.5703\n",
      "Epoch 117/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 58379.7251 - val_loss: 61552.0000\n",
      "Epoch 118/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 57468.6523 - val_loss: 70104.6484\n",
      "Epoch 119/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 78939.0072 - val_loss: 40664.0508\n",
      "Epoch 120/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 54543.2389 - val_loss: 35272.8320\n",
      "Epoch 121/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 43409.8741 - val_loss: 35943.3789\n",
      "Epoch 122/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 44472.2486 - val_loss: 47130.4219\n",
      "Epoch 123/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 54747.0646 - val_loss: 55416.8750\n",
      "Epoch 124/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 56648.2372 - val_loss: 59440.8203\n",
      "Epoch 125/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 65494.4229 - val_loss: 48211.5977\n",
      "Epoch 126/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 57359.1557 - val_loss: 47586.3125\n",
      "Epoch 127/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 51286.3929 - val_loss: 52758.7070\n",
      "Epoch 128/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 60028.5265 - val_loss: 44745.8750\n",
      "Epoch 129/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 55329.0737 - val_loss: 39806.3438\n",
      "Epoch 130/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 49056.9389 - val_loss: 48151.1328\n",
      "Epoch 131/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 52984.1919 - val_loss: 54948.0391\n",
      "Epoch 132/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 70902.7062 - val_loss: 42835.1406\n",
      "Epoch 133/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 55449.8415 - val_loss: 44301.6445\n",
      "Epoch 134/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 59039.1203 - val_loss: 41530.7656\n",
      "Epoch 135/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 52013.6938 - val_loss: 48306.9375\n",
      "Epoch 136/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 58284.2427 - val_loss: 50868.0703\n",
      "Epoch 137/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 51798.2515 - val_loss: 62644.6250\n",
      "Epoch 138/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 70411.7128 - val_loss: 54786.3828\n",
      "Epoch 139/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 73333.1651 - val_loss: 39334.2227\n",
      "Epoch 140/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 46235.3299 - val_loss: 43680.0156\n",
      "Epoch 141/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 51164.4365 - val_loss: 54479.3477\n",
      "Epoch 142/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 60968.8835 - val_loss: 51459.6016\n",
      "Epoch 143/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 67728.3893 - val_loss: 47614.9844\n",
      "Epoch 144/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 50719.1146 - val_loss: 48012.5742\n",
      "Epoch 145/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800/2800 [==============================] - 0s 6us/step - loss: 63874.6710 - val_loss: 41428.9297\n",
      "Epoch 146/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 45516.9208 - val_loss: 43836.7266\n",
      "Epoch 147/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 62238.2094 - val_loss: 34014.2031\n",
      "Epoch 148/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 48880.3599 - val_loss: 42544.7812\n",
      "Epoch 149/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 53228.1029 - val_loss: 44081.2773\n",
      "Epoch 150/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 55177.2874 - val_loss: 51424.7891\n",
      "Epoch 151/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 61270.2344 - val_loss: 55438.7891\n",
      "Epoch 152/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 73592.5544 - val_loss: 42249.0039\n",
      "Epoch 153/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 52786.8285 - val_loss: 44749.0703\n",
      "Epoch 154/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 58055.8562 - val_loss: 44689.6523\n",
      "Epoch 155/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 59949.1576 - val_loss: 52719.8359\n",
      "Epoch 156/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 61259.2449 - val_loss: 59250.0742\n",
      "Epoch 157/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 59091.1812 - val_loss: 66418.1328\n",
      "Epoch 158/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 80646.7076 - val_loss: 44788.9102\n",
      "Epoch 159/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 52153.9333 - val_loss: 43786.1641\n",
      "Epoch 160/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 51400.0830 - val_loss: 54139.3320\n",
      "Epoch 161/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 73387.5738 - val_loss: 41099.7188\n",
      "Epoch 162/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 51668.1974 - val_loss: 42807.8047\n",
      "Epoch 163/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 52326.8949 - val_loss: 50228.4492\n",
      "Epoch 164/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 58332.8181 - val_loss: 61131.0938\n",
      "Epoch 165/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 70967.8085 - val_loss: 43004.4531\n",
      "Epoch 166/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 57903.6763 - val_loss: 47565.1250\n",
      "Epoch 167/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 68317.9968 - val_loss: 34116.6094\n",
      "Epoch 168/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 44125.4659 - val_loss: 42447.8359\n",
      "Epoch 169/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 56687.0282 - val_loss: 33655.6367\n",
      "Epoch 170/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42613.6755 - val_loss: 38256.5898\n",
      "Epoch 171/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 50598.8616 - val_loss: 49243.6641\n",
      "Epoch 172/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 65204.1490 - val_loss: 48705.1016\n",
      "Epoch 173/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 61063.2669 - val_loss: 50418.6602\n",
      "Epoch 174/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 65759.5344 - val_loss: 42353.5039\n",
      "Epoch 175/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 55122.0832 - val_loss: 40169.2773\n",
      "Epoch 176/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 52613.6373 - val_loss: 45205.0938\n",
      "Epoch 177/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 54086.6579 - val_loss: 50187.2617\n",
      "Epoch 178/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 60746.5078 - val_loss: 51746.4453\n",
      "Epoch 179/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 59567.6233 - val_loss: 57317.7461\n",
      "Epoch 180/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 63000.7627 - val_loss: 63428.9805\n",
      "Epoch 181/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 72706.4558 - val_loss: 53601.6758\n",
      "Epoch 182/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 63466.5713 - val_loss: 43187.7852\n",
      "Epoch 183/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 54749.8917 - val_loss: 41634.7188\n",
      "Epoch 184/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 51547.1202 - val_loss: 44050.4375\n",
      "Epoch 185/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 49268.5760 - val_loss: 55971.8633\n",
      "Epoch 186/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 66743.9531 - val_loss: 54278.3750\n",
      "Epoch 187/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 66899.2969 - val_loss: 43316.2852\n",
      "Epoch 188/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 58221.2143 - val_loss: 34230.2500\n",
      "Epoch 189/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 43758.4105 - val_loss: 46548.5586\n",
      "Epoch 190/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 51756.8072 - val_loss: 44713.3242\n",
      "Epoch 191/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 52841.5013 - val_loss: 43410.8477\n",
      "Epoch 192/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 57700.2222 - val_loss: 45637.0430\n",
      "Epoch 193/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 54731.9016 - val_loss: 47275.5000\n",
      "Epoch 194/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 59288.6206 - val_loss: 38320.1211\n",
      "Epoch 195/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 52361.0646 - val_loss: 41019.7070\n",
      "Epoch 196/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 52930.5331 - val_loss: 50530.3594\n",
      "Epoch 197/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 63042.1372 - val_loss: 55567.8398\n",
      "Epoch 198/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 62528.2258 - val_loss: 65679.3594\n",
      "Epoch 199/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 68116.6648 - val_loss: 50432.1680\n",
      "Epoch 200/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 61876.9998 - val_loss: 34722.3164\n",
      "Epoch 201/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 42712.1921 - val_loss: 40304.5742\n",
      "Epoch 202/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 49972.4893 - val_loss: 56879.3438\n",
      "Epoch 203/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 71391.4037 - val_loss: 48757.4219\n",
      "Epoch 204/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 63699.0808 - val_loss: 43927.7422\n",
      "Epoch 205/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 61526.1336 - val_loss: 35119.4180\n",
      "Epoch 206/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42938.5268 - val_loss: 41868.8320\n",
      "Epoch 207/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 53552.2603 - val_loss: 35427.2812\n",
      "Epoch 208/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 54557.4288 - val_loss: 31840.9395\n",
      "Epoch 209/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 46478.2953 - val_loss: 34736.2461\n",
      "Epoch 210/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 51343.1862 - val_loss: 41287.6211\n",
      "Epoch 211/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 51771.4646 - val_loss: 59786.0391\n",
      "Epoch 212/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 69083.2610 - val_loss: 60424.9414\n",
      "Epoch 213/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 70696.5906 - val_loss: 52304.1094\n",
      "Epoch 214/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 70594.3745 - val_loss: 31585.3535\n",
      "Epoch 215/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 44068.3012 - val_loss: 41020.5273\n",
      "Epoch 216/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 53446.7081 - val_loss: 52020.5078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 59209.0167 - val_loss: 57063.0312\n",
      "Epoch 218/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 62020.5179 - val_loss: 54888.3398\n",
      "Epoch 219/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 68024.9596 - val_loss: 47062.8516\n",
      "Epoch 220/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 58498.9370 - val_loss: 40306.0469\n",
      "Epoch 221/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 49728.1466 - val_loss: 45188.4766\n",
      "Epoch 222/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 48892.0461 - val_loss: 58122.9375\n",
      "Epoch 223/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 69497.9800 - val_loss: 49971.6055\n",
      "Epoch 224/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 60375.7763 - val_loss: 47160.3359\n",
      "Epoch 225/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 58104.8925 - val_loss: 42434.4023\n",
      "Epoch 226/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 57380.9416 - val_loss: 37353.8867\n",
      "Epoch 227/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 44771.9158 - val_loss: 50736.0000\n",
      "Epoch 228/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 63994.6295 - val_loss: 46099.2148\n",
      "Epoch 229/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 57383.9170 - val_loss: 40709.5195\n",
      "Epoch 230/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 53798.3152 - val_loss: 35228.0859\n",
      "Epoch 231/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 44752.5147 - val_loss: 44349.1172\n",
      "Epoch 232/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 50087.3196 - val_loss: 57314.9453\n",
      "Epoch 233/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 57603.3160 - val_loss: 51453.7617\n",
      "Epoch 234/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 70256.8876 - val_loss: 37412.3477\n",
      "Epoch 235/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 49219.5054 - val_loss: 36390.9805\n",
      "Epoch 236/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 46068.2418 - val_loss: 39275.5234\n",
      "Epoch 237/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 50461.1245 - val_loss: 41581.4258\n",
      "Epoch 238/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 53544.3446 - val_loss: 53156.3867\n",
      "Epoch 239/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 63046.7651 - val_loss: 47685.2891\n",
      "Epoch 240/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 58158.8701 - val_loss: 54524.9023\n",
      "Epoch 241/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 56827.6855 - val_loss: 47198.3867\n",
      "Epoch 242/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 60540.6596 - val_loss: 49198.9102\n",
      "Epoch 243/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 55097.0121 - val_loss: 60291.9609\n",
      "Epoch 244/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 62967.8110 - val_loss: 63077.4805\n",
      "Epoch 245/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 67620.2816 - val_loss: 58950.2891\n",
      "Epoch 246/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 71511.5839 - val_loss: 60712.3281\n",
      "Epoch 247/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 68478.8764 - val_loss: 48703.1016\n",
      "Epoch 248/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 59882.8673 - val_loss: 55081.0938\n",
      "Epoch 249/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 65787.5181 - val_loss: 54344.0625\n",
      "Epoch 250/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 61552.7075 - val_loss: 64192.9375\n",
      "Epoch 251/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 70705.5293 - val_loss: 57214.6055\n",
      "Epoch 252/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 73858.9503 - val_loss: 34960.9375\n",
      "Epoch 253/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 48541.5362 - val_loss: 38479.3750\n",
      "Epoch 254/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 47490.9500 - val_loss: 43508.0312\n",
      "Epoch 255/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 57171.9332 - val_loss: 46944.0898\n",
      "Epoch 256/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 62772.0851 - val_loss: 38561.3398\n",
      "Epoch 257/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 46813.1300 - val_loss: 50061.7070\n",
      "Epoch 258/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 64801.8264 - val_loss: 52774.9141\n",
      "Epoch 259/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 68988.6533 - val_loss: 36688.1641\n",
      "Epoch 260/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 48889.1709 - val_loss: 41878.1992\n",
      "Epoch 261/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 52424.6269 - val_loss: 47157.8320\n",
      "Epoch 262/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 54241.7006 - val_loss: 47764.8203\n",
      "Epoch 263/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 63010.7491 - val_loss: 35059.5391\n",
      "Epoch 264/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 47684.7976 - val_loss: 44979.5117\n",
      "Epoch 265/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 62688.5725 - val_loss: 33461.9375\n",
      "Epoch 266/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 46541.3869 - val_loss: 47869.8125\n",
      "Epoch 267/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 53739.7863 - val_loss: 51827.8906\n",
      "Epoch 268/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 61779.9617 - val_loss: 54256.8984\n",
      "Epoch 269/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 62786.6933 - val_loss: 46960.4531\n",
      "Epoch 270/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 54068.7625 - val_loss: 40763.4258\n",
      "Epoch 271/2500\n",
      "2800/2800 [==============================] - ETA: 0s - loss: 46013.648 - 0s 7us/step - loss: 46821.6036 - val_loss: 46414.3594\n",
      "Epoch 272/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 53373.8009 - val_loss: 49998.5000\n",
      "Epoch 273/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 57006.5900 - val_loss: 49793.4141\n",
      "Epoch 274/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 62409.0392 - val_loss: 34033.6133\n",
      "Epoch 275/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39537.4339 - val_loss: 53109.1992\n",
      "Epoch 276/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 56144.7727 - val_loss: 47981.3711\n",
      "Epoch 277/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 51180.8175 - val_loss: 41347.7852\n",
      "Epoch 278/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 47115.2793 - val_loss: 45799.1094\n",
      "Epoch 279/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 54473.5956 - val_loss: 45267.1016\n",
      "Epoch 280/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 53401.4345 - val_loss: 43658.6758\n",
      "Epoch 281/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 53729.2211 - val_loss: 45804.0312\n",
      "Epoch 282/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 55216.6692 - val_loss: 47427.1172\n",
      "Epoch 283/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 56054.1977 - val_loss: 39873.3203\n",
      "Epoch 284/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 44859.3370 - val_loss: 48236.7422\n",
      "Epoch 285/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 60454.0384 - val_loss: 48122.2109\n",
      "Epoch 286/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 54322.0553 - val_loss: 61331.2500\n",
      "Epoch 287/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 68590.3668 - val_loss: 55329.5547\n",
      "Epoch 288/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800/2800 [==============================] - 0s 7us/step - loss: 62309.6748 - val_loss: 54236.0352\n",
      "Epoch 289/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 65359.0002 - val_loss: 51981.2188\n",
      "Epoch 290/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 59223.9571 - val_loss: 39280.7422\n",
      "Epoch 291/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 45626.6517 - val_loss: 44088.7812\n",
      "Epoch 292/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 50702.0492 - val_loss: 55774.2852\n",
      "Epoch 293/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 59871.6042 - val_loss: 51547.8203\n",
      "Epoch 294/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 60513.0559 - val_loss: 39713.7266\n",
      "Epoch 295/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 48606.2229 - val_loss: 36488.9805\n",
      "Epoch 296/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 44384.9698 - val_loss: 49293.9727\n",
      "Epoch 297/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 52247.1023 - val_loss: 53431.6211\n",
      "Epoch 298/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 61608.7008 - val_loss: 58095.3086\n",
      "Epoch 299/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 64531.7899 - val_loss: 45824.2500\n",
      "Epoch 300/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 51443.2866 - val_loss: 43891.8672\n",
      "Epoch 301/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 51111.7451 - val_loss: 55717.3672\n",
      "Epoch 302/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 68297.6717 - val_loss: 38765.9766\n",
      "Epoch 303/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 39884.9409 - val_loss: 45013.3789\n",
      "Epoch 304/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 52153.9868 - val_loss: 40913.2266\n",
      "Epoch 305/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 48017.8205 - val_loss: 49893.1484\n",
      "Epoch 306/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 56134.7822 - val_loss: 55329.9570\n",
      "Epoch 307/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 61894.9105 - val_loss: 41353.0312\n",
      "Epoch 308/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 49222.4223 - val_loss: 49135.9258\n",
      "Epoch 309/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 59488.5181 - val_loss: 41491.7812\n",
      "Epoch 310/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 52538.1708 - val_loss: 39984.9219\n",
      "Epoch 311/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 50898.6910 - val_loss: 47002.9180\n",
      "Epoch 312/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 55720.0025 - val_loss: 42757.2695\n",
      "Epoch 313/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 52218.6325 - val_loss: 48785.9219\n",
      "Epoch 314/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 58201.6183 - val_loss: 55735.6562\n",
      "Epoch 315/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 64932.1584 - val_loss: 43953.9570\n",
      "Epoch 316/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 50511.5720 - val_loss: 58157.9297\n",
      "Epoch 317/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 63701.0581 - val_loss: 59173.4375\n",
      "Epoch 318/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 70824.2787 - val_loss: 45139.8438\n",
      "Epoch 319/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 55858.1706 - val_loss: 46629.1953\n",
      "Epoch 320/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 50887.1914 - val_loss: 47477.8164\n",
      "Epoch 321/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 56660.2911 - val_loss: 47065.5195\n",
      "Epoch 322/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 62085.0418 - val_loss: 41831.6328\n",
      "Epoch 323/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 50518.3416 - val_loss: 40874.8828\n",
      "Epoch 324/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 46735.6454 - val_loss: 41779.0703\n",
      "Epoch 325/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 47060.3555 - val_loss: 51524.5547\n",
      "Epoch 326/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 56450.2387 - val_loss: 41300.2969\n",
      "Epoch 327/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 50474.6085 - val_loss: 44171.9297\n",
      "Epoch 328/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 49136.2448 - val_loss: 57445.7812\n",
      "Epoch 329/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 57797.4577 - val_loss: 41178.4453\n",
      "Epoch 330/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 46713.1838 - val_loss: 47124.1172\n",
      "Epoch 331/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 54944.8625 - val_loss: 45554.4062\n",
      "Epoch 332/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 54156.5823 - val_loss: 41140.5000\n",
      "Epoch 333/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 50185.3434 - val_loss: 39831.7148\n",
      "Epoch 334/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 46078.1717 - val_loss: 40834.3906\n",
      "Epoch 335/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 51715.2949 - val_loss: 32258.6367\n",
      "Epoch 336/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 43667.2960 - val_loss: 35883.5430\n",
      "Epoch 337/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 47220.4219 - val_loss: 32404.0078\n",
      "Epoch 338/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 44245.5562 - val_loss: 38276.0898\n",
      "Epoch 339/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 50090.6480 - val_loss: 39945.0469\n",
      "Epoch 340/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 53033.4252 - val_loss: 34686.3359\n",
      "Epoch 341/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 43626.8168 - val_loss: 49997.9492\n",
      "Epoch 342/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 57890.4038 - val_loss: 41675.3477\n",
      "Epoch 343/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 55314.8090 - val_loss: 37527.7344\n",
      "Epoch 344/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 47094.0953 - val_loss: 53494.7734\n",
      "Epoch 345/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 63533.0523 - val_loss: 47086.9922\n",
      "Epoch 346/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 55289.3728 - val_loss: 36074.5391\n",
      "Epoch 347/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 45184.3790 - val_loss: 40527.5352\n",
      "Epoch 348/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 48857.6146 - val_loss: 36203.4883\n",
      "Epoch 349/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 46987.5688 - val_loss: 34433.9805\n",
      "Epoch 350/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40410.1423 - val_loss: 43516.0703\n",
      "Epoch 351/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 50474.3416 - val_loss: 36492.7109\n",
      "Epoch 352/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 44313.4235 - val_loss: 40109.7617\n",
      "Epoch 353/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 46936.6649 - val_loss: 45095.1836\n",
      "Epoch 354/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 47602.2736 - val_loss: 55486.5664\n",
      "Epoch 355/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 55995.0500 - val_loss: 59542.6133\n",
      "Epoch 356/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 64119.5910 - val_loss: 54685.6016\n",
      "Epoch 357/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 61283.3469 - val_loss: 43773.7266\n",
      "Epoch 358/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 51616.1683 - val_loss: 38863.8828\n",
      "Epoch 359/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 48972.3756 - val_loss: 42803.1133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 360/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 49780.0106 - val_loss: 47751.6562\n",
      "Epoch 361/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 54490.5709 - val_loss: 37156.1953\n",
      "Epoch 362/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 52083.5446 - val_loss: 31356.2988\n",
      "Epoch 363/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37879.8011 - val_loss: 41549.3203\n",
      "Epoch 364/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 53715.1775 - val_loss: 27737.9922\n",
      "Epoch 365/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 36105.9098 - val_loss: 24915.5977\n",
      "Epoch 366/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32363.3072 - val_loss: 25360.3281\n",
      "Epoch 367/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 32288.2102 - val_loss: 32038.2305\n",
      "Epoch 368/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 42478.6769 - val_loss: 26410.1367\n",
      "Epoch 369/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32054.6112 - val_loss: 33930.7812\n",
      "Epoch 370/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36757.4288 - val_loss: 36340.0742\n",
      "Epoch 371/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41946.7998 - val_loss: 37686.4844\n",
      "Epoch 372/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 48456.4133 - val_loss: 27502.2891\n",
      "Epoch 373/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 36187.3466 - val_loss: 31843.3242\n",
      "Epoch 374/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 41562.9132 - val_loss: 31689.7637\n",
      "Epoch 375/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 34628.5374 - val_loss: 42617.5938\n",
      "Epoch 376/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 46629.5403 - val_loss: 40460.8438\n",
      "Epoch 377/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 47735.9092 - val_loss: 38992.0977\n",
      "Epoch 378/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 46853.2279 - val_loss: 34832.8711\n",
      "Epoch 379/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 42927.2596 - val_loss: 31209.7188\n",
      "Epoch 380/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40418.3627 - val_loss: 34754.5391\n",
      "Epoch 381/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 51470.3648 - val_loss: 28785.6035\n",
      "Epoch 382/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 37184.0163 - val_loss: 25818.9688\n",
      "Epoch 383/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34158.0566 - val_loss: 28641.5039\n",
      "Epoch 384/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38441.4908 - val_loss: 28236.1250\n",
      "Epoch 385/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 36767.4114 - val_loss: 36543.7188\n",
      "Epoch 386/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41540.2883 - val_loss: 49053.4062\n",
      "Epoch 387/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 53522.1054 - val_loss: 40893.4062\n",
      "Epoch 388/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 50389.6824 - val_loss: 39132.1172\n",
      "Epoch 389/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 47399.4875 - val_loss: 50067.3242\n",
      "Epoch 390/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 55841.9159 - val_loss: 49923.9531\n",
      "Epoch 391/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 57165.2467 - val_loss: 43960.3008\n",
      "Epoch 392/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 50831.1343 - val_loss: 48904.1641\n",
      "Epoch 393/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 53355.6537 - val_loss: 49200.5508\n",
      "Epoch 394/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 51789.1775 - val_loss: 50111.3984\n",
      "Epoch 395/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 59031.3520 - val_loss: 45619.6484\n",
      "Epoch 396/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 50398.7107 - val_loss: 44560.3398\n",
      "Epoch 397/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 45465.6333 - val_loss: 49512.8281\n",
      "Epoch 398/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 59487.4886 - val_loss: 36130.0117\n",
      "Epoch 399/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 46183.5535 - val_loss: 29662.8477\n",
      "Epoch 400/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 38379.0607 - val_loss: 38459.8828\n",
      "Epoch 401/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 45788.9239 - val_loss: 51699.9922\n",
      "Epoch 402/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 59772.3529 - val_loss: 39681.1172\n",
      "Epoch 403/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 47191.6674 - val_loss: 42053.3984\n",
      "Epoch 404/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 49435.5552 - val_loss: 48634.4414\n",
      "Epoch 405/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 58771.8413 - val_loss: 37992.4531\n",
      "Epoch 406/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 50752.0058 - val_loss: 36053.4453\n",
      "Epoch 407/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37415.7265 - val_loss: 63722.2109\n",
      "Epoch 408/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 60008.0211 - val_loss: 32439.8262\n",
      "Epoch 409/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39624.1135 - val_loss: 40891.1094\n",
      "Epoch 410/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 46983.2854 - val_loss: 37490.1875\n",
      "Epoch 411/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 39402.7500 - val_loss: 45819.3672\n",
      "Epoch 412/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 58119.3116 - val_loss: 31736.0762\n",
      "Epoch 413/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 40684.1786 - val_loss: 34428.5469\n",
      "Epoch 414/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 43616.1041 - val_loss: 38765.5547\n",
      "Epoch 415/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 44246.6910 - val_loss: 36188.0000\n",
      "Epoch 416/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 46067.7204 - val_loss: 34958.5859\n",
      "Epoch 417/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 46107.0271 - val_loss: 36402.0547\n",
      "Epoch 418/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 44289.7712 - val_loss: 37309.8594\n",
      "Epoch 419/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 44945.9748 - val_loss: 43185.3086\n",
      "Epoch 420/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 46159.7883 - val_loss: 47354.4727\n",
      "Epoch 421/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 56784.7908 - val_loss: 41589.7422\n",
      "Epoch 422/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 50472.4855 - val_loss: 48783.5703\n",
      "Epoch 423/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 58941.5222 - val_loss: 45635.5312\n",
      "Epoch 424/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 48189.3989 - val_loss: 44115.3555\n",
      "Epoch 425/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 46929.6802 - val_loss: 53974.9609\n",
      "Epoch 426/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 62248.3270 - val_loss: 30978.5508\n",
      "Epoch 427/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41356.5192 - val_loss: 38941.5234\n",
      "Epoch 428/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42817.0387 - val_loss: 46165.8867\n",
      "Epoch 429/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 49992.1724 - val_loss: 48974.7969\n",
      "Epoch 430/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 58354.3337 - val_loss: 46018.8711\n",
      "Epoch 431/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 54840.2831 - val_loss: 53645.4922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 432/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 56666.9880 - val_loss: 56049.2344\n",
      "Epoch 433/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 57444.2609 - val_loss: 63571.5625\n",
      "Epoch 434/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 59367.3424 - val_loss: 64136.0391\n",
      "Epoch 435/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 69505.7205 - val_loss: 54727.4141\n",
      "Epoch 436/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 60922.9932 - val_loss: 46359.4688\n",
      "Epoch 437/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 51102.5346 - val_loss: 36871.1445\n",
      "Epoch 438/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 34193.1303 - val_loss: 52895.2227\n",
      "Epoch 439/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 68624.0279 - val_loss: 34123.2422\n",
      "Epoch 440/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 38455.8566 - val_loss: 37775.1445\n",
      "Epoch 441/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 46567.8363 - val_loss: 37914.7539\n",
      "Epoch 442/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42196.6614 - val_loss: 37225.7266\n",
      "Epoch 443/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 44605.4125 - val_loss: 40333.3750\n",
      "Epoch 444/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 42806.7381 - val_loss: 47388.8594\n",
      "Epoch 445/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 49341.9292 - val_loss: 43190.2422\n",
      "Epoch 446/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 51517.6325 - val_loss: 30418.5117\n",
      "Epoch 447/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37475.1467 - val_loss: 39648.4570\n",
      "Epoch 448/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 49530.4789 - val_loss: 38982.2734\n",
      "Epoch 449/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 49230.0417 - val_loss: 28859.9395\n",
      "Epoch 450/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 36557.1131 - val_loss: 36318.8477\n",
      "Epoch 451/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42770.7690 - val_loss: 42938.5273\n",
      "Epoch 452/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 49417.4531 - val_loss: 40426.3359\n",
      "Epoch 453/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42867.4631 - val_loss: 51934.7109\n",
      "Epoch 454/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 57446.7573 - val_loss: 45153.3984\n",
      "Epoch 455/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 53525.9332 - val_loss: 35629.6523\n",
      "Epoch 456/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 41738.3332 - val_loss: 36388.2109\n",
      "Epoch 457/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 44463.0633 - val_loss: 42476.2383\n",
      "Epoch 458/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 50988.7819 - val_loss: 33940.5781\n",
      "Epoch 459/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41739.0464 - val_loss: 40160.4883\n",
      "Epoch 460/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 46885.6602 - val_loss: 39974.0703\n",
      "Epoch 461/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 49841.0824 - val_loss: 30346.9805\n",
      "Epoch 462/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37017.8535 - val_loss: 39342.5625\n",
      "Epoch 463/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42502.4684 - val_loss: 37969.7578\n",
      "Epoch 464/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 47632.9039 - val_loss: 25639.0117\n",
      "Epoch 465/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34850.3377 - val_loss: 33438.1133\n",
      "Epoch 466/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 48597.0479 - val_loss: 28591.4922\n",
      "Epoch 467/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40200.3880 - val_loss: 31486.8828\n",
      "Epoch 468/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 41025.9226 - val_loss: 35862.3984\n",
      "Epoch 469/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 42347.9756 - val_loss: 46851.3828\n",
      "Epoch 470/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 53113.4733 - val_loss: 51887.5898\n",
      "Epoch 471/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 61038.8777 - val_loss: 60938.9688\n",
      "Epoch 472/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 60483.9324 - val_loss: 66405.3984\n",
      "Epoch 473/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 69153.4413 - val_loss: 47029.9062\n",
      "Epoch 474/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 44694.5667 - val_loss: 55754.3984\n",
      "Epoch 475/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 61526.4684 - val_loss: 43020.4062\n",
      "Epoch 476/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 49400.7118 - val_loss: 42639.8242\n",
      "Epoch 477/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 51584.7822 - val_loss: 46437.1562\n",
      "Epoch 478/2500\n",
      "2800/2800 [==============================] - ETA: 0s - loss: 52136.140 - 0s 8us/step - loss: 47298.3024 - val_loss: 61818.6211\n",
      "Epoch 479/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 58560.1838 - val_loss: 46791.7812\n",
      "Epoch 480/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 58731.9394 - val_loss: 33596.0625\n",
      "Epoch 481/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 41267.2716 - val_loss: 44826.7109\n",
      "Epoch 482/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 55538.9312 - val_loss: 38540.1367\n",
      "Epoch 483/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 42010.8434 - val_loss: 34511.7578\n",
      "Epoch 484/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 43111.3729 - val_loss: 31844.2422\n",
      "Epoch 485/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 40845.7569 - val_loss: 35040.3906\n",
      "Epoch 486/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38282.1666 - val_loss: 31288.9766\n",
      "Epoch 487/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 38973.0450 - val_loss: 35484.7500\n",
      "Epoch 488/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42182.8054 - val_loss: 30643.1250\n",
      "Epoch 489/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39330.6767 - val_loss: 35061.4570\n",
      "Epoch 490/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 44774.6478 - val_loss: 42396.9180\n",
      "Epoch 491/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 47072.0633 - val_loss: 42074.3984\n",
      "Epoch 492/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 51873.6852 - val_loss: 32038.0625\n",
      "Epoch 493/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 44488.0148 - val_loss: 32085.9453\n",
      "Epoch 494/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 45303.3164 - val_loss: 24987.7188\n",
      "Epoch 495/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30727.8803 - val_loss: 28552.5469\n",
      "Epoch 496/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31417.9295 - val_loss: 30622.7656\n",
      "Epoch 497/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38448.7252 - val_loss: 32532.4199\n",
      "Epoch 498/2500\n",
      "2800/2800 [==============================] - ETA: 0s - loss: 37386.144 - 0s 8us/step - loss: 40479.9991 - val_loss: 39681.6328\n",
      "Epoch 499/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 49742.8087 - val_loss: 39740.5547\n",
      "Epoch 500/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 47530.4609 - val_loss: 36860.9648\n",
      "Epoch 501/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 50261.1772 - val_loss: 29746.9570\n",
      "Epoch 502/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 36412.9035 - val_loss: 43530.6328\n",
      "Epoch 503/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800/2800 [==============================] - 0s 8us/step - loss: 53077.1237 - val_loss: 37676.9141\n",
      "Epoch 504/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 43955.3932 - val_loss: 37676.4180\n",
      "Epoch 505/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 50870.7987 - val_loss: 33375.8516\n",
      "Epoch 506/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 42770.5873 - val_loss: 31322.2422\n",
      "Epoch 507/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41061.9815 - val_loss: 27864.0391\n",
      "Epoch 508/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35903.5296 - val_loss: 30687.3906\n",
      "Epoch 509/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 39051.1578 - val_loss: 42865.1094\n",
      "Epoch 510/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 49836.5946 - val_loss: 44302.1992\n",
      "Epoch 511/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 51573.4017 - val_loss: 41302.6172\n",
      "Epoch 512/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 46122.7715 - val_loss: 47172.0195\n",
      "Epoch 513/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 58787.7683 - val_loss: 43821.3477\n",
      "Epoch 514/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 45944.7824 - val_loss: 53042.0820\n",
      "Epoch 515/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 56521.7032 - val_loss: 58994.7383\n",
      "Epoch 516/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 67527.6092 - val_loss: 37632.2031\n",
      "Epoch 517/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 45066.8248 - val_loss: 37085.7578\n",
      "Epoch 518/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 42237.3689 - val_loss: 28501.8320\n",
      "Epoch 519/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 28886.4707 - val_loss: 36600.3867\n",
      "Epoch 520/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 41119.7283 - val_loss: 31048.4727\n",
      "Epoch 521/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 37906.5966 - val_loss: 34976.0547\n",
      "Epoch 522/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 44352.6847 - val_loss: 40943.0391\n",
      "Epoch 523/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 47571.9351 - val_loss: 37880.3828\n",
      "Epoch 524/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42111.7689 - val_loss: 40954.3828\n",
      "Epoch 525/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 45371.9991 - val_loss: 53467.6445\n",
      "Epoch 526/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 49025.8520 - val_loss: 54640.0508\n",
      "Epoch 527/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 54798.4585 - val_loss: 51004.9609\n",
      "Epoch 528/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 58138.0905 - val_loss: 34337.9531\n",
      "Epoch 529/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35150.4207 - val_loss: 44702.4336\n",
      "Epoch 530/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 47026.1573 - val_loss: 51853.3555\n",
      "Epoch 531/2500\n",
      "2800/2800 [==============================] - ETA: 0s - loss: 58430.382 - 0s 7us/step - loss: 52301.6502 - val_loss: 50765.4766\n",
      "Epoch 532/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 53114.7895 - val_loss: 33885.6094\n",
      "Epoch 533/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 40820.0941 - val_loss: 31922.8438\n",
      "Epoch 534/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41504.8646 - val_loss: 28898.9219\n",
      "Epoch 535/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35883.6629 - val_loss: 30108.1641\n",
      "Epoch 536/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 36911.0440 - val_loss: 36731.4766\n",
      "Epoch 537/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41465.8660 - val_loss: 48075.0781\n",
      "Epoch 538/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 53520.1036 - val_loss: 38213.8203\n",
      "Epoch 539/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 44350.3076 - val_loss: 46273.1719\n",
      "Epoch 540/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 52518.2408 - val_loss: 42687.7109\n",
      "Epoch 541/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 47745.7007 - val_loss: 33055.5859\n",
      "Epoch 542/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 44590.9005 - val_loss: 28851.9609\n",
      "Epoch 543/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42238.7877 - val_loss: 24921.9375\n",
      "Epoch 544/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32665.6124 - val_loss: 31426.6035\n",
      "Epoch 545/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 37747.7938 - val_loss: 32323.5586\n",
      "Epoch 546/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38444.4238 - val_loss: 37467.4453\n",
      "Epoch 547/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 50507.4382 - val_loss: 19460.1406\n",
      "Epoch 548/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 25606.3955 - val_loss: 26260.2012\n",
      "Epoch 549/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36360.0447 - val_loss: 29694.1875\n",
      "Epoch 550/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 34198.5362 - val_loss: 34786.9180\n",
      "Epoch 551/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41050.3968 - val_loss: 36376.3203\n",
      "Epoch 552/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 45854.0273 - val_loss: 30438.5352\n",
      "Epoch 553/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40177.4700 - val_loss: 34515.3516\n",
      "Epoch 554/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39015.7023 - val_loss: 40500.8359\n",
      "Epoch 555/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 50229.7497 - val_loss: 40187.0625\n",
      "Epoch 556/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 46961.9517 - val_loss: 35377.4688\n",
      "Epoch 557/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 42801.5497 - val_loss: 46881.9492\n",
      "Epoch 558/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 48980.1480 - val_loss: 43896.7148\n",
      "Epoch 559/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 54907.0913 - val_loss: 33655.2656\n",
      "Epoch 560/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41223.3057 - val_loss: 34782.5469\n",
      "Epoch 561/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38372.2405 - val_loss: 39882.8828\n",
      "Epoch 562/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 46700.2109 - val_loss: 38710.4102\n",
      "Epoch 563/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 46229.0190 - val_loss: 36394.4102\n",
      "Epoch 564/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 43449.1060 - val_loss: 37466.8438\n",
      "Epoch 565/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 42166.6592 - val_loss: 42103.4922\n",
      "Epoch 566/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 54183.7088 - val_loss: 28732.0820\n",
      "Epoch 567/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36544.6750 - val_loss: 33325.2461\n",
      "Epoch 568/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40958.7941 - val_loss: 39945.7031\n",
      "Epoch 569/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 45161.2406 - val_loss: 40856.7891\n",
      "Epoch 570/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 49615.4706 - val_loss: 38773.3945\n",
      "Epoch 571/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 46893.0336 - val_loss: 48750.6172\n",
      "Epoch 572/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 52270.1211 - val_loss: 37847.4922\n",
      "Epoch 573/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 47193.0854 - val_loss: 36803.6602\n",
      "Epoch 574/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800/2800 [==============================] - 0s 7us/step - loss: 44468.7569 - val_loss: 35923.7305\n",
      "Epoch 575/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 44992.8875 - val_loss: 22395.6543\n",
      "Epoch 576/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 27758.9460 - val_loss: 33550.2109\n",
      "Epoch 577/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 45379.7747 - val_loss: 35217.8047\n",
      "Epoch 578/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 43563.0161 - val_loss: 37259.9141\n",
      "Epoch 579/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 43351.2300 - val_loss: 50243.7891\n",
      "Epoch 580/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 59150.4348 - val_loss: 38523.6367\n",
      "Epoch 581/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 50791.1753 - val_loss: 37590.0234\n",
      "Epoch 582/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 43201.9215 - val_loss: 40482.2461\n",
      "Epoch 583/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 48417.9736 - val_loss: 41094.4219\n",
      "Epoch 584/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 53084.9890 - val_loss: 23006.5449\n",
      "Epoch 585/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 27868.2187 - val_loss: 35614.4141\n",
      "Epoch 586/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 42933.9646 - val_loss: 39167.4375\n",
      "Epoch 587/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 45854.8103 - val_loss: 33949.8516\n",
      "Epoch 588/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 43461.6312 - val_loss: 28087.8828\n",
      "Epoch 589/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33813.7677 - val_loss: 42579.3242\n",
      "Epoch 590/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 49561.5479 - val_loss: 41979.8594\n",
      "Epoch 591/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 44039.4553 - val_loss: 37677.9375\n",
      "Epoch 592/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 49317.3887 - val_loss: 28865.6621\n",
      "Epoch 593/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 38000.9720 - val_loss: 32431.3320\n",
      "Epoch 594/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40231.8025 - val_loss: 38754.3906\n",
      "Epoch 595/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 49312.9305 - val_loss: 39835.9844\n",
      "Epoch 596/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 48791.6524 - val_loss: 47396.0625\n",
      "Epoch 597/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 53811.7049 - val_loss: 34195.1562\n",
      "Epoch 598/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41650.5142 - val_loss: 36396.6016\n",
      "Epoch 599/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 41417.3795 - val_loss: 47702.3633\n",
      "Epoch 600/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 47641.9750 - val_loss: 60195.7422\n",
      "Epoch 601/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 58384.7891 - val_loss: 61021.8359\n",
      "Epoch 602/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 62107.6627 - val_loss: 48476.4805\n",
      "Epoch 603/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 51130.9165 - val_loss: 39390.7695\n",
      "Epoch 604/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 44213.8265 - val_loss: 37730.5938\n",
      "Epoch 605/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 42525.1419 - val_loss: 37513.5742\n",
      "Epoch 606/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 41443.3836 - val_loss: 42415.4609\n",
      "Epoch 607/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 45236.9071 - val_loss: 45253.5742\n",
      "Epoch 608/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 50521.9651 - val_loss: 27453.0352\n",
      "Epoch 609/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 30507.9790 - val_loss: 38287.7695\n",
      "Epoch 610/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 36787.5211 - val_loss: 44948.9453\n",
      "Epoch 611/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 46936.7558 - val_loss: 39231.9922\n",
      "Epoch 612/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 42167.1425 - val_loss: 35305.8711\n",
      "Epoch 613/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 37877.5783 - val_loss: 34992.3711\n",
      "Epoch 614/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37156.2373 - val_loss: 39663.6797\n",
      "Epoch 615/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 45822.6808 - val_loss: 39876.3750\n",
      "Epoch 616/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 40618.9641 - val_loss: 41054.7148\n",
      "Epoch 617/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 44302.6761 - val_loss: 41238.4492\n",
      "Epoch 618/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 44455.4840 - val_loss: 43489.7109\n",
      "Epoch 619/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 49192.4481 - val_loss: 33952.8750\n",
      "Epoch 620/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39709.2535 - val_loss: 37607.9805\n",
      "Epoch 621/2500\n",
      "2800/2800 [==============================] - 0s 10us/step - loss: 47228.7788 - val_loss: 23328.9648\n",
      "Epoch 622/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31505.1421 - val_loss: 29847.9629\n",
      "Epoch 623/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 35973.0183 - val_loss: 36300.5703\n",
      "Epoch 624/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 42799.9567 - val_loss: 30206.6367\n",
      "Epoch 625/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34429.4216 - val_loss: 37383.9062\n",
      "Epoch 626/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 40468.8518 - val_loss: 45682.8594\n",
      "Epoch 627/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 48771.5457 - val_loss: 32647.5156\n",
      "Epoch 628/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36412.5774 - val_loss: 46420.7422\n",
      "Epoch 629/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 54613.6019 - val_loss: 36789.8594\n",
      "Epoch 630/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 45116.6953 - val_loss: 32353.3887\n",
      "Epoch 631/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41847.2659 - val_loss: 35178.6719\n",
      "Epoch 632/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41090.8316 - val_loss: 42107.6719\n",
      "Epoch 633/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 47286.2221 - val_loss: 31426.7285\n",
      "Epoch 634/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40512.4831 - val_loss: 26735.6133\n",
      "Epoch 635/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38860.0786 - val_loss: 31045.1074\n",
      "Epoch 636/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 39738.0127 - val_loss: 40621.1289\n",
      "Epoch 637/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 44069.6216 - val_loss: 51016.7891\n",
      "Epoch 638/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 44179.0890 - val_loss: 65150.6211\n",
      "Epoch 639/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 58569.7104 - val_loss: 52826.1836\n",
      "Epoch 640/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 55397.8685 - val_loss: 53827.0625\n",
      "Epoch 641/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 61442.1336 - val_loss: 38202.5312\n",
      "Epoch 642/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42902.4946 - val_loss: 46080.0898\n",
      "Epoch 643/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 52077.7665 - val_loss: 36906.0391\n",
      "Epoch 644/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 43128.4989 - val_loss: 33136.9609\n",
      "Epoch 645/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39940.1006 - val_loss: 34840.1172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 646/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 41278.8171 - val_loss: 36589.3789\n",
      "Epoch 647/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 46820.0405 - val_loss: 38438.1172\n",
      "Epoch 648/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 43547.6651 - val_loss: 37492.5625\n",
      "Epoch 649/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 47731.0654 - val_loss: 34263.2539\n",
      "Epoch 650/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40926.2519 - val_loss: 44668.3359\n",
      "Epoch 651/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 50395.5718 - val_loss: 29484.0000\n",
      "Epoch 652/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34528.2877 - val_loss: 40943.3047\n",
      "Epoch 653/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 46248.9395 - val_loss: 40309.4180\n",
      "Epoch 654/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 49246.2974 - val_loss: 29072.4102\n",
      "Epoch 655/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39247.0675 - val_loss: 31116.6055\n",
      "Epoch 656/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 41311.9579 - val_loss: 28639.9297\n",
      "Epoch 657/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33538.6711 - val_loss: 42989.9258\n",
      "Epoch 658/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 48542.3223 - val_loss: 37694.4883\n",
      "Epoch 659/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 49023.8136 - val_loss: 28432.1289\n",
      "Epoch 660/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38189.0909 - val_loss: 34128.1328\n",
      "Epoch 661/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 43046.5425 - val_loss: 39169.3828\n",
      "Epoch 662/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 49606.9671 - val_loss: 38590.5820\n",
      "Epoch 663/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 45272.3021 - val_loss: 46975.2500\n",
      "Epoch 664/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 53110.1292 - val_loss: 56898.4492\n",
      "Epoch 665/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 63827.2818 - val_loss: 42987.0312\n",
      "Epoch 666/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 51085.6423 - val_loss: 37479.6367\n",
      "Epoch 667/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38711.6712 - val_loss: 42787.4492\n",
      "Epoch 668/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 42732.4088 - val_loss: 41507.8672\n",
      "Epoch 669/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 48564.8200 - val_loss: 33276.7188\n",
      "Epoch 670/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 38852.9220 - val_loss: 40289.4648\n",
      "Epoch 671/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 47881.0479 - val_loss: 44090.4609\n",
      "Epoch 672/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 51315.5395 - val_loss: 42975.9688\n",
      "Epoch 673/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 52300.6510 - val_loss: 26781.7422\n",
      "Epoch 674/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 32947.5570 - val_loss: 25094.4512\n",
      "Epoch 675/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 35833.5901 - val_loss: 33686.2148\n",
      "Epoch 676/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 41135.0632 - val_loss: 34930.5820\n",
      "Epoch 677/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 42043.2385 - val_loss: 31425.7031\n",
      "Epoch 678/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 40461.1309 - val_loss: 37472.4453\n",
      "Epoch 679/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 36250.0126 - val_loss: 61459.1836\n",
      "Epoch 680/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 58335.3364 - val_loss: 57896.6602\n",
      "Epoch 681/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 63073.3760 - val_loss: 43320.3750\n",
      "Epoch 682/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 62997.2695 - val_loss: 26322.6992\n",
      "Epoch 683/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31338.6809 - val_loss: 31913.5371\n",
      "Epoch 684/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 38158.6456 - val_loss: 42706.0820\n",
      "Epoch 685/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 47186.2676 - val_loss: 36034.4844\n",
      "Epoch 686/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 34866.3063 - val_loss: 49687.0273\n",
      "Epoch 687/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 58498.9392 - val_loss: 27551.3867\n",
      "Epoch 688/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 35503.9266 - val_loss: 26069.8887\n",
      "Epoch 689/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36847.2589 - val_loss: 30767.3691\n",
      "Epoch 690/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42588.1806 - val_loss: 27857.0684\n",
      "Epoch 691/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35969.0551 - val_loss: 37325.5781\n",
      "Epoch 692/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 45780.1543 - val_loss: 34266.1484\n",
      "Epoch 693/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39691.7144 - val_loss: 30327.9121\n",
      "Epoch 694/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41055.4240 - val_loss: 30048.9844\n",
      "Epoch 695/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38096.4095 - val_loss: 33544.1055\n",
      "Epoch 696/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 37768.4170 - val_loss: 49893.1055\n",
      "Epoch 697/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 55749.5867 - val_loss: 49470.3633\n",
      "Epoch 698/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 55147.8619 - val_loss: 44650.6484\n",
      "Epoch 699/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 50209.6286 - val_loss: 47725.4219\n",
      "Epoch 700/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 48434.6998 - val_loss: 52810.2266\n",
      "Epoch 701/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 53132.6029 - val_loss: 45419.8125\n",
      "Epoch 702/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 50212.5714 - val_loss: 42233.5898\n",
      "Epoch 703/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 45494.6876 - val_loss: 41786.7344\n",
      "Epoch 704/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 45035.9877 - val_loss: 48667.6094\n",
      "Epoch 705/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 60066.8491 - val_loss: 37793.5078\n",
      "Epoch 706/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 52889.1289 - val_loss: 33999.4844\n",
      "Epoch 707/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41518.6404 - val_loss: 38231.5391\n",
      "Epoch 708/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39965.0051 - val_loss: 44533.5547\n",
      "Epoch 709/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 49645.7754 - val_loss: 40230.5781\n",
      "Epoch 710/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 47885.6238 - val_loss: 30631.8926\n",
      "Epoch 711/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37448.3313 - val_loss: 40358.1406\n",
      "Epoch 712/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 48441.9170 - val_loss: 33081.0234\n",
      "Epoch 713/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 41376.1192 - val_loss: 34741.0547\n",
      "Epoch 714/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 48023.6618 - val_loss: 32471.9238\n",
      "Epoch 715/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41076.6703 - val_loss: 32807.6914\n",
      "Epoch 716/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39602.9213 - val_loss: 36545.0625\n",
      "Epoch 717/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 48352.9539 - val_loss: 42160.8438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 718/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 50889.0407 - val_loss: 47421.3008\n",
      "Epoch 719/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 49411.5671 - val_loss: 47214.0664\n",
      "Epoch 720/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 55523.7448 - val_loss: 35897.7070\n",
      "Epoch 721/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 40637.8820 - val_loss: 41695.5703\n",
      "Epoch 722/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 46582.5713 - val_loss: 51185.2930\n",
      "Epoch 723/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 55703.0025 - val_loss: 39204.1641\n",
      "Epoch 724/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 44210.6826 - val_loss: 49051.5742\n",
      "Epoch 725/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 53764.8893 - val_loss: 44673.4727\n",
      "Epoch 726/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 51969.7921 - val_loss: 43138.4023\n",
      "Epoch 727/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 50721.9382 - val_loss: 35156.8633\n",
      "Epoch 728/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 42992.3068 - val_loss: 47737.4648\n",
      "Epoch 729/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 54104.2187 - val_loss: 40266.6953\n",
      "Epoch 730/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 51174.5514 - val_loss: 29525.2656\n",
      "Epoch 731/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39971.0125 - val_loss: 37945.6367\n",
      "Epoch 732/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 45888.0494 - val_loss: 52983.6016\n",
      "Epoch 733/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 56131.2490 - val_loss: 57491.0273\n",
      "Epoch 734/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 57161.6454 - val_loss: 34892.9805\n",
      "Epoch 735/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42198.8339 - val_loss: 35958.6602\n",
      "Epoch 736/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37014.4768 - val_loss: 47884.2344\n",
      "Epoch 737/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 52525.9961 - val_loss: 62963.5938\n",
      "Epoch 738/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 60902.3210 - val_loss: 57366.0195\n",
      "Epoch 739/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 69031.1765 - val_loss: 37392.8867\n",
      "Epoch 740/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42681.3392 - val_loss: 47387.5703\n",
      "Epoch 741/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 47519.7829 - val_loss: 40692.2266\n",
      "Epoch 742/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 52958.0187 - val_loss: 38132.0781\n",
      "Epoch 743/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40632.6286 - val_loss: 46076.3438\n",
      "Epoch 744/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 50982.7834 - val_loss: 41275.5859\n",
      "Epoch 745/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 52606.7641 - val_loss: 38439.3359\n",
      "Epoch 746/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 45543.7080 - val_loss: 46013.0547\n",
      "Epoch 747/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 53953.7783 - val_loss: 31785.2852\n",
      "Epoch 748/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 43333.7069 - val_loss: 32427.0273\n",
      "Epoch 749/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 43624.6380 - val_loss: 32444.9707\n",
      "Epoch 750/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37905.2843 - val_loss: 43142.2852\n",
      "Epoch 751/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 53509.9897 - val_loss: 34237.4883\n",
      "Epoch 752/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40498.7035 - val_loss: 42862.7812\n",
      "Epoch 753/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 47492.5566 - val_loss: 47576.3125\n",
      "Epoch 754/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 55776.5475 - val_loss: 32438.9121\n",
      "Epoch 755/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 38568.4306 - val_loss: 41624.2852\n",
      "Epoch 756/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 47562.6817 - val_loss: 51905.1094\n",
      "Epoch 757/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 57979.7995 - val_loss: 45252.5469\n",
      "Epoch 758/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 51106.1594 - val_loss: 43526.2383\n",
      "Epoch 759/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 51740.9482 - val_loss: 48581.7031\n",
      "Epoch 760/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 52179.6965 - val_loss: 51899.5234\n",
      "Epoch 761/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 59133.4545 - val_loss: 46875.0156\n",
      "Epoch 762/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 52636.9045 - val_loss: 48663.8320\n",
      "Epoch 763/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 54989.4671 - val_loss: 42626.2148\n",
      "Epoch 764/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 50012.2194 - val_loss: 56544.8125\n",
      "Epoch 765/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 60806.9160 - val_loss: 49974.4648\n",
      "Epoch 766/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 56291.2581 - val_loss: 48042.5117\n",
      "Epoch 767/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 53210.6721 - val_loss: 51072.0078\n",
      "Epoch 768/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 56762.7421 - val_loss: 48270.0625\n",
      "Epoch 769/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 62923.7682 - val_loss: 44560.5430\n",
      "Epoch 770/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 45248.7378 - val_loss: 43373.6367\n",
      "Epoch 771/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 51987.9846 - val_loss: 36972.1875\n",
      "Epoch 772/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 47044.1983 - val_loss: 33326.0273\n",
      "Epoch 773/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42412.8189 - val_loss: 38927.2578\n",
      "Epoch 774/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 49815.2441 - val_loss: 40282.3086\n",
      "Epoch 775/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 48089.6953 - val_loss: 37605.3828\n",
      "Epoch 776/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 44388.5678 - val_loss: 55040.0391\n",
      "Epoch 777/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 59692.8123 - val_loss: 32001.3340\n",
      "Epoch 778/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 39804.0285 - val_loss: 37710.2305\n",
      "Epoch 779/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39680.3956 - val_loss: 45620.7617\n",
      "Epoch 780/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 52984.3130 - val_loss: 45947.4492\n",
      "Epoch 781/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 54809.0168 - val_loss: 40834.9531\n",
      "Epoch 782/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 47276.4436 - val_loss: 46675.2422\n",
      "Epoch 783/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 50033.1218 - val_loss: 40966.9375\n",
      "Epoch 784/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 47314.8289 - val_loss: 39051.0234\n",
      "Epoch 785/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42953.2780 - val_loss: 31902.1172\n",
      "Epoch 786/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41503.7042 - val_loss: 28714.7266\n",
      "Epoch 787/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 35837.1311 - val_loss: 35589.8867\n",
      "Epoch 788/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 42002.6758 - val_loss: 35134.7109\n",
      "Epoch 789/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41156.3329 - val_loss: 35095.9609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 790/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 50637.0465 - val_loss: 33575.1211\n",
      "Epoch 791/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 42671.7831 - val_loss: 44497.0625\n",
      "Epoch 792/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 54862.6195 - val_loss: 49490.9258\n",
      "Epoch 793/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 57348.9140 - val_loss: 33223.5547\n",
      "Epoch 794/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40008.8466 - val_loss: 40276.5938\n",
      "Epoch 795/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 55900.2739 - val_loss: 38660.7500\n",
      "Epoch 796/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 46749.5634 - val_loss: 47795.2422\n",
      "Epoch 797/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 52016.6736 - val_loss: 49672.1719\n",
      "Epoch 798/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 54073.4779 - val_loss: 40746.1367\n",
      "Epoch 799/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 48928.2425 - val_loss: 45754.4375\n",
      "Epoch 800/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 55531.8385 - val_loss: 50050.4023\n",
      "Epoch 801/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 48307.8844 - val_loss: 46653.3164\n",
      "Epoch 802/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 47709.5896 - val_loss: 55780.0781\n",
      "Epoch 803/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 64815.1486 - val_loss: 34300.9492\n",
      "Epoch 804/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40394.1185 - val_loss: 45695.7305\n",
      "Epoch 805/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 48182.7593 - val_loss: 42610.4766\n",
      "Epoch 806/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 51373.8124 - val_loss: 45636.2461\n",
      "Epoch 807/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 54037.2075 - val_loss: 45917.4297\n",
      "Epoch 808/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 45145.5784 - val_loss: 56908.4609\n",
      "Epoch 809/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 57452.6872 - val_loss: 51853.3203\n",
      "Epoch 810/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 58489.1581 - val_loss: 47919.8750\n",
      "Epoch 811/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 59468.5514 - val_loss: 34633.2422\n",
      "Epoch 812/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 49231.6161 - val_loss: 26167.9922\n",
      "Epoch 813/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 31030.6829 - val_loss: 37475.3398\n",
      "Epoch 814/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 46174.1406 - val_loss: 32505.5059\n",
      "Epoch 815/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 42812.4934 - val_loss: 28037.9707\n",
      "Epoch 816/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39420.7679 - val_loss: 28122.8945\n",
      "Epoch 817/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 40338.2435 - val_loss: 27910.2031\n",
      "Epoch 818/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38104.4551 - val_loss: 32963.2852\n",
      "Epoch 819/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 43898.9052 - val_loss: 39907.1992\n",
      "Epoch 820/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 50133.0131 - val_loss: 35585.7578\n",
      "Epoch 821/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42659.9032 - val_loss: 41649.7188\n",
      "Epoch 822/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 46459.6029 - val_loss: 37441.3711\n",
      "Epoch 823/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39603.3834 - val_loss: 57573.2773\n",
      "Epoch 824/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 56174.6759 - val_loss: 55440.5703\n",
      "Epoch 825/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 65668.9440 - val_loss: 37617.7148\n",
      "Epoch 826/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 47271.6149 - val_loss: 43915.0078\n",
      "Epoch 827/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 48880.9284 - val_loss: 27351.3184\n",
      "Epoch 828/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31832.7276 - val_loss: 36505.5430\n",
      "Epoch 829/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 50821.4636 - val_loss: 32629.2773\n",
      "Epoch 830/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 36047.0255 - val_loss: 51591.2422\n",
      "Epoch 831/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 51695.5625 - val_loss: 56378.2969\n",
      "Epoch 832/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 62952.5034 - val_loss: 34518.5977\n",
      "Epoch 833/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37025.7798 - val_loss: 42475.8164\n",
      "Epoch 834/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 47135.3502 - val_loss: 38991.6328\n",
      "Epoch 835/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 43644.3835 - val_loss: 53804.1055\n",
      "Epoch 836/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 50049.3948 - val_loss: 40807.5859\n",
      "Epoch 837/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 54970.3461 - val_loss: 31135.9863\n",
      "Epoch 838/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 37283.1342 - val_loss: 44015.1055\n",
      "Epoch 839/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 47514.3564 - val_loss: 49494.7188\n",
      "Epoch 840/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 47906.9173 - val_loss: 48995.8281\n",
      "Epoch 841/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 50459.3039 - val_loss: 57197.4844\n",
      "Epoch 842/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 61233.0596 - val_loss: 39005.9883\n",
      "Epoch 843/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 46051.5917 - val_loss: 32662.9805\n",
      "Epoch 844/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 45318.3999 - val_loss: 28767.0859\n",
      "Epoch 845/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35108.2710 - val_loss: 36601.6250\n",
      "Epoch 846/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 45611.2935 - val_loss: 37234.4023\n",
      "Epoch 847/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 43945.5329 - val_loss: 45693.6680\n",
      "Epoch 848/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 49772.0983 - val_loss: 41205.9531\n",
      "Epoch 849/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 42478.7399 - val_loss: 43404.7578\n",
      "Epoch 850/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 49782.2654 - val_loss: 36049.5820\n",
      "Epoch 851/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 45321.8728 - val_loss: 29026.3438\n",
      "Epoch 852/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38399.9797 - val_loss: 32285.0156\n",
      "Epoch 853/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 36635.5034 - val_loss: 43952.2812\n",
      "Epoch 854/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 50810.8937 - val_loss: 43460.6680\n",
      "Epoch 855/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 53207.6204 - val_loss: 35100.7461\n",
      "Epoch 856/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 45012.6730 - val_loss: 39508.2734\n",
      "Epoch 857/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 43175.0638 - val_loss: 40456.4453\n",
      "Epoch 858/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 52762.5806 - val_loss: 33139.4766\n",
      "Epoch 859/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41855.5844 - val_loss: 30004.6738\n",
      "Epoch 860/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41021.1370 - val_loss: 32716.1973\n",
      "Epoch 861/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 41757.8491 - val_loss: 35495.5039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 862/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42606.5562 - val_loss: 35436.0547\n",
      "Epoch 863/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40518.6300 - val_loss: 42343.0781\n",
      "Epoch 864/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 53454.9935 - val_loss: 44287.9062\n",
      "Epoch 865/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 53370.9787 - val_loss: 41568.7188\n",
      "Epoch 866/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 50814.9605 - val_loss: 41851.7695\n",
      "Epoch 867/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 49508.8339 - val_loss: 32508.5352\n",
      "Epoch 868/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38115.4527 - val_loss: 49873.6758\n",
      "Epoch 869/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41515.8860 - val_loss: 39459.1289\n",
      "Epoch 870/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 49071.4068 - val_loss: 38004.7500\n",
      "Epoch 871/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 50547.4286 - val_loss: 36742.2695\n",
      "Epoch 872/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 46652.7044 - val_loss: 43785.4727\n",
      "Epoch 873/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 53056.7387 - val_loss: 37979.1641\n",
      "Epoch 874/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 48861.0705 - val_loss: 30955.3086\n",
      "Epoch 875/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 36343.0997 - val_loss: 43888.4766\n",
      "Epoch 876/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 52954.5547 - val_loss: 42641.6875\n",
      "Epoch 877/2500\n",
      "2800/2800 [==============================] - 0s 10us/step - loss: 53216.5635 - val_loss: 38756.8906\n",
      "Epoch 878/2500\n",
      "2800/2800 [==============================] - 0s 10us/step - loss: 39428.2202 - val_loss: 48764.4961\n",
      "Epoch 879/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 53271.8007 - val_loss: 51662.8672\n",
      "Epoch 880/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 57880.9022 - val_loss: 34264.6680\n",
      "Epoch 881/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 41484.2214 - val_loss: 45132.0469\n",
      "Epoch 882/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 52722.2300 - val_loss: 51365.8789\n",
      "Epoch 883/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 56045.1121 - val_loss: 36666.3906\n",
      "Epoch 884/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 43091.5726 - val_loss: 36033.5312\n",
      "Epoch 885/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 43422.2909 - val_loss: 44119.3516\n",
      "Epoch 886/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 56216.9931 - val_loss: 38339.8242\n",
      "Epoch 887/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 45267.5151 - val_loss: 34411.1172\n",
      "Epoch 888/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 40256.6934 - val_loss: 44289.4805\n",
      "Epoch 889/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 53102.9615 - val_loss: 53368.6133\n",
      "Epoch 890/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 60249.2789 - val_loss: 46717.9258\n",
      "Epoch 891/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 44352.9093 - val_loss: 51589.6211\n",
      "Epoch 892/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 59708.5170 - val_loss: 40105.2617\n",
      "Epoch 893/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 41578.5979 - val_loss: 35510.3125\n",
      "Epoch 894/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42545.2016 - val_loss: 53870.0977\n",
      "Epoch 895/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 58526.5194 - val_loss: 44394.6836\n",
      "Epoch 896/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 44014.5976 - val_loss: 52363.2656\n",
      "Epoch 897/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 55791.6771 - val_loss: 44219.3008\n",
      "Epoch 898/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 47375.7999 - val_loss: 56280.9688\n",
      "Epoch 899/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 57686.3002 - val_loss: 43596.9453\n",
      "Epoch 900/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 56822.8742 - val_loss: 31002.7051\n",
      "Epoch 901/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 39401.2380 - val_loss: 32836.6289\n",
      "Epoch 902/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39715.0847 - val_loss: 30084.2109\n",
      "Epoch 903/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 28670.2181 - val_loss: 39240.5820\n",
      "Epoch 904/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40987.1995 - val_loss: 33195.3398\n",
      "Epoch 905/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 46844.9519 - val_loss: 27022.9785\n",
      "Epoch 906/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 33489.8970 - val_loss: 38829.0195\n",
      "Epoch 907/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37942.7687 - val_loss: 55251.3359\n",
      "Epoch 908/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 53567.1460 - val_loss: 45657.2500\n",
      "Epoch 909/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 50658.5127 - val_loss: 41418.3125\n",
      "Epoch 910/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 55514.2618 - val_loss: 30413.6328\n",
      "Epoch 911/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32835.4017 - val_loss: 37463.7656\n",
      "Epoch 912/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 43565.1502 - val_loss: 38035.8125\n",
      "Epoch 913/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 49026.5862 - val_loss: 29697.2363\n",
      "Epoch 914/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39007.7272 - val_loss: 38429.5781\n",
      "Epoch 915/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 45275.3531 - val_loss: 27915.0098\n",
      "Epoch 916/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36939.6214 - val_loss: 38820.4219\n",
      "Epoch 917/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 47544.2474 - val_loss: 37626.5391\n",
      "Epoch 918/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42284.7155 - val_loss: 41371.8555\n",
      "Epoch 919/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 49373.2517 - val_loss: 31701.3164\n",
      "Epoch 920/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 39332.3450 - val_loss: 33778.1875\n",
      "Epoch 921/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38883.5009 - val_loss: 29697.9746\n",
      "Epoch 922/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39399.0984 - val_loss: 30930.0039\n",
      "Epoch 923/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40221.4751 - val_loss: 39601.8516\n",
      "Epoch 924/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 38777.0466 - val_loss: 51300.1758\n",
      "Epoch 925/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 50450.3526 - val_loss: 47457.8984\n",
      "Epoch 926/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 49146.6227 - val_loss: 46217.4453\n",
      "Epoch 927/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 51982.1853 - val_loss: 36553.0430\n",
      "Epoch 928/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 46265.7078 - val_loss: 41005.5273\n",
      "Epoch 929/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 46544.7731 - val_loss: 32118.8203\n",
      "Epoch 930/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42504.1244 - val_loss: 31385.1387\n",
      "Epoch 931/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 37787.8489 - val_loss: 36174.0273\n",
      "Epoch 932/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 44962.0629 - val_loss: 32954.4258\n",
      "Epoch 933/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 47467.3254 - val_loss: 28976.1758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 934/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40319.1563 - val_loss: 31054.3457\n",
      "Epoch 935/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 39870.4186 - val_loss: 35489.4688\n",
      "Epoch 936/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37430.8402 - val_loss: 52758.9727\n",
      "Epoch 937/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 57633.4142 - val_loss: 38351.6133\n",
      "Epoch 938/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41942.8523 - val_loss: 45899.6055\n",
      "Epoch 939/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 54798.4379 - val_loss: 42826.9414\n",
      "Epoch 940/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 47596.3700 - val_loss: 42735.7109\n",
      "Epoch 941/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 51153.3992 - val_loss: 29907.9043\n",
      "Epoch 942/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 37925.5769 - val_loss: 30535.1094\n",
      "Epoch 943/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35941.8764 - val_loss: 27049.2090\n",
      "Epoch 944/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36358.8716 - val_loss: 30395.9766\n",
      "Epoch 945/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 44577.1956 - val_loss: 25477.8398\n",
      "Epoch 946/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33871.2338 - val_loss: 32908.2383\n",
      "Epoch 947/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40531.9647 - val_loss: 40210.6484\n",
      "Epoch 948/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 48589.1545 - val_loss: 34955.5938\n",
      "Epoch 949/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 44504.3651 - val_loss: 30783.2207\n",
      "Epoch 950/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36943.7388 - val_loss: 37418.8242\n",
      "Epoch 951/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 46510.6640 - val_loss: 27806.8242\n",
      "Epoch 952/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30199.6487 - val_loss: 40750.3477\n",
      "Epoch 953/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 49636.0190 - val_loss: 29724.9395\n",
      "Epoch 954/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39812.2063 - val_loss: 27365.3379\n",
      "Epoch 955/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33875.3473 - val_loss: 30358.3340\n",
      "Epoch 956/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32796.4183 - val_loss: 41015.9414\n",
      "Epoch 957/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 44126.6139 - val_loss: 42923.7539\n",
      "Epoch 958/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 49711.7676 - val_loss: 41210.0117\n",
      "Epoch 959/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39119.2139 - val_loss: 44886.6758\n",
      "Epoch 960/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 54187.6915 - val_loss: 38150.8594\n",
      "Epoch 961/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38120.7490 - val_loss: 55566.8125\n",
      "Epoch 962/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 47110.7945 - val_loss: 46915.6953\n",
      "Epoch 963/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 48719.5447 - val_loss: 48243.2500\n",
      "Epoch 964/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 53944.9973 - val_loss: 35338.7930\n",
      "Epoch 965/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 45775.1980 - val_loss: 32530.2500\n",
      "Epoch 966/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37164.6335 - val_loss: 38897.3828\n",
      "Epoch 967/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 44829.3633 - val_loss: 36099.3086\n",
      "Epoch 968/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41503.1762 - val_loss: 33968.6562\n",
      "Epoch 969/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 42383.2032 - val_loss: 30438.7422\n",
      "Epoch 970/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35813.5122 - val_loss: 32294.5762\n",
      "Epoch 971/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36160.1261 - val_loss: 37882.5703\n",
      "Epoch 972/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 44390.0602 - val_loss: 22177.2012\n",
      "Epoch 973/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 27946.6848 - val_loss: 27815.5957\n",
      "Epoch 974/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 33949.8397 - val_loss: 30695.9766\n",
      "Epoch 975/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 33675.0750 - val_loss: 40420.4766\n",
      "Epoch 976/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 44427.3453 - val_loss: 38591.7734\n",
      "Epoch 977/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39886.0836 - val_loss: 49771.8203\n",
      "Epoch 978/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 48840.5185 - val_loss: 48288.4414\n",
      "Epoch 979/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 48897.6516 - val_loss: 42184.4297\n",
      "Epoch 980/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 45176.2088 - val_loss: 40855.2305\n",
      "Epoch 981/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 52049.1917 - val_loss: 28733.6836\n",
      "Epoch 982/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36490.1111 - val_loss: 33194.2383\n",
      "Epoch 983/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38531.8213 - val_loss: 36641.3438\n",
      "Epoch 984/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 45674.7843 - val_loss: 30611.1172\n",
      "Epoch 985/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 41409.3127 - val_loss: 22939.4902\n",
      "Epoch 986/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31865.5009 - val_loss: 23799.0684\n",
      "Epoch 987/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 34298.0757 - val_loss: 24357.3691\n",
      "Epoch 988/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 29932.8069 - val_loss: 24232.7285\n",
      "Epoch 989/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37537.7364 - val_loss: 19276.0156\n",
      "Epoch 990/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 27551.6263 - val_loss: 27578.5195\n",
      "Epoch 991/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31442.5705 - val_loss: 36806.2188\n",
      "Epoch 992/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 43445.6447 - val_loss: 27325.9395\n",
      "Epoch 993/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31360.9229 - val_loss: 33974.9297\n",
      "Epoch 994/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 45564.7985 - val_loss: 26342.0938\n",
      "Epoch 995/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32762.2557 - val_loss: 27309.3574\n",
      "Epoch 996/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 35250.7058 - val_loss: 21805.0312\n",
      "Epoch 997/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 30595.7487 - val_loss: 25595.9316\n",
      "Epoch 998/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33945.6274 - val_loss: 29310.7480\n",
      "Epoch 999/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35692.1399 - val_loss: 32358.1699\n",
      "Epoch 1000/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39748.2128 - val_loss: 25388.8613\n",
      "Epoch 1001/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33790.5725 - val_loss: 29408.4336\n",
      "Epoch 1002/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32200.6461 - val_loss: 39055.6836\n",
      "Epoch 1003/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 45415.9934 - val_loss: 27636.8906\n",
      "Epoch 1004/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31462.8547 - val_loss: 24762.5664\n",
      "Epoch 1005/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 28692.8604 - val_loss: 27601.5527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1006/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 33761.9288 - val_loss: 30344.9844\n",
      "Epoch 1007/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 39138.6529 - val_loss: 40530.3906\n",
      "Epoch 1008/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 46365.0133 - val_loss: 43432.7539\n",
      "Epoch 1009/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 42760.5540 - val_loss: 45372.0000\n",
      "Epoch 1010/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 48178.9090 - val_loss: 47045.0977\n",
      "Epoch 1011/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 56444.5780 - val_loss: 35460.1523\n",
      "Epoch 1012/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 43972.4251 - val_loss: 38109.3828\n",
      "Epoch 1013/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42507.7476 - val_loss: 40200.8750\n",
      "Epoch 1014/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 46409.9286 - val_loss: 36223.4180\n",
      "Epoch 1015/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 44445.6296 - val_loss: 24584.4492\n",
      "Epoch 1016/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35158.0874 - val_loss: 25232.3125\n",
      "Epoch 1017/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 31302.3373 - val_loss: 35864.6172\n",
      "Epoch 1018/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38453.9545 - val_loss: 46107.6250\n",
      "Epoch 1019/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 52023.7283 - val_loss: 28564.4258\n",
      "Epoch 1020/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39490.0633 - val_loss: 25932.7930\n",
      "Epoch 1021/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 29060.1566 - val_loss: 39822.5273\n",
      "Epoch 1022/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 44383.6599 - val_loss: 30983.9570\n",
      "Epoch 1023/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38387.7756 - val_loss: 24788.5938\n",
      "Epoch 1024/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 29499.0967 - val_loss: 27998.3672\n",
      "Epoch 1025/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37291.6012 - val_loss: 29693.2422\n",
      "Epoch 1026/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36484.3138 - val_loss: 39345.4570\n",
      "Epoch 1027/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 48083.1953 - val_loss: 36990.2188\n",
      "Epoch 1028/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 48771.9767 - val_loss: 28594.1953\n",
      "Epoch 1029/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36961.4542 - val_loss: 32702.5469\n",
      "Epoch 1030/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37632.7595 - val_loss: 32523.0469\n",
      "Epoch 1031/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41824.5633 - val_loss: 31653.1133\n",
      "Epoch 1032/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42242.5746 - val_loss: 24441.7852\n",
      "Epoch 1033/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 27027.3947 - val_loss: 36989.8398\n",
      "Epoch 1034/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 48433.8293 - val_loss: 22022.5898\n",
      "Epoch 1035/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30100.5358 - val_loss: 17761.3047\n",
      "Epoch 1036/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 26694.3983 - val_loss: 20136.7988\n",
      "Epoch 1037/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 23831.0118 - val_loss: 33374.7344\n",
      "Epoch 1038/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 38192.9808 - val_loss: 38564.0703\n",
      "Epoch 1039/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 43173.7984 - val_loss: 37716.8125\n",
      "Epoch 1040/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38495.2104 - val_loss: 39591.3672\n",
      "Epoch 1041/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 46575.9623 - val_loss: 24919.0703\n",
      "Epoch 1042/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 27560.8774 - val_loss: 25151.4746\n",
      "Epoch 1043/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 31431.5491 - val_loss: 27397.1914\n",
      "Epoch 1044/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37383.4205 - val_loss: 21735.4121\n",
      "Epoch 1045/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 26788.0843 - val_loss: 23920.0469\n",
      "Epoch 1046/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 28421.9444 - val_loss: 25545.0430\n",
      "Epoch 1047/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 28711.6716 - val_loss: 28342.8750\n",
      "Epoch 1048/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32465.3983 - val_loss: 30489.3203\n",
      "Epoch 1049/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 38851.7844 - val_loss: 25913.0508\n",
      "Epoch 1050/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 32391.6929 - val_loss: 28006.9395\n",
      "Epoch 1051/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34808.6422 - val_loss: 19949.8008\n",
      "Epoch 1052/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32154.6614 - val_loss: 19741.6387\n",
      "Epoch 1053/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 26735.2828 - val_loss: 27621.0234\n",
      "Epoch 1054/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 37607.6389 - val_loss: 21165.1289\n",
      "Epoch 1055/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 27380.8115 - val_loss: 28523.7930\n",
      "Epoch 1056/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31438.9859 - val_loss: 29675.6211\n",
      "Epoch 1057/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 32914.6256 - val_loss: 31891.2305\n",
      "Epoch 1058/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 36765.5720 - val_loss: 40774.1289\n",
      "Epoch 1059/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 43932.8763 - val_loss: 40087.8398\n",
      "Epoch 1060/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 44282.8227 - val_loss: 33404.3984\n",
      "Epoch 1061/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42848.3992 - val_loss: 27196.0820\n",
      "Epoch 1062/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 31451.6458 - val_loss: 29639.7480\n",
      "Epoch 1063/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36668.7722 - val_loss: 29227.4395\n",
      "Epoch 1064/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31263.7084 - val_loss: 36798.8203\n",
      "Epoch 1065/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 43926.8926 - val_loss: 27889.6367\n",
      "Epoch 1066/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33505.1295 - val_loss: 33554.4062\n",
      "Epoch 1067/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 45753.1294 - val_loss: 27714.5625\n",
      "Epoch 1068/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36958.3924 - val_loss: 21003.8594\n",
      "Epoch 1069/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 26031.3659 - val_loss: 26421.1758\n",
      "Epoch 1070/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33451.7763 - val_loss: 23297.4805\n",
      "Epoch 1071/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 28389.4682 - val_loss: 26341.6289\n",
      "Epoch 1072/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32432.6718 - val_loss: 29959.9531\n",
      "Epoch 1073/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36527.4573 - val_loss: 28487.2305\n",
      "Epoch 1074/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 33826.3592 - val_loss: 25379.2734\n",
      "Epoch 1075/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32520.0895 - val_loss: 24931.7246\n",
      "Epoch 1076/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32608.6598 - val_loss: 30561.0977\n",
      "Epoch 1077/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800/2800 [==============================] - 0s 7us/step - loss: 32654.8199 - val_loss: 37075.8906\n",
      "Epoch 1078/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 43234.6678 - val_loss: 35923.4805\n",
      "Epoch 1079/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 38376.6110 - val_loss: 30730.8496\n",
      "Epoch 1080/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31477.3670 - val_loss: 44770.5781\n",
      "Epoch 1081/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 45715.7081 - val_loss: 39786.8594\n",
      "Epoch 1082/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 45028.5677 - val_loss: 34676.4062\n",
      "Epoch 1083/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42360.9496 - val_loss: 34990.9414\n",
      "Epoch 1084/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38186.3190 - val_loss: 34507.2305\n",
      "Epoch 1085/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37794.0171 - val_loss: 23290.6289\n",
      "Epoch 1086/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 27833.2039 - val_loss: 30620.6895\n",
      "Epoch 1087/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35716.1705 - val_loss: 24320.1387\n",
      "Epoch 1088/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 27423.0896 - val_loss: 28003.9570\n",
      "Epoch 1089/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34016.3553 - val_loss: 28568.3477\n",
      "Epoch 1090/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 35266.1080 - val_loss: 31069.0742\n",
      "Epoch 1091/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 35604.2212 - val_loss: 27122.2988\n",
      "Epoch 1092/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 30535.9212 - val_loss: 33723.9531\n",
      "Epoch 1093/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 45680.3056 - val_loss: 23204.6992\n",
      "Epoch 1094/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 29795.1783 - val_loss: 23378.5117\n",
      "Epoch 1095/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 29163.1323 - val_loss: 33985.6836\n",
      "Epoch 1096/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 38402.1892 - val_loss: 32887.4375\n",
      "Epoch 1097/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 43043.2589 - val_loss: 28860.7051\n",
      "Epoch 1098/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 36534.6017 - val_loss: 26520.5254\n",
      "Epoch 1099/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32694.5076 - val_loss: 40657.5898\n",
      "Epoch 1100/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38437.4962 - val_loss: 41110.4180\n",
      "Epoch 1101/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 46589.7417 - val_loss: 37047.3516\n",
      "Epoch 1102/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 39792.7610 - val_loss: 31184.4219\n",
      "Epoch 1103/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36223.3128 - val_loss: 42859.1172\n",
      "Epoch 1104/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 47345.1188 - val_loss: 35917.4102\n",
      "Epoch 1105/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 40699.1839 - val_loss: 33535.7812\n",
      "Epoch 1106/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 43122.6203 - val_loss: 22517.0098\n",
      "Epoch 1107/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30009.9006 - val_loss: 21111.5391\n",
      "Epoch 1108/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 28380.8007 - val_loss: 26780.3789\n",
      "Epoch 1109/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33564.8504 - val_loss: 31494.0859\n",
      "Epoch 1110/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 33922.8460 - val_loss: 41828.8438\n",
      "Epoch 1111/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 50217.3812 - val_loss: 35630.4766\n",
      "Epoch 1112/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37759.0627 - val_loss: 38493.6523\n",
      "Epoch 1113/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36440.0726 - val_loss: 40109.2578\n",
      "Epoch 1114/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 42888.2118 - val_loss: 35724.5703\n",
      "Epoch 1115/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40345.0671 - val_loss: 31722.0879\n",
      "Epoch 1116/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 36066.1979 - val_loss: 32718.4336\n",
      "Epoch 1117/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37298.8619 - val_loss: 22109.1309\n",
      "Epoch 1118/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 26795.5649 - val_loss: 26591.4336\n",
      "Epoch 1119/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32580.2853 - val_loss: 25661.1680\n",
      "Epoch 1120/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 28411.9440 - val_loss: 33305.9219\n",
      "Epoch 1121/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38432.1336 - val_loss: 32778.9375\n",
      "Epoch 1122/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42063.7486 - val_loss: 26418.6836\n",
      "Epoch 1123/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 35952.3372 - val_loss: 28004.6445\n",
      "Epoch 1124/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 32433.8917 - val_loss: 34866.7422\n",
      "Epoch 1125/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39342.4990 - val_loss: 22566.1445\n",
      "Epoch 1126/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 29847.0621 - val_loss: 20930.8242\n",
      "Epoch 1127/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 29698.0079 - val_loss: 20240.3887\n",
      "Epoch 1128/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 24762.7095 - val_loss: 23084.4277\n",
      "Epoch 1129/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30322.9991 - val_loss: 31875.9805\n",
      "Epoch 1130/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 38444.4051 - val_loss: 30425.6191\n",
      "Epoch 1131/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 34605.2832 - val_loss: 38094.7461\n",
      "Epoch 1132/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 45037.3849 - val_loss: 36929.4062\n",
      "Epoch 1133/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 39252.1056 - val_loss: 41461.8047\n",
      "Epoch 1134/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 46348.7947 - val_loss: 37796.3672\n",
      "Epoch 1135/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 41079.3735 - val_loss: 40235.3672\n",
      "Epoch 1136/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38494.1944 - val_loss: 34230.7344\n",
      "Epoch 1137/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 39466.0361 - val_loss: 33997.8242\n",
      "Epoch 1138/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42951.9527 - val_loss: 21562.8945\n",
      "Epoch 1139/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 30337.2492 - val_loss: 20313.0859\n",
      "Epoch 1140/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 29573.3510 - val_loss: 18922.9297\n",
      "Epoch 1141/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 22749.9117 - val_loss: 27838.8652\n",
      "Epoch 1142/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 33858.3756 - val_loss: 28238.0430\n",
      "Epoch 1143/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 37677.9879 - val_loss: 27369.7852\n",
      "Epoch 1144/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 35835.9623 - val_loss: 20136.8418\n",
      "Epoch 1145/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 25291.0337 - val_loss: 22460.2578\n",
      "Epoch 1146/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 29211.8252 - val_loss: 31233.7773\n",
      "Epoch 1147/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35275.6008 - val_loss: 40622.6406\n",
      "Epoch 1148/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800/2800 [==============================] - 0s 7us/step - loss: 40037.8561 - val_loss: 42188.9414\n",
      "Epoch 1149/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 43155.0123 - val_loss: 34024.4297\n",
      "Epoch 1150/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38853.6764 - val_loss: 36991.5742\n",
      "Epoch 1151/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 44660.8428 - val_loss: 26490.4980\n",
      "Epoch 1152/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33159.3422 - val_loss: 28207.2598\n",
      "Epoch 1153/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37325.3779 - val_loss: 22611.1602\n",
      "Epoch 1154/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30914.3839 - val_loss: 22515.1016\n",
      "Epoch 1155/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 28711.9120 - val_loss: 27042.0859\n",
      "Epoch 1156/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31504.6908 - val_loss: 35678.7031\n",
      "Epoch 1157/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34695.5258 - val_loss: 44389.8281\n",
      "Epoch 1158/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 44545.5696 - val_loss: 37761.6133\n",
      "Epoch 1159/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42712.1740 - val_loss: 29885.3984\n",
      "Epoch 1160/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 31602.0259 - val_loss: 31058.8574\n",
      "Epoch 1161/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 33728.2166 - val_loss: 27739.3125\n",
      "Epoch 1162/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32274.1186 - val_loss: 34376.4492\n",
      "Epoch 1163/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35011.1326 - val_loss: 42087.7500\n",
      "Epoch 1164/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41920.5368 - val_loss: 25238.7168\n",
      "Epoch 1165/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 30607.2894 - val_loss: 27048.6074\n",
      "Epoch 1166/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33967.3605 - val_loss: 26051.0078\n",
      "Epoch 1167/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33461.7990 - val_loss: 28974.8164\n",
      "Epoch 1168/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35127.7274 - val_loss: 26779.3828\n",
      "Epoch 1169/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30248.0072 - val_loss: 34066.0117\n",
      "Epoch 1170/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 38352.1646 - val_loss: 37628.6016\n",
      "Epoch 1171/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38311.7157 - val_loss: 33061.9336\n",
      "Epoch 1172/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 45014.2914 - val_loss: 24913.7051\n",
      "Epoch 1173/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 29988.6315 - val_loss: 26699.4473\n",
      "Epoch 1174/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32925.8621 - val_loss: 27061.6191\n",
      "Epoch 1175/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 30103.0944 - val_loss: 23048.3164\n",
      "Epoch 1176/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 26074.6148 - val_loss: 31813.7344\n",
      "Epoch 1177/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37287.2539 - val_loss: 24227.4355\n",
      "Epoch 1178/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 29180.5963 - val_loss: 30295.9219\n",
      "Epoch 1179/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34299.0870 - val_loss: 27441.2422\n",
      "Epoch 1180/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 35288.3987 - val_loss: 28921.2441\n",
      "Epoch 1181/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 34233.7249 - val_loss: 30726.7656\n",
      "Epoch 1182/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40084.8407 - val_loss: 26169.9824\n",
      "Epoch 1183/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 31175.0575 - val_loss: 33132.8984\n",
      "Epoch 1184/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 38958.0051 - val_loss: 29711.9375\n",
      "Epoch 1185/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35402.3229 - val_loss: 23897.3281\n",
      "Epoch 1186/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 32799.8384 - val_loss: 30878.4375\n",
      "Epoch 1187/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33594.9788 - val_loss: 43828.4336\n",
      "Epoch 1188/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 45888.3268 - val_loss: 36004.0195\n",
      "Epoch 1189/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38604.9374 - val_loss: 38266.3281\n",
      "Epoch 1190/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 45822.2409 - val_loss: 23746.2637\n",
      "Epoch 1191/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 28551.7770 - val_loss: 28019.3047\n",
      "Epoch 1192/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31801.5868 - val_loss: 33796.1211\n",
      "Epoch 1193/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42297.0967 - val_loss: 22623.2871\n",
      "Epoch 1194/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 29567.5753 - val_loss: 25305.5938\n",
      "Epoch 1195/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31732.3292 - val_loss: 24265.6621\n",
      "Epoch 1196/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 27871.3828 - val_loss: 34004.4023\n",
      "Epoch 1197/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39161.4835 - val_loss: 27842.2910\n",
      "Epoch 1198/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35230.6565 - val_loss: 28584.1758\n",
      "Epoch 1199/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35602.3833 - val_loss: 28466.4512\n",
      "Epoch 1200/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35233.8778 - val_loss: 30333.8262\n",
      "Epoch 1201/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33596.5191 - val_loss: 32406.8555\n",
      "Epoch 1202/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 38013.3873 - val_loss: 29880.8984\n",
      "Epoch 1203/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32021.6054 - val_loss: 39787.3633\n",
      "Epoch 1204/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 45921.8211 - val_loss: 33645.5039\n",
      "Epoch 1205/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 43857.9754 - val_loss: 24474.2812\n",
      "Epoch 1206/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 28572.3518 - val_loss: 31508.2695\n",
      "Epoch 1207/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 36833.5788 - val_loss: 31118.9512\n",
      "Epoch 1208/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 35095.9636 - val_loss: 32668.0566\n",
      "Epoch 1209/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 35951.8056 - val_loss: 31833.1387\n",
      "Epoch 1210/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35775.3714 - val_loss: 33772.7227\n",
      "Epoch 1211/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37070.6085 - val_loss: 44202.0469\n",
      "Epoch 1212/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 49524.6894 - val_loss: 36504.7266\n",
      "Epoch 1213/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39657.2895 - val_loss: 35469.1367\n",
      "Epoch 1214/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37575.1917 - val_loss: 36972.0703\n",
      "Epoch 1215/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42880.3420 - val_loss: 31055.1328\n",
      "Epoch 1216/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 35553.0183 - val_loss: 39866.8516\n",
      "Epoch 1217/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 46815.0505 - val_loss: 34553.1094\n",
      "Epoch 1218/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 48100.8128 - val_loss: 20237.2188\n",
      "Epoch 1219/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800/2800 [==============================] - 0s 8us/step - loss: 25549.6813 - val_loss: 26116.5195\n",
      "Epoch 1220/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34836.1667 - val_loss: 25004.7676\n",
      "Epoch 1221/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 30423.6671 - val_loss: 26366.1562\n",
      "Epoch 1222/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 26840.9776 - val_loss: 35744.6953\n",
      "Epoch 1223/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37244.8257 - val_loss: 31464.6016\n",
      "Epoch 1224/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39301.3831 - val_loss: 25453.2520\n",
      "Epoch 1225/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32096.7524 - val_loss: 24692.8379\n",
      "Epoch 1226/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 26987.4583 - val_loss: 30838.1172\n",
      "Epoch 1227/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30101.9709 - val_loss: 39585.0391\n",
      "Epoch 1228/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41620.0111 - val_loss: 35461.8359\n",
      "Epoch 1229/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 37790.3897 - val_loss: 39889.5508\n",
      "Epoch 1230/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42747.7499 - val_loss: 32144.5508\n",
      "Epoch 1231/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37185.3414 - val_loss: 32048.8047\n",
      "Epoch 1232/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 39162.4215 - val_loss: 25467.5449\n",
      "Epoch 1233/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 28918.2838 - val_loss: 33163.9102\n",
      "Epoch 1234/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 37445.5744 - val_loss: 24022.1094\n",
      "Epoch 1235/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33291.5710 - val_loss: 19808.0586\n",
      "Epoch 1236/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 25740.9762 - val_loss: 24536.3828\n",
      "Epoch 1237/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 29875.6935 - val_loss: 31141.3633\n",
      "Epoch 1238/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33340.6154 - val_loss: 34697.0039\n",
      "Epoch 1239/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40972.1743 - val_loss: 22453.7500\n",
      "Epoch 1240/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 25584.6558 - val_loss: 28018.9023\n",
      "Epoch 1241/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34537.3204 - val_loss: 30784.6641\n",
      "Epoch 1242/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 35081.2216 - val_loss: 31585.1973\n",
      "Epoch 1243/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33356.9699 - val_loss: 33957.5039\n",
      "Epoch 1244/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33033.6823 - val_loss: 46444.6875\n",
      "Epoch 1245/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 47687.2192 - val_loss: 35724.7422\n",
      "Epoch 1246/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 37765.6769 - val_loss: 34481.4922\n",
      "Epoch 1247/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 38066.6083 - val_loss: 29933.0469\n",
      "Epoch 1248/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33011.1878 - val_loss: 24726.2168\n",
      "Epoch 1249/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30415.8380 - val_loss: 31657.3164\n",
      "Epoch 1250/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35022.2337 - val_loss: 31614.5586\n",
      "Epoch 1251/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38399.6212 - val_loss: 21382.7070\n",
      "Epoch 1252/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 26862.2001 - val_loss: 31639.1328\n",
      "Epoch 1253/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36425.5482 - val_loss: 32446.3945\n",
      "Epoch 1254/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 36520.3020 - val_loss: 31916.4258\n",
      "Epoch 1255/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32752.7146 - val_loss: 35262.3477\n",
      "Epoch 1256/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37098.3576 - val_loss: 38899.3477\n",
      "Epoch 1257/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 44606.8037 - val_loss: 32917.8008\n",
      "Epoch 1258/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 42041.5124 - val_loss: 30112.0586\n",
      "Epoch 1259/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33553.8622 - val_loss: 29103.7441\n",
      "Epoch 1260/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 31894.8285 - val_loss: 36812.1406\n",
      "Epoch 1261/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 43016.3283 - val_loss: 38060.1172\n",
      "Epoch 1262/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39047.4754 - val_loss: 35342.7578\n",
      "Epoch 1263/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 44336.2660 - val_loss: 30024.1699\n",
      "Epoch 1264/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33873.3825 - val_loss: 26125.1016\n",
      "Epoch 1265/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 28358.6620 - val_loss: 34516.6758\n",
      "Epoch 1266/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 48848.9096 - val_loss: 34360.3320\n",
      "Epoch 1267/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 43162.8639 - val_loss: 62898.2344\n",
      "Epoch 1268/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 61124.7472 - val_loss: 32804.7500\n",
      "Epoch 1269/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37501.4405 - val_loss: 30041.0332\n",
      "Epoch 1270/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 45440.8526 - val_loss: 35218.7383\n",
      "Epoch 1271/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40080.4414 - val_loss: 28493.4375\n",
      "Epoch 1272/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31229.4523 - val_loss: 32213.8809\n",
      "Epoch 1273/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37411.0798 - val_loss: 26060.2246\n",
      "Epoch 1274/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35369.0070 - val_loss: 23058.8203\n",
      "Epoch 1275/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 28292.4277 - val_loss: 25695.9707\n",
      "Epoch 1276/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 29243.9189 - val_loss: 38563.0859\n",
      "Epoch 1277/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 48726.8215 - val_loss: 36519.2383\n",
      "Epoch 1278/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 44184.4895 - val_loss: 32749.7422\n",
      "Epoch 1279/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37782.7725 - val_loss: 36736.8281\n",
      "Epoch 1280/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39238.4143 - val_loss: 34551.0156\n",
      "Epoch 1281/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 43893.0229 - val_loss: 20424.9043\n",
      "Epoch 1282/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 28806.5875 - val_loss: 25017.7090\n",
      "Epoch 1283/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 27426.3213 - val_loss: 24616.5078\n",
      "Epoch 1284/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 29605.0116 - val_loss: 25703.6055\n",
      "Epoch 1285/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32329.4774 - val_loss: 25300.6133\n",
      "Epoch 1286/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 28862.5187 - val_loss: 34176.7969\n",
      "Epoch 1287/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 44910.2754 - val_loss: 21493.9219\n",
      "Epoch 1288/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 30351.2425 - val_loss: 14239.9570\n",
      "Epoch 1289/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 19118.8471 - val_loss: 19358.1152\n",
      "Epoch 1290/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800/2800 [==============================] - 0s 9us/step - loss: 25696.7135 - val_loss: 20850.2969\n",
      "Epoch 1291/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 24590.2799 - val_loss: 26624.0430\n",
      "Epoch 1292/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 30391.3173 - val_loss: 29350.7773\n",
      "Epoch 1293/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33329.6273 - val_loss: 29053.3691\n",
      "Epoch 1294/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32719.1430 - val_loss: 32554.4570\n",
      "Epoch 1295/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 39099.2513 - val_loss: 24898.8066\n",
      "Epoch 1296/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30607.1705 - val_loss: 26933.0078\n",
      "Epoch 1297/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 30838.9973 - val_loss: 33275.2773\n",
      "Epoch 1298/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38120.8148 - val_loss: 29118.2559\n",
      "Epoch 1299/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33654.0184 - val_loss: 33272.4102\n",
      "Epoch 1300/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 37136.6173 - val_loss: 34297.1016\n",
      "Epoch 1301/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 41289.2298 - val_loss: 21098.2227\n",
      "Epoch 1302/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 26291.9759 - val_loss: 28241.4062\n",
      "Epoch 1303/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32932.6263 - val_loss: 32933.2383\n",
      "Epoch 1304/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41295.3091 - val_loss: 26596.8613\n",
      "Epoch 1305/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 32159.6222 - val_loss: 28547.8184\n",
      "Epoch 1306/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34374.5657 - val_loss: 33548.1602\n",
      "Epoch 1307/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38012.8260 - val_loss: 32916.1797\n",
      "Epoch 1308/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41014.1499 - val_loss: 25969.2949\n",
      "Epoch 1309/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32439.2314 - val_loss: 27034.6621\n",
      "Epoch 1310/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 32444.4156 - val_loss: 25479.7207\n",
      "Epoch 1311/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 30577.3250 - val_loss: 25934.1992\n",
      "Epoch 1312/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 28115.1214 - val_loss: 30680.9043\n",
      "Epoch 1313/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 30815.8667 - val_loss: 40531.4414\n",
      "Epoch 1314/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41057.9267 - val_loss: 34822.5508\n",
      "Epoch 1315/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40912.3361 - val_loss: 30927.3086\n",
      "Epoch 1316/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38820.3083 - val_loss: 24676.2305\n",
      "Epoch 1317/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 28650.3035 - val_loss: 26773.1270\n",
      "Epoch 1318/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31751.4900 - val_loss: 27359.1055\n",
      "Epoch 1319/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37171.0373 - val_loss: 27921.7891\n",
      "Epoch 1320/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34527.9476 - val_loss: 31361.1523\n",
      "Epoch 1321/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 35691.6648 - val_loss: 24928.6094\n",
      "Epoch 1322/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 30189.3886 - val_loss: 28667.4160\n",
      "Epoch 1323/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35754.4751 - val_loss: 26052.2227\n",
      "Epoch 1324/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 28970.2278 - val_loss: 25980.5391\n",
      "Epoch 1325/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 32868.0361 - val_loss: 29910.0898\n",
      "Epoch 1326/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 32476.8095 - val_loss: 37885.7812\n",
      "Epoch 1327/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 42125.2608 - val_loss: 40092.7617\n",
      "Epoch 1328/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 45313.4546 - val_loss: 33885.7578\n",
      "Epoch 1329/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 40730.9103 - val_loss: 34393.8672\n",
      "Epoch 1330/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40706.2919 - val_loss: 30856.1406\n",
      "Epoch 1331/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 41149.8921 - val_loss: 28669.2539\n",
      "Epoch 1332/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 36326.9911 - val_loss: 28740.8555\n",
      "Epoch 1333/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34290.4094 - val_loss: 33424.9062\n",
      "Epoch 1334/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 38423.4993 - val_loss: 31713.4434\n",
      "Epoch 1335/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37332.5511 - val_loss: 31769.3555\n",
      "Epoch 1336/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 38327.3691 - val_loss: 37077.4883\n",
      "Epoch 1337/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 42710.6674 - val_loss: 37718.1445\n",
      "Epoch 1338/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 48633.9446 - val_loss: 25318.8750\n",
      "Epoch 1339/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30300.0058 - val_loss: 28465.4199\n",
      "Epoch 1340/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35994.0316 - val_loss: 24825.2754\n",
      "Epoch 1341/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31995.0553 - val_loss: 25443.3984\n",
      "Epoch 1342/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 31506.3504 - val_loss: 27196.9355\n",
      "Epoch 1343/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33678.9862 - val_loss: 33072.7070\n",
      "Epoch 1344/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38461.9886 - val_loss: 29465.8125\n",
      "Epoch 1345/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34084.4162 - val_loss: 35045.4883\n",
      "Epoch 1346/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38504.4481 - val_loss: 39073.5703\n",
      "Epoch 1347/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 40274.5130 - val_loss: 35019.5195\n",
      "Epoch 1348/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 39025.0490 - val_loss: 30079.1016\n",
      "Epoch 1349/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37680.6475 - val_loss: 23819.6133\n",
      "Epoch 1350/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 31189.5909 - val_loss: 20612.7715\n",
      "Epoch 1351/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 27078.6893 - val_loss: 22870.2793\n",
      "Epoch 1352/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 32707.1228 - val_loss: 23205.4531\n",
      "Epoch 1353/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 29927.6622 - val_loss: 26040.5117\n",
      "Epoch 1354/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34600.1830 - val_loss: 28514.0156\n",
      "Epoch 1355/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 36824.0748 - val_loss: 27027.0898\n",
      "Epoch 1356/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36708.7530 - val_loss: 25073.7578\n",
      "Epoch 1357/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35303.9199 - val_loss: 24587.8809\n",
      "Epoch 1358/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 29347.8943 - val_loss: 30598.2188\n",
      "Epoch 1359/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32496.2420 - val_loss: 27379.8828\n",
      "Epoch 1360/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34696.5981 - val_loss: 28149.9141\n",
      "Epoch 1361/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800/2800 [==============================] - 0s 7us/step - loss: 31246.7730 - val_loss: 35975.5547\n",
      "Epoch 1362/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 45750.7543 - val_loss: 26903.9258\n",
      "Epoch 1363/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31479.3319 - val_loss: 33912.4023\n",
      "Epoch 1364/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34797.8061 - val_loss: 48596.5703\n",
      "Epoch 1365/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 49599.8004 - val_loss: 46191.2266\n",
      "Epoch 1366/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 48746.1465 - val_loss: 33952.1055\n",
      "Epoch 1367/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34707.4146 - val_loss: 39170.2500\n",
      "Epoch 1368/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40742.5691 - val_loss: 29585.2207\n",
      "Epoch 1369/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34977.3535 - val_loss: 30209.6426\n",
      "Epoch 1370/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34922.6753 - val_loss: 36414.2344\n",
      "Epoch 1371/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 46072.0591 - val_loss: 35073.9688\n",
      "Epoch 1372/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42136.6977 - val_loss: 36378.3672\n",
      "Epoch 1373/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40580.0364 - val_loss: 21007.2363\n",
      "Epoch 1374/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 29231.3449 - val_loss: 17197.9648\n",
      "Epoch 1375/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 24684.1143 - val_loss: 18940.8008\n",
      "Epoch 1376/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 24970.7042 - val_loss: 23062.4375\n",
      "Epoch 1377/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 27804.8614 - val_loss: 26457.2070\n",
      "Epoch 1378/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35032.7952 - val_loss: 26866.6055\n",
      "Epoch 1379/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 34378.6271 - val_loss: 25347.0156\n",
      "Epoch 1380/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33254.0642 - val_loss: 29204.7285\n",
      "Epoch 1381/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37212.4146 - val_loss: 25255.4336\n",
      "Epoch 1382/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 32464.2311 - val_loss: 33653.7812\n",
      "Epoch 1383/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35974.6650 - val_loss: 37879.7227\n",
      "Epoch 1384/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 47005.7920 - val_loss: 28862.8281\n",
      "Epoch 1385/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 31433.2510 - val_loss: 32841.4375\n",
      "Epoch 1386/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39301.5990 - val_loss: 37154.1602\n",
      "Epoch 1387/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 39368.0487 - val_loss: 34903.8594\n",
      "Epoch 1388/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41124.3698 - val_loss: 26331.9980\n",
      "Epoch 1389/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 34299.3355 - val_loss: 29343.3438\n",
      "Epoch 1390/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 30048.5673 - val_loss: 37482.6328\n",
      "Epoch 1391/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 47450.5834 - val_loss: 26341.4922\n",
      "Epoch 1392/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31347.6125 - val_loss: 34073.9219\n",
      "Epoch 1393/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 41843.9576 - val_loss: 33093.3906\n",
      "Epoch 1394/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35391.0317 - val_loss: 38822.0586\n",
      "Epoch 1395/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 43722.4280 - val_loss: 32829.2695\n",
      "Epoch 1396/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35027.8644 - val_loss: 40968.2734\n",
      "Epoch 1397/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 45517.8146 - val_loss: 31360.2148\n",
      "Epoch 1398/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32287.8612 - val_loss: 38174.5273\n",
      "Epoch 1399/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39348.1201 - val_loss: 44507.1016\n",
      "Epoch 1400/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 49413.6064 - val_loss: 30452.0469\n",
      "Epoch 1401/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 38423.3139 - val_loss: 24126.6406\n",
      "Epoch 1402/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 25074.7301 - val_loss: 34298.9492\n",
      "Epoch 1403/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37064.2938 - val_loss: 40816.4531\n",
      "Epoch 1404/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 49186.5634 - val_loss: 26236.8555\n",
      "Epoch 1405/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 36093.0617 - val_loss: 18187.7246\n",
      "Epoch 1406/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 24809.2671 - val_loss: 23218.7969\n",
      "Epoch 1407/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 28823.3869 - val_loss: 24213.5605\n",
      "Epoch 1408/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 33183.2855 - val_loss: 23590.0293\n",
      "Epoch 1409/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 29196.4156 - val_loss: 26150.3750\n",
      "Epoch 1410/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 31998.5678 - val_loss: 30607.2539\n",
      "Epoch 1411/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 34980.8664 - val_loss: 36035.9062\n",
      "Epoch 1412/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42800.8447 - val_loss: 29350.3477\n",
      "Epoch 1413/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35706.9561 - val_loss: 25260.4922\n",
      "Epoch 1414/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 30736.4910 - val_loss: 31068.3789\n",
      "Epoch 1415/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 40328.1723 - val_loss: 29318.0527\n",
      "Epoch 1416/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 39060.8633 - val_loss: 19277.7520\n",
      "Epoch 1417/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 26987.4384 - val_loss: 23162.7441\n",
      "Epoch 1418/2500\n",
      "2800/2800 [==============================] - 0s 10us/step - loss: 30481.7886 - val_loss: 23847.6914\n",
      "Epoch 1419/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 29580.1987 - val_loss: 27344.3711\n",
      "Epoch 1420/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 38345.0407 - val_loss: 21689.8320\n",
      "Epoch 1421/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 27017.3069 - val_loss: 27220.0352\n",
      "Epoch 1422/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30691.9574 - val_loss: 43542.7852\n",
      "Epoch 1423/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 53874.8665 - val_loss: 20976.3086\n",
      "Epoch 1424/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 27252.0648 - val_loss: 23551.1562\n",
      "Epoch 1425/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 26595.4090 - val_loss: 29580.9727\n",
      "Epoch 1426/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 31559.9776 - val_loss: 31969.3965\n",
      "Epoch 1427/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35730.0982 - val_loss: 33454.8516\n",
      "Epoch 1428/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39621.1235 - val_loss: 28537.8438\n",
      "Epoch 1429/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 33918.6053 - val_loss: 27776.4395\n",
      "Epoch 1430/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 27265.6653 - val_loss: 30581.9238\n",
      "Epoch 1431/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35484.6333 - val_loss: 24066.4355\n",
      "Epoch 1432/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800/2800 [==============================] - 0s 9us/step - loss: 28473.9651 - val_loss: 25211.7070\n",
      "Epoch 1433/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 27699.3746 - val_loss: 30655.5801\n",
      "Epoch 1434/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38692.3244 - val_loss: 30691.9688\n",
      "Epoch 1435/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32327.6630 - val_loss: 27233.0449\n",
      "Epoch 1436/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 32879.4446 - val_loss: 27421.3672\n",
      "Epoch 1437/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32652.3292 - val_loss: 40228.9922\n",
      "Epoch 1438/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 43830.1299 - val_loss: 28233.6582\n",
      "Epoch 1439/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34279.9912 - val_loss: 30595.7109\n",
      "Epoch 1440/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35947.0974 - val_loss: 26094.1074\n",
      "Epoch 1441/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31391.9859 - val_loss: 27640.2578\n",
      "Epoch 1442/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 33669.4896 - val_loss: 31251.1680\n",
      "Epoch 1443/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37468.8917 - val_loss: 23009.7969\n",
      "Epoch 1444/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30726.8906 - val_loss: 27464.4453\n",
      "Epoch 1445/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 31009.9814 - val_loss: 35388.6914\n",
      "Epoch 1446/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 37952.1241 - val_loss: 44143.9180\n",
      "Epoch 1447/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 47824.3168 - val_loss: 27304.3770\n",
      "Epoch 1448/2500\n",
      "2800/2800 [==============================] - 0s 10us/step - loss: 32536.3365 - val_loss: 27633.8867\n",
      "Epoch 1449/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32126.0899 - val_loss: 18001.3887\n",
      "Epoch 1450/2500\n",
      "2800/2800 [==============================] - 0s 10us/step - loss: 22797.5774 - val_loss: 26859.3867\n",
      "Epoch 1451/2500\n",
      "2800/2800 [==============================] - 0s 11us/step - loss: 37036.9252 - val_loss: 17980.9883\n",
      "Epoch 1452/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 24094.1119 - val_loss: 24865.0918\n",
      "Epoch 1453/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31664.6090 - val_loss: 29586.7969\n",
      "Epoch 1454/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31578.2616 - val_loss: 34932.6914\n",
      "Epoch 1455/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36423.9073 - val_loss: 31637.1914\n",
      "Epoch 1456/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38405.5822 - val_loss: 27976.0586\n",
      "Epoch 1457/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 28832.4492 - val_loss: 42341.6289\n",
      "Epoch 1458/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 43896.1774 - val_loss: 38217.7188\n",
      "Epoch 1459/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 43457.1125 - val_loss: 34591.8047\n",
      "Epoch 1460/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40371.6279 - val_loss: 24030.8125\n",
      "Epoch 1461/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 29225.9651 - val_loss: 31244.5000\n",
      "Epoch 1462/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34704.8718 - val_loss: 40297.0938\n",
      "Epoch 1463/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 46410.4822 - val_loss: 29107.5273\n",
      "Epoch 1464/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33339.2641 - val_loss: 29973.7227\n",
      "Epoch 1465/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33300.9455 - val_loss: 34764.0391\n",
      "Epoch 1466/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36820.5595 - val_loss: 43044.7266\n",
      "Epoch 1467/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 47375.5989 - val_loss: 40887.9883\n",
      "Epoch 1468/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 45769.7793 - val_loss: 36978.8320\n",
      "Epoch 1469/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 44042.6702 - val_loss: 32475.4102\n",
      "Epoch 1470/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39909.6275 - val_loss: 22773.1172\n",
      "Epoch 1471/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 29924.8184 - val_loss: 24299.4961\n",
      "Epoch 1472/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 30519.2466 - val_loss: 20864.6230\n",
      "Epoch 1473/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 25515.4749 - val_loss: 29382.0547\n",
      "Epoch 1474/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 42473.6558 - val_loss: 21493.3359\n",
      "Epoch 1475/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 27848.2379 - val_loss: 24934.9902\n",
      "Epoch 1476/2500\n",
      "2800/2800 [==============================] - 0s 10us/step - loss: 32414.1340 - val_loss: 23599.5625\n",
      "Epoch 1477/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 32127.6349 - val_loss: 25507.1660\n",
      "Epoch 1478/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 31791.8225 - val_loss: 40078.9961\n",
      "Epoch 1479/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 39327.5301 - val_loss: 34895.8594\n",
      "Epoch 1480/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 42297.9494 - val_loss: 31369.7305\n",
      "Epoch 1481/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37800.3910 - val_loss: 23476.4023\n",
      "Epoch 1482/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 28125.8599 - val_loss: 29085.2266\n",
      "Epoch 1483/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34115.2712 - val_loss: 36186.6406\n",
      "Epoch 1484/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36731.7922 - val_loss: 39103.0938\n",
      "Epoch 1485/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 45042.9943 - val_loss: 35922.1445\n",
      "Epoch 1486/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 43109.3324 - val_loss: 24326.7129\n",
      "Epoch 1487/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 31670.5094 - val_loss: 30671.3984\n",
      "Epoch 1488/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 29580.4702 - val_loss: 48882.0742\n",
      "Epoch 1489/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 52147.3339 - val_loss: 34013.8203\n",
      "Epoch 1490/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34477.0850 - val_loss: 43001.7148\n",
      "Epoch 1491/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 50842.0354 - val_loss: 28874.1016\n",
      "Epoch 1492/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 31039.7093 - val_loss: 31389.0898\n",
      "Epoch 1493/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 34740.9763 - val_loss: 34528.9492\n",
      "Epoch 1494/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 38117.2032 - val_loss: 35024.0000\n",
      "Epoch 1495/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 43694.4806 - val_loss: 25996.7695\n",
      "Epoch 1496/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 31026.0136 - val_loss: 30276.2695\n",
      "Epoch 1497/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 36087.3956 - val_loss: 31497.0918\n",
      "Epoch 1498/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34736.7488 - val_loss: 39285.7461\n",
      "Epoch 1499/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40433.8928 - val_loss: 37062.2461\n",
      "Epoch 1500/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 45338.0669 - val_loss: 29112.9688\n",
      "Epoch 1501/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34817.7544 - val_loss: 26898.7852\n",
      "Epoch 1502/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35068.8023 - val_loss: 30132.2734\n",
      "Epoch 1503/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800/2800 [==============================] - 0s 7us/step - loss: 36002.6724 - val_loss: 23088.1875\n",
      "Epoch 1504/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31300.3565 - val_loss: 25201.9805\n",
      "Epoch 1505/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 33366.9438 - val_loss: 28762.2949\n",
      "Epoch 1506/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 30445.2820 - val_loss: 31882.1270\n",
      "Epoch 1507/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 36090.2056 - val_loss: 37009.0703\n",
      "Epoch 1508/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 42051.3393 - val_loss: 31595.0293\n",
      "Epoch 1509/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 37823.8685 - val_loss: 31997.2734\n",
      "Epoch 1510/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 40288.4650 - val_loss: 22612.8320\n",
      "Epoch 1511/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31806.8713 - val_loss: 21018.2598\n",
      "Epoch 1512/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 26434.1446 - val_loss: 27708.3926\n",
      "Epoch 1513/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 29495.8535 - val_loss: 23811.9844\n",
      "Epoch 1514/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33657.6994 - val_loss: 19221.6914\n",
      "Epoch 1515/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 25295.8176 - val_loss: 25426.2930\n",
      "Epoch 1516/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 28826.1198 - val_loss: 38023.9180\n",
      "Epoch 1517/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41675.0912 - val_loss: 34463.4258\n",
      "Epoch 1518/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36412.7691 - val_loss: 42800.9570\n",
      "Epoch 1519/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 46498.4729 - val_loss: 28492.4336\n",
      "Epoch 1520/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30439.1742 - val_loss: 39747.4883\n",
      "Epoch 1521/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40713.0767 - val_loss: 40426.4805\n",
      "Epoch 1522/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 43380.2953 - val_loss: 36263.4492\n",
      "Epoch 1523/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40496.9340 - val_loss: 36259.9414\n",
      "Epoch 1524/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40611.7630 - val_loss: 38501.5234\n",
      "Epoch 1525/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 44945.9951 - val_loss: 27516.1406\n",
      "Epoch 1526/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 28231.9084 - val_loss: 33845.4180\n",
      "Epoch 1527/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33300.8023 - val_loss: 28338.1836\n",
      "Epoch 1528/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 29278.7705 - val_loss: 29366.7734\n",
      "Epoch 1529/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34501.7993 - val_loss: 25296.6328\n",
      "Epoch 1530/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30336.0977 - val_loss: 28848.2617\n",
      "Epoch 1531/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 35251.2781 - val_loss: 30059.0391\n",
      "Epoch 1532/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 33079.6164 - val_loss: 38764.5234\n",
      "Epoch 1533/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41619.1694 - val_loss: 30354.4688\n",
      "Epoch 1534/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 31112.3450 - val_loss: 31344.9434\n",
      "Epoch 1535/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 32318.3973 - val_loss: 39377.0938\n",
      "Epoch 1536/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38938.6134 - val_loss: 40263.7109\n",
      "Epoch 1537/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 46453.4326 - val_loss: 28510.7578\n",
      "Epoch 1538/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 33956.6831 - val_loss: 27170.9102\n",
      "Epoch 1539/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 32434.3801 - val_loss: 21781.7656\n",
      "Epoch 1540/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 24254.4756 - val_loss: 34347.4180\n",
      "Epoch 1541/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 37894.3848 - val_loss: 32425.1836\n",
      "Epoch 1542/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 34572.5811 - val_loss: 36444.2773\n",
      "Epoch 1543/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37272.2352 - val_loss: 32062.8418\n",
      "Epoch 1544/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36967.6658 - val_loss: 34186.6172\n",
      "Epoch 1545/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39778.4200 - val_loss: 30752.9805\n",
      "Epoch 1546/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36027.7886 - val_loss: 33313.0156\n",
      "Epoch 1547/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36404.8996 - val_loss: 39345.5625\n",
      "Epoch 1548/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 45929.0252 - val_loss: 28584.7246\n",
      "Epoch 1549/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 34466.3869 - val_loss: 33639.0039\n",
      "Epoch 1550/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39387.3385 - val_loss: 28840.3105\n",
      "Epoch 1551/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 33643.2092 - val_loss: 34495.9844\n",
      "Epoch 1552/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 37224.1865 - val_loss: 49261.6523\n",
      "Epoch 1553/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 55280.9266 - val_loss: 31740.6719\n",
      "Epoch 1554/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33278.1111 - val_loss: 40424.4180\n",
      "Epoch 1555/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42871.3133 - val_loss: 32885.1172\n",
      "Epoch 1556/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 39281.7806 - val_loss: 36651.0156\n",
      "Epoch 1557/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 41073.7544 - val_loss: 36204.6719\n",
      "Epoch 1558/2500\n",
      "2800/2800 [==============================] - 0s 10us/step - loss: 42342.9900 - val_loss: 31113.2012\n",
      "Epoch 1559/2500\n",
      "2800/2800 [==============================] - 0s 10us/step - loss: 33071.9592 - val_loss: 31445.1562\n",
      "Epoch 1560/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 36246.3140 - val_loss: 31065.9297\n",
      "Epoch 1561/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 39475.0632 - val_loss: 19228.9062\n",
      "Epoch 1562/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 27316.2314 - val_loss: 19601.8496\n",
      "Epoch 1563/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 25555.5931 - val_loss: 29676.6973\n",
      "Epoch 1564/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37272.2133 - val_loss: 26970.0840\n",
      "Epoch 1565/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32112.2457 - val_loss: 29260.5566\n",
      "Epoch 1566/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30862.0195 - val_loss: 38854.7188\n",
      "Epoch 1567/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40116.1194 - val_loss: 45037.2461\n",
      "Epoch 1568/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 51727.3499 - val_loss: 27499.5508\n",
      "Epoch 1569/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 30230.1414 - val_loss: 26661.2773\n",
      "Epoch 1570/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 29354.0155 - val_loss: 30007.3203\n",
      "Epoch 1571/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40236.1930 - val_loss: 23674.8047\n",
      "Epoch 1572/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 29545.9303 - val_loss: 30439.0293\n",
      "Epoch 1573/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34377.2040 - val_loss: 33228.3359\n",
      "Epoch 1574/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800/2800 [==============================] - 0s 7us/step - loss: 46808.2957 - val_loss: 17974.7148\n",
      "Epoch 1575/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 22352.2770 - val_loss: 15271.6416\n",
      "Epoch 1576/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 18186.3170 - val_loss: 24874.1211\n",
      "Epoch 1577/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 29728.2511 - val_loss: 26696.0000\n",
      "Epoch 1578/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 30604.1323 - val_loss: 24476.2070\n",
      "Epoch 1579/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30856.8443 - val_loss: 26005.3281\n",
      "Epoch 1580/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33082.2052 - val_loss: 25209.2207\n",
      "Epoch 1581/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 32996.9835 - val_loss: 21648.2188\n",
      "Epoch 1582/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 25707.1113 - val_loss: 28863.7148\n",
      "Epoch 1583/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 33515.7572 - val_loss: 32611.6406\n",
      "Epoch 1584/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 36624.9015 - val_loss: 29723.8809\n",
      "Epoch 1585/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36484.2980 - val_loss: 23358.8203\n",
      "Epoch 1586/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 28130.5398 - val_loss: 27484.4258\n",
      "Epoch 1587/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 32065.7189 - val_loss: 32691.8164\n",
      "Epoch 1588/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39959.0739 - val_loss: 24803.6777\n",
      "Epoch 1589/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 32552.4714 - val_loss: 26456.6621\n",
      "Epoch 1590/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34295.1109 - val_loss: 19861.1211\n",
      "Epoch 1591/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 27638.4344 - val_loss: 23646.9082\n",
      "Epoch 1592/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 27716.0082 - val_loss: 21980.4004\n",
      "Epoch 1593/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 28519.0380 - val_loss: 24493.7793\n",
      "Epoch 1594/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 29852.8985 - val_loss: 32654.7383\n",
      "Epoch 1595/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37326.1768 - val_loss: 36293.7539\n",
      "Epoch 1596/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 38262.2733 - val_loss: 35150.6211\n",
      "Epoch 1597/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 40532.8718 - val_loss: 28723.6914\n",
      "Epoch 1598/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 34342.7063 - val_loss: 35852.7812\n",
      "Epoch 1599/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 38799.2463 - val_loss: 29640.5098\n",
      "Epoch 1600/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 29154.2215 - val_loss: 34919.0000\n",
      "Epoch 1601/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 39136.7464 - val_loss: 35906.9375\n",
      "Epoch 1602/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36621.8343 - val_loss: 40439.1562\n",
      "Epoch 1603/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 38841.1388 - val_loss: 40318.9492\n",
      "Epoch 1604/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 46869.8843 - val_loss: 29459.1562\n",
      "Epoch 1605/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38107.7045 - val_loss: 31737.6699\n",
      "Epoch 1606/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34166.5646 - val_loss: 40943.8359\n",
      "Epoch 1607/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 53651.7839 - val_loss: 29610.5449\n",
      "Epoch 1608/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 38177.9618 - val_loss: 30465.4922\n",
      "Epoch 1609/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 29665.4752 - val_loss: 37480.9648\n",
      "Epoch 1610/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 41040.6300 - val_loss: 37079.0664\n",
      "Epoch 1611/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 41957.1970 - val_loss: 42470.9570\n",
      "Epoch 1612/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 49285.7333 - val_loss: 30043.7910\n",
      "Epoch 1613/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 33955.6200 - val_loss: 26502.1582\n",
      "Epoch 1614/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 32886.3885 - val_loss: 24418.7754\n",
      "Epoch 1615/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 27138.4880 - val_loss: 29572.8320\n",
      "Epoch 1616/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 38118.6104 - val_loss: 23850.4941\n",
      "Epoch 1617/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32881.4136 - val_loss: 23257.8867\n",
      "Epoch 1618/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 29595.5242 - val_loss: 23275.5879\n",
      "Epoch 1619/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 32199.8034 - val_loss: 22875.5703\n",
      "Epoch 1620/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 28727.9695 - val_loss: 25386.6172\n",
      "Epoch 1621/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33228.7386 - val_loss: 23152.3086\n",
      "Epoch 1622/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 27192.2677 - val_loss: 26459.0586\n",
      "Epoch 1623/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33077.9291 - val_loss: 25574.4531\n",
      "Epoch 1624/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 28775.8355 - val_loss: 37652.2109\n",
      "Epoch 1625/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 44505.2436 - val_loss: 29500.3047\n",
      "Epoch 1626/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 41045.0820 - val_loss: 22866.2344\n",
      "Epoch 1627/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 29547.6769 - val_loss: 23098.9082\n",
      "Epoch 1628/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 26731.3593 - val_loss: 28891.5234\n",
      "Epoch 1629/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 30952.1521 - val_loss: 36759.7148\n",
      "Epoch 1630/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39453.8830 - val_loss: 28485.5020\n",
      "Epoch 1631/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 36145.9800 - val_loss: 28758.2305\n",
      "Epoch 1632/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 29889.1273 - val_loss: 40345.8203\n",
      "Epoch 1633/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 46100.9944 - val_loss: 24992.9922\n",
      "Epoch 1634/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 29011.2119 - val_loss: 28269.8164\n",
      "Epoch 1635/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 36570.8563 - val_loss: 23952.8887\n",
      "Epoch 1636/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30372.8684 - val_loss: 24281.1680\n",
      "Epoch 1637/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 30112.3733 - val_loss: 23518.1562\n",
      "Epoch 1638/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 25143.7073 - val_loss: 27153.4492\n",
      "Epoch 1639/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 34946.7590 - val_loss: 23213.7578\n",
      "Epoch 1640/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 31073.4273 - val_loss: 23728.7793\n",
      "Epoch 1641/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 26690.5536 - val_loss: 31043.8652\n",
      "Epoch 1642/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 37971.6208 - val_loss: 32265.0547\n",
      "Epoch 1643/2500\n",
      "2800/2800 [==============================] - ETA: 0s - loss: 35469.218 - 0s 6us/step - loss: 37461.7438 - val_loss: 31318.9199\n",
      "Epoch 1644/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 43204.9084 - val_loss: 17909.1250\n",
      "Epoch 1645/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800/2800 [==============================] - 0s 7us/step - loss: 21873.5467 - val_loss: 24801.1328\n",
      "Epoch 1646/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 26396.8090 - val_loss: 34464.1797\n",
      "Epoch 1647/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40225.2896 - val_loss: 29704.6523\n",
      "Epoch 1648/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35688.9516 - val_loss: 24181.5039\n",
      "Epoch 1649/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30739.5514 - val_loss: 18382.6406\n",
      "Epoch 1650/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 25590.9278 - val_loss: 20730.2012\n",
      "Epoch 1651/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 26729.8325 - val_loss: 24234.1934\n",
      "Epoch 1652/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 29036.7330 - val_loss: 28468.0293\n",
      "Epoch 1653/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35637.3366 - val_loss: 27760.9453\n",
      "Epoch 1654/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33808.7603 - val_loss: 30306.1348\n",
      "Epoch 1655/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31878.9312 - val_loss: 35895.4023\n",
      "Epoch 1656/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 45835.3080 - val_loss: 24778.9082\n",
      "Epoch 1657/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 27790.3073 - val_loss: 23958.8477\n",
      "Epoch 1658/2500\n",
      "2800/2800 [==============================] - 0s 10us/step - loss: 31763.8298 - val_loss: 17265.1504\n",
      "Epoch 1659/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 24624.2242 - val_loss: 19603.6719\n",
      "Epoch 1660/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 25492.5931 - val_loss: 22601.1328\n",
      "Epoch 1661/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 27022.7840 - val_loss: 26683.2949\n",
      "Epoch 1662/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35479.4928 - val_loss: 21488.6992\n",
      "Epoch 1663/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 28224.8809 - val_loss: 24177.1836\n",
      "Epoch 1664/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 27289.7012 - val_loss: 30781.6172\n",
      "Epoch 1665/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33332.7062 - val_loss: 35410.4844\n",
      "Epoch 1666/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39281.7715 - val_loss: 28588.9629\n",
      "Epoch 1667/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33359.0235 - val_loss: 28015.9844\n",
      "Epoch 1668/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31754.3919 - val_loss: 24964.8281\n",
      "Epoch 1669/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 29351.8960 - val_loss: 32740.4609\n",
      "Epoch 1670/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 33709.6719 - val_loss: 35327.2695\n",
      "Epoch 1671/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39767.9725 - val_loss: 25320.1699\n",
      "Epoch 1672/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 28714.2610 - val_loss: 29028.4492\n",
      "Epoch 1673/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 38584.0623 - val_loss: 26900.5098\n",
      "Epoch 1674/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 33099.8100 - val_loss: 26541.4336\n",
      "Epoch 1675/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 33256.7603 - val_loss: 33793.2070\n",
      "Epoch 1676/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38011.3231 - val_loss: 28879.4688\n",
      "Epoch 1677/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 31128.3551 - val_loss: 37835.6250\n",
      "Epoch 1678/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 45428.0995 - val_loss: 26889.8926\n",
      "Epoch 1679/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 32044.1839 - val_loss: 30019.0781\n",
      "Epoch 1680/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 29166.5505 - val_loss: 33436.2383\n",
      "Epoch 1681/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37634.1347 - val_loss: 27534.2422\n",
      "Epoch 1682/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 34034.4347 - val_loss: 28757.7090\n",
      "Epoch 1683/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30114.1735 - val_loss: 32375.2520\n",
      "Epoch 1684/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 40732.0367 - val_loss: 28610.5820\n",
      "Epoch 1685/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 28913.2736 - val_loss: 36147.5547\n",
      "Epoch 1686/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34389.4328 - val_loss: 33731.1445\n",
      "Epoch 1687/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41550.7400 - val_loss: 26985.2500\n",
      "Epoch 1688/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35196.9588 - val_loss: 24201.3867\n",
      "Epoch 1689/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32513.8419 - val_loss: 27589.3535\n",
      "Epoch 1690/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35862.9576 - val_loss: 24088.5547\n",
      "Epoch 1691/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 28550.6755 - val_loss: 25987.3789\n",
      "Epoch 1692/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 32239.0425 - val_loss: 23321.2480\n",
      "Epoch 1693/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 28932.3762 - val_loss: 25810.3770\n",
      "Epoch 1694/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 32635.5371 - val_loss: 25596.7812\n",
      "Epoch 1695/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33114.5633 - val_loss: 31647.4297\n",
      "Epoch 1696/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 40666.7749 - val_loss: 27981.8477\n",
      "Epoch 1697/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 34535.9991 - val_loss: 30848.5859\n",
      "Epoch 1698/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36431.6640 - val_loss: 32976.2070\n",
      "Epoch 1699/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 37753.5374 - val_loss: 36700.2617\n",
      "Epoch 1700/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 44429.7543 - val_loss: 28486.2773\n",
      "Epoch 1701/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34296.0059 - val_loss: 33942.4062\n",
      "Epoch 1702/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38359.5261 - val_loss: 36411.8477\n",
      "Epoch 1703/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 47563.1566 - val_loss: 19239.4297\n",
      "Epoch 1704/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 28220.7107 - val_loss: 19683.3633\n",
      "Epoch 1705/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 26171.2968 - val_loss: 20935.5703\n",
      "Epoch 1706/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 29290.5309 - val_loss: 23461.0410\n",
      "Epoch 1707/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 28133.2195 - val_loss: 31229.8340\n",
      "Epoch 1708/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 36787.0523 - val_loss: 33941.5234\n",
      "Epoch 1709/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 39239.2880 - val_loss: 32617.5078\n",
      "Epoch 1710/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 40336.3996 - val_loss: 26927.1738\n",
      "Epoch 1711/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 32462.9783 - val_loss: 31312.4023\n",
      "Epoch 1712/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 41255.7630 - val_loss: 21088.9688\n",
      "Epoch 1713/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 27985.5413 - val_loss: 27473.2461\n",
      "Epoch 1714/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 32019.0179 - val_loss: 28669.5781\n",
      "Epoch 1715/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 34450.9064 - val_loss: 29280.2109\n",
      "Epoch 1716/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800/2800 [==============================] - 0s 7us/step - loss: 36339.9642 - val_loss: 35934.6016\n",
      "Epoch 1717/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41992.0016 - val_loss: 26173.5996\n",
      "Epoch 1718/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30042.5404 - val_loss: 32853.3789\n",
      "Epoch 1719/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41003.6733 - val_loss: 32725.2871\n",
      "Epoch 1720/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 44742.3408 - val_loss: 19670.0000\n",
      "Epoch 1721/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 27398.3084 - val_loss: 21392.8594\n",
      "Epoch 1722/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 26619.4908 - val_loss: 23673.2832\n",
      "Epoch 1723/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30719.9671 - val_loss: 34667.5938\n",
      "Epoch 1724/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37888.6711 - val_loss: 36443.3320\n",
      "Epoch 1725/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42998.1287 - val_loss: 30209.5801\n",
      "Epoch 1726/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 34693.0081 - val_loss: 33320.9297\n",
      "Epoch 1727/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38660.8993 - val_loss: 25095.0098\n",
      "Epoch 1728/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 30734.5927 - val_loss: 30502.0898\n",
      "Epoch 1729/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34521.2615 - val_loss: 36658.5078\n",
      "Epoch 1730/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 42506.3542 - val_loss: 29661.3320\n",
      "Epoch 1731/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33028.8975 - val_loss: 41540.4727\n",
      "Epoch 1732/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 42298.5892 - val_loss: 32084.7754\n",
      "Epoch 1733/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 38301.0866 - val_loss: 39222.8594\n",
      "Epoch 1734/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 43611.9123 - val_loss: 40038.0859\n",
      "Epoch 1735/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 38595.5440 - val_loss: 49517.2656\n",
      "Epoch 1736/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 46641.0964 - val_loss: 54154.9375\n",
      "Epoch 1737/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 52800.2227 - val_loss: 42679.7539\n",
      "Epoch 1738/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 43186.1940 - val_loss: 39229.8164\n",
      "Epoch 1739/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 44460.2513 - val_loss: 40979.0117\n",
      "Epoch 1740/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 38012.2397 - val_loss: 42183.8711\n",
      "Epoch 1741/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 41547.7977 - val_loss: 38858.8945\n",
      "Epoch 1742/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 44432.7712 - val_loss: 32770.7930\n",
      "Epoch 1743/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 29548.8040 - val_loss: 45800.9609\n",
      "Epoch 1744/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 50559.3456 - val_loss: 28322.4570\n",
      "Epoch 1745/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30987.6852 - val_loss: 33987.7383\n",
      "Epoch 1746/2500\n",
      "2800/2800 [==============================] - 0s 10us/step - loss: 37991.4354 - val_loss: 40814.9453\n",
      "Epoch 1747/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42085.4680 - val_loss: 37884.8906\n",
      "Epoch 1748/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40460.1986 - val_loss: 29694.2852\n",
      "Epoch 1749/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34576.1429 - val_loss: 33820.5938\n",
      "Epoch 1750/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35808.8856 - val_loss: 38074.2461\n",
      "Epoch 1751/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 37465.2277 - val_loss: 40557.4297\n",
      "Epoch 1752/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 41245.3168 - val_loss: 42708.6758\n",
      "Epoch 1753/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 47791.0225 - val_loss: 25053.7969\n",
      "Epoch 1754/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31221.0065 - val_loss: 26241.7344\n",
      "Epoch 1755/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31007.9585 - val_loss: 30788.5156\n",
      "Epoch 1756/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36457.5157 - val_loss: 30083.6426\n",
      "Epoch 1757/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35920.8829 - val_loss: 36732.5898\n",
      "Epoch 1758/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39734.6903 - val_loss: 32386.9609\n",
      "Epoch 1759/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 43428.6813 - val_loss: 20671.3984\n",
      "Epoch 1760/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 23804.9464 - val_loss: 30148.3281\n",
      "Epoch 1761/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37672.9652 - val_loss: 30202.6562\n",
      "Epoch 1762/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36536.8500 - val_loss: 30660.9297\n",
      "Epoch 1763/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 35271.5790 - val_loss: 34813.7422\n",
      "Epoch 1764/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34539.1497 - val_loss: 46706.1250\n",
      "Epoch 1765/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 51373.3954 - val_loss: 36286.8281\n",
      "Epoch 1766/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 40463.1575 - val_loss: 32703.5039\n",
      "Epoch 1767/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33271.9089 - val_loss: 41093.4961\n",
      "Epoch 1768/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41314.0804 - val_loss: 35209.6562\n",
      "Epoch 1769/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 35371.4868 - val_loss: 32507.3848\n",
      "Epoch 1770/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 35422.2417 - val_loss: 33317.3594\n",
      "Epoch 1771/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 40976.9773 - val_loss: 29781.5312\n",
      "Epoch 1772/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39609.7634 - val_loss: 25998.9414\n",
      "Epoch 1773/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 27109.2249 - val_loss: 36843.4062\n",
      "Epoch 1774/2500\n",
      "2800/2800 [==============================] - 0s 10us/step - loss: 45182.7726 - val_loss: 31903.4102\n",
      "Epoch 1775/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38533.7446 - val_loss: 27179.2734\n",
      "Epoch 1776/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32307.7684 - val_loss: 38155.4141\n",
      "Epoch 1777/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 42277.5521 - val_loss: 37900.6641\n",
      "Epoch 1778/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 44793.5556 - val_loss: 36323.1953\n",
      "Epoch 1779/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 36902.5024 - val_loss: 32144.7363\n",
      "Epoch 1780/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 33121.7511 - val_loss: 39153.9844\n",
      "Epoch 1781/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42801.6855 - val_loss: 32095.3340\n",
      "Epoch 1782/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31119.0608 - val_loss: 33464.3320\n",
      "Epoch 1783/2500\n",
      "2800/2800 [==============================] - 0s 10us/step - loss: 41137.0733 - val_loss: 28001.8379\n",
      "Epoch 1784/2500\n",
      "2800/2800 [==============================] - 0s 10us/step - loss: 31839.9316 - val_loss: 34736.7422\n",
      "Epoch 1785/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 44627.9135 - val_loss: 22568.8281\n",
      "Epoch 1786/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 27446.2998 - val_loss: 28055.8848\n",
      "Epoch 1787/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800/2800 [==============================] - 0s 8us/step - loss: 33693.8254 - val_loss: 32439.5957\n",
      "Epoch 1788/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 33681.6008 - val_loss: 35194.9570\n",
      "Epoch 1789/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41584.6127 - val_loss: 30699.9570\n",
      "Epoch 1790/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 33617.4948 - val_loss: 38931.9570\n",
      "Epoch 1791/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 43651.3718 - val_loss: 27479.4648\n",
      "Epoch 1792/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34592.7493 - val_loss: 16708.3926\n",
      "Epoch 1793/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 20105.6260 - val_loss: 21266.1328\n",
      "Epoch 1794/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 23701.5305 - val_loss: 33184.7500\n",
      "Epoch 1795/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 35486.5526 - val_loss: 45258.3242\n",
      "Epoch 1796/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 49280.0343 - val_loss: 33058.5586\n",
      "Epoch 1797/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 36259.5497 - val_loss: 35682.5156\n",
      "Epoch 1798/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40286.5129 - val_loss: 28907.7578\n",
      "Epoch 1799/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37279.8315 - val_loss: 23767.9492\n",
      "Epoch 1800/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 29686.4899 - val_loss: 26434.3672\n",
      "Epoch 1801/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33626.3087 - val_loss: 27740.2363\n",
      "Epoch 1802/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 29383.1105 - val_loss: 37920.5938\n",
      "Epoch 1803/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42377.3446 - val_loss: 29950.7402\n",
      "Epoch 1804/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 34491.3737 - val_loss: 28540.6445\n",
      "Epoch 1805/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 32576.5724 - val_loss: 33539.6094\n",
      "Epoch 1806/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34751.6867 - val_loss: 34595.9805\n",
      "Epoch 1807/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37050.0547 - val_loss: 41135.3828\n",
      "Epoch 1808/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40855.2966 - val_loss: 34724.0078\n",
      "Epoch 1809/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41692.3878 - val_loss: 31135.3379\n",
      "Epoch 1810/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 32802.8352 - val_loss: 32926.9258\n",
      "Epoch 1811/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31780.4110 - val_loss: 37063.1016\n",
      "Epoch 1812/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 38982.8358 - val_loss: 30858.5664\n",
      "Epoch 1813/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34669.2602 - val_loss: 26136.8828\n",
      "Epoch 1814/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30280.1851 - val_loss: 33445.2461\n",
      "Epoch 1815/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35733.2339 - val_loss: 36104.2227\n",
      "Epoch 1816/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41640.6392 - val_loss: 36343.5156\n",
      "Epoch 1817/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 44322.6787 - val_loss: 24885.4199\n",
      "Epoch 1818/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 35992.0919 - val_loss: 22268.5332\n",
      "Epoch 1819/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 25670.0847 - val_loss: 27728.3281\n",
      "Epoch 1820/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32085.6466 - val_loss: 29184.4824\n",
      "Epoch 1821/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36255.2647 - val_loss: 21184.7520\n",
      "Epoch 1822/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 26806.2840 - val_loss: 25546.3184\n",
      "Epoch 1823/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30594.4050 - val_loss: 29850.9727\n",
      "Epoch 1824/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 32872.9997 - val_loss: 22896.4727\n",
      "Epoch 1825/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 26155.7672 - val_loss: 33838.5703\n",
      "Epoch 1826/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40030.8731 - val_loss: 22557.9102\n",
      "Epoch 1827/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 27600.9606 - val_loss: 22656.8008\n",
      "Epoch 1828/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 28790.1049 - val_loss: 29804.7109\n",
      "Epoch 1829/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36033.5099 - val_loss: 31487.6074\n",
      "Epoch 1830/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37233.6180 - val_loss: 28141.6797\n",
      "Epoch 1831/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 30421.0782 - val_loss: 35849.7266\n",
      "Epoch 1832/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 39679.2935 - val_loss: 25856.6934\n",
      "Epoch 1833/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 31668.2790 - val_loss: 33036.7070\n",
      "Epoch 1834/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 43642.1019 - val_loss: 20366.8477\n",
      "Epoch 1835/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 25767.1320 - val_loss: 24747.3281\n",
      "Epoch 1836/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 31954.2456 - val_loss: 24914.9395\n",
      "Epoch 1837/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 33535.0974 - val_loss: 25566.9121\n",
      "Epoch 1838/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 27491.3194 - val_loss: 33859.1445\n",
      "Epoch 1839/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 43117.5814 - val_loss: 26209.1602\n",
      "Epoch 1840/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 27191.7064 - val_loss: 34906.3008\n",
      "Epoch 1841/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 34458.2637 - val_loss: 30126.1289\n",
      "Epoch 1842/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 36196.8205 - val_loss: 24257.9883\n",
      "Epoch 1843/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31471.5109 - val_loss: 30599.6855\n",
      "Epoch 1844/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37800.5074 - val_loss: 26466.1797\n",
      "Epoch 1845/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 29846.1041 - val_loss: 35921.9961\n",
      "Epoch 1846/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 39423.2876 - val_loss: 34988.4219\n",
      "Epoch 1847/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36836.7650 - val_loss: 36276.4297\n",
      "Epoch 1848/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31832.4470 - val_loss: 43283.0781\n",
      "Epoch 1849/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41357.7790 - val_loss: 36936.0156\n",
      "Epoch 1850/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 46848.6914 - val_loss: 23809.4102\n",
      "Epoch 1851/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 25626.8376 - val_loss: 35155.0781\n",
      "Epoch 1852/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40592.7593 - val_loss: 32965.6875\n",
      "Epoch 1853/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 35540.0461 - val_loss: 40308.6328\n",
      "Epoch 1854/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40325.7440 - val_loss: 37518.1797\n",
      "Epoch 1855/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38651.4752 - val_loss: 33593.9219\n",
      "Epoch 1856/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 39918.4830 - val_loss: 37255.0312\n",
      "Epoch 1857/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 45366.7090 - val_loss: 22518.7051\n",
      "Epoch 1858/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800/2800 [==============================] - 0s 8us/step - loss: 28943.3369 - val_loss: 24823.7344\n",
      "Epoch 1859/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34462.9536 - val_loss: 33038.3945\n",
      "Epoch 1860/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 38949.5640 - val_loss: 48202.3477\n",
      "Epoch 1861/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 51187.9591 - val_loss: 33965.5898\n",
      "Epoch 1862/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 35812.6892 - val_loss: 36606.6250\n",
      "Epoch 1863/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35465.1965 - val_loss: 39378.5859\n",
      "Epoch 1864/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41791.0233 - val_loss: 35352.5547\n",
      "Epoch 1865/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33891.8508 - val_loss: 37154.2734\n",
      "Epoch 1866/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 40653.8049 - val_loss: 30976.9316\n",
      "Epoch 1867/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 39289.1363 - val_loss: 24510.9102\n",
      "Epoch 1868/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 29864.1180 - val_loss: 30117.3086\n",
      "Epoch 1869/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 33615.3551 - val_loss: 29416.6445\n",
      "Epoch 1870/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 32782.1954 - val_loss: 32174.9668\n",
      "Epoch 1871/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 33509.9638 - val_loss: 43474.8164\n",
      "Epoch 1872/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 47011.6623 - val_loss: 34000.0938\n",
      "Epoch 1873/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 38835.2149 - val_loss: 26265.8984\n",
      "Epoch 1874/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32801.2348 - val_loss: 29028.7617\n",
      "Epoch 1875/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35474.8820 - val_loss: 27826.1074\n",
      "Epoch 1876/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32315.7517 - val_loss: 26346.3340\n",
      "Epoch 1877/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33245.5507 - val_loss: 22774.3828\n",
      "Epoch 1878/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 30557.8312 - val_loss: 24226.1465\n",
      "Epoch 1879/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 28251.2280 - val_loss: 28929.7246\n",
      "Epoch 1880/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30410.0760 - val_loss: 34753.1289\n",
      "Epoch 1881/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 44137.2963 - val_loss: 26201.4531\n",
      "Epoch 1882/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 32850.4170 - val_loss: 27064.6523\n",
      "Epoch 1883/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 29563.2976 - val_loss: 35387.5977\n",
      "Epoch 1884/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 40580.4187 - val_loss: 26174.9258\n",
      "Epoch 1885/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 31565.9288 - val_loss: 26492.4570\n",
      "Epoch 1886/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 33471.1406 - val_loss: 27159.6367\n",
      "Epoch 1887/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 32530.0349 - val_loss: 29979.5410\n",
      "Epoch 1888/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 37563.3159 - val_loss: 25398.2949\n",
      "Epoch 1889/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 29461.5920 - val_loss: 30399.3574\n",
      "Epoch 1890/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41300.5645 - val_loss: 18701.1816\n",
      "Epoch 1891/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 23475.7790 - val_loss: 29203.0879\n",
      "Epoch 1892/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 37014.6303 - val_loss: 22413.2930\n",
      "Epoch 1893/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 28841.5430 - val_loss: 24834.0254\n",
      "Epoch 1894/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 29656.6906 - val_loss: 27753.0703\n",
      "Epoch 1895/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 34010.1739 - val_loss: 34620.6523\n",
      "Epoch 1896/2500\n",
      "2800/2800 [==============================] - 0s 10us/step - loss: 41486.7605 - val_loss: 26662.5234\n",
      "Epoch 1897/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 28604.0447 - val_loss: 31349.8496\n",
      "Epoch 1898/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 33291.3873 - val_loss: 39716.7422\n",
      "Epoch 1899/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 40078.6539 - val_loss: 31884.5840\n",
      "Epoch 1900/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36515.7102 - val_loss: 24103.7715\n",
      "Epoch 1901/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 29209.6326 - val_loss: 33241.7070\n",
      "Epoch 1902/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38891.1526 - val_loss: 34200.9141\n",
      "Epoch 1903/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36456.7112 - val_loss: 42614.0859\n",
      "Epoch 1904/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 49409.4733 - val_loss: 33454.9883\n",
      "Epoch 1905/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38768.1148 - val_loss: 34186.6055\n",
      "Epoch 1906/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38702.1492 - val_loss: 33382.7031\n",
      "Epoch 1907/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 31992.2642 - val_loss: 30484.0703\n",
      "Epoch 1908/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 35933.4729 - val_loss: 30075.9141\n",
      "Epoch 1909/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32389.3315 - val_loss: 23250.4277\n",
      "Epoch 1910/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 26077.6874 - val_loss: 29939.7363\n",
      "Epoch 1911/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 34249.2644 - val_loss: 32737.7012\n",
      "Epoch 1912/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37419.2049 - val_loss: 32696.2109\n",
      "Epoch 1913/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 40716.0902 - val_loss: 30346.7480\n",
      "Epoch 1914/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33907.7326 - val_loss: 31035.8906\n",
      "Epoch 1915/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 40376.6066 - val_loss: 26626.6230\n",
      "Epoch 1916/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 33357.0757 - val_loss: 24665.2598\n",
      "Epoch 1917/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 28083.5555 - val_loss: 31131.1836\n",
      "Epoch 1918/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38337.0464 - val_loss: 26303.0938\n",
      "Epoch 1919/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30753.1643 - val_loss: 32971.8633\n",
      "Epoch 1920/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 37129.0167 - val_loss: 35044.3477\n",
      "Epoch 1921/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 33664.1232 - val_loss: 46940.0000\n",
      "Epoch 1922/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 49156.1552 - val_loss: 39929.6992\n",
      "Epoch 1923/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42915.0877 - val_loss: 49707.3711\n",
      "Epoch 1924/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 52030.7605 - val_loss: 46349.9141\n",
      "Epoch 1925/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 52958.1840 - val_loss: 39189.8125\n",
      "Epoch 1926/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38362.7828 - val_loss: 35498.3438\n",
      "Epoch 1927/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40524.1286 - val_loss: 25823.3633\n",
      "Epoch 1928/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 28868.4896 - val_loss: 30495.1387\n",
      "Epoch 1929/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800/2800 [==============================] - 0s 8us/step - loss: 35565.3320 - val_loss: 25992.4062\n",
      "Epoch 1930/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 31172.4261 - val_loss: 28143.9375\n",
      "Epoch 1931/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 31069.5813 - val_loss: 34304.4375\n",
      "Epoch 1932/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38506.8968 - val_loss: 22920.2246\n",
      "Epoch 1933/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 26107.2478 - val_loss: 31939.7754\n",
      "Epoch 1934/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32933.1358 - val_loss: 34497.0977\n",
      "Epoch 1935/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37447.7337 - val_loss: 27028.6934\n",
      "Epoch 1936/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 31030.8773 - val_loss: 21252.3086\n",
      "Epoch 1937/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 26108.5789 - val_loss: 23573.2734\n",
      "Epoch 1938/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 25775.4421 - val_loss: 37832.9453\n",
      "Epoch 1939/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39635.5734 - val_loss: 26313.4570\n",
      "Epoch 1940/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 31997.1401 - val_loss: 21036.1016\n",
      "Epoch 1941/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 28157.3294 - val_loss: 21037.5254\n",
      "Epoch 1942/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 22237.9004 - val_loss: 32100.4297\n",
      "Epoch 1943/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 30293.7779 - val_loss: 42215.3320\n",
      "Epoch 1944/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 42282.1484 - val_loss: 39612.7305\n",
      "Epoch 1945/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 41736.4259 - val_loss: 26767.5000\n",
      "Epoch 1946/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 31360.0041 - val_loss: 23511.4297\n",
      "Epoch 1947/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30309.7524 - val_loss: 28116.4473\n",
      "Epoch 1948/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37370.6569 - val_loss: 25365.2129\n",
      "Epoch 1949/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 31905.6661 - val_loss: 25264.7070\n",
      "Epoch 1950/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 31449.8643 - val_loss: 25990.4785\n",
      "Epoch 1951/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 32539.5030 - val_loss: 26449.8594\n",
      "Epoch 1952/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36525.2016 - val_loss: 20574.1074\n",
      "Epoch 1953/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 22117.6330 - val_loss: 28904.6543\n",
      "Epoch 1954/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36387.9405 - val_loss: 24570.8438\n",
      "Epoch 1955/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 27553.5853 - val_loss: 29456.6680\n",
      "Epoch 1956/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34737.0160 - val_loss: 32970.4688\n",
      "Epoch 1957/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34943.0769 - val_loss: 29089.7500\n",
      "Epoch 1958/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36715.7453 - val_loss: 24126.1191\n",
      "Epoch 1959/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31040.0104 - val_loss: 29811.5000\n",
      "Epoch 1960/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32733.3252 - val_loss: 27640.2969\n",
      "Epoch 1961/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32068.5776 - val_loss: 34194.5312\n",
      "Epoch 1962/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40436.3929 - val_loss: 33304.2539\n",
      "Epoch 1963/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38530.7407 - val_loss: 34204.2070\n",
      "Epoch 1964/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38212.2252 - val_loss: 29631.7246\n",
      "Epoch 1965/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30957.5788 - val_loss: 39622.6758\n",
      "Epoch 1966/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39865.6396 - val_loss: 44982.9258\n",
      "Epoch 1967/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 44716.9264 - val_loss: 34588.8750\n",
      "Epoch 1968/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34064.8056 - val_loss: 31190.0918\n",
      "Epoch 1969/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 35348.4270 - val_loss: 34525.4023\n",
      "Epoch 1970/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40080.1704 - val_loss: 32694.9766\n",
      "Epoch 1971/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38950.3741 - val_loss: 31391.6680\n",
      "Epoch 1972/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37806.2844 - val_loss: 30190.7324\n",
      "Epoch 1973/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36820.8481 - val_loss: 33374.1797\n",
      "Epoch 1974/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40665.5146 - val_loss: 27542.1367\n",
      "Epoch 1975/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35823.9747 - val_loss: 25221.8691\n",
      "Epoch 1976/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31529.1628 - val_loss: 24615.3809\n",
      "Epoch 1977/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 30341.5557 - val_loss: 27205.4805\n",
      "Epoch 1978/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 33496.2692 - val_loss: 29836.2188\n",
      "Epoch 1979/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33789.2616 - val_loss: 30199.2344\n",
      "Epoch 1980/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37309.6587 - val_loss: 31364.5996\n",
      "Epoch 1981/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40953.1408 - val_loss: 24790.8613\n",
      "Epoch 1982/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 27459.6427 - val_loss: 30130.3164\n",
      "Epoch 1983/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 33797.2334 - val_loss: 38638.6602\n",
      "Epoch 1984/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 42721.8411 - val_loss: 26047.3203\n",
      "Epoch 1985/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 29172.0972 - val_loss: 40274.3789\n",
      "Epoch 1986/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 43141.0587 - val_loss: 45413.9648\n",
      "Epoch 1987/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 46984.1232 - val_loss: 38438.4531\n",
      "Epoch 1988/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 37621.6612 - val_loss: 36443.9375\n",
      "Epoch 1989/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38253.3199 - val_loss: 31367.3008\n",
      "Epoch 1990/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35900.3549 - val_loss: 29808.4805\n",
      "Epoch 1991/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 37806.5685 - val_loss: 16708.1230\n",
      "Epoch 1992/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 21639.3924 - val_loss: 22906.6328\n",
      "Epoch 1993/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 29751.4948 - val_loss: 26555.5586\n",
      "Epoch 1994/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32761.0681 - val_loss: 36243.0781\n",
      "Epoch 1995/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38264.3131 - val_loss: 32040.2793\n",
      "Epoch 1996/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41491.4690 - val_loss: 23258.9082\n",
      "Epoch 1997/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 28357.8885 - val_loss: 29326.4492\n",
      "Epoch 1998/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 30581.7362 - val_loss: 39121.4062\n",
      "Epoch 1999/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 46846.5505 - val_loss: 23947.8496\n",
      "Epoch 2000/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800/2800 [==============================] - 0s 7us/step - loss: 26687.9485 - val_loss: 27407.2832\n",
      "Epoch 2001/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32174.1347 - val_loss: 24010.6836\n",
      "Epoch 2002/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 29969.1872 - val_loss: 23087.3281\n",
      "Epoch 2003/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 29549.7125 - val_loss: 26496.1699\n",
      "Epoch 2004/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 28895.4570 - val_loss: 33112.5312\n",
      "Epoch 2005/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33781.4430 - val_loss: 38150.4883\n",
      "Epoch 2006/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40771.4284 - val_loss: 27694.1191\n",
      "Epoch 2007/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 34064.4721 - val_loss: 23452.0918\n",
      "Epoch 2008/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30903.4767 - val_loss: 23115.9375\n",
      "Epoch 2009/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 28604.8592 - val_loss: 22516.7441\n",
      "Epoch 2010/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 27486.0466 - val_loss: 23904.2324\n",
      "Epoch 2011/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 27930.9820 - val_loss: 32431.7051\n",
      "Epoch 2012/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35572.8369 - val_loss: 28450.0254\n",
      "Epoch 2013/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34090.8917 - val_loss: 28290.5234\n",
      "Epoch 2014/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36598.7186 - val_loss: 25056.2227\n",
      "Epoch 2015/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30497.1196 - val_loss: 29363.9746\n",
      "Epoch 2016/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 40299.5079 - val_loss: 23081.5586\n",
      "Epoch 2017/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 27313.0735 - val_loss: 26854.0879\n",
      "Epoch 2018/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 31746.3427 - val_loss: 26772.7422\n",
      "Epoch 2019/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 28502.5199 - val_loss: 27766.8750\n",
      "Epoch 2020/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 28868.5447 - val_loss: 33630.9805\n",
      "Epoch 2021/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36235.9242 - val_loss: 29300.6758\n",
      "Epoch 2022/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35471.0733 - val_loss: 36023.2422\n",
      "Epoch 2023/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39545.0382 - val_loss: 42467.4609\n",
      "Epoch 2024/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 39385.2696 - val_loss: 42024.0391\n",
      "Epoch 2025/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 44467.7325 - val_loss: 35934.0430\n",
      "Epoch 2026/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 40853.3477 - val_loss: 36853.5078\n",
      "Epoch 2027/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 41291.2297 - val_loss: 37372.6445\n",
      "Epoch 2028/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41610.4469 - val_loss: 32988.0273\n",
      "Epoch 2029/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33976.1402 - val_loss: 31039.1992\n",
      "Epoch 2030/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34706.2252 - val_loss: 33743.1211\n",
      "Epoch 2031/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 38764.7509 - val_loss: 33076.8789\n",
      "Epoch 2032/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39287.2505 - val_loss: 34295.5820\n",
      "Epoch 2033/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 40827.3226 - val_loss: 29238.1562\n",
      "Epoch 2034/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 36823.0036 - val_loss: 37197.0664\n",
      "Epoch 2035/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40480.2971 - val_loss: 25850.1562\n",
      "Epoch 2036/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32597.5246 - val_loss: 32668.5293\n",
      "Epoch 2037/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 39902.9538 - val_loss: 37175.0273\n",
      "Epoch 2038/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 43406.5116 - val_loss: 34146.8047\n",
      "Epoch 2039/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32738.8675 - val_loss: 37463.0664\n",
      "Epoch 2040/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 39436.7364 - val_loss: 35867.2734\n",
      "Epoch 2041/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37423.0662 - val_loss: 35966.7656\n",
      "Epoch 2042/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40163.0645 - val_loss: 34444.3711\n",
      "Epoch 2043/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 41901.3871 - val_loss: 29763.7852\n",
      "Epoch 2044/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34283.9860 - val_loss: 37582.2852\n",
      "Epoch 2045/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40865.2072 - val_loss: 36854.7109\n",
      "Epoch 2046/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 43491.8137 - val_loss: 34782.5742\n",
      "Epoch 2047/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40138.7929 - val_loss: 37472.3438\n",
      "Epoch 2048/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 47157.1678 - val_loss: 27107.8281\n",
      "Epoch 2049/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33621.8909 - val_loss: 41171.1133\n",
      "Epoch 2050/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 45193.4730 - val_loss: 36567.3320\n",
      "Epoch 2051/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41808.1519 - val_loss: 39351.0938\n",
      "Epoch 2052/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 44951.6441 - val_loss: 37310.9141\n",
      "Epoch 2053/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41162.8419 - val_loss: 46606.8711\n",
      "Epoch 2054/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 52514.1703 - val_loss: 28742.7598\n",
      "Epoch 2055/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37069.5126 - val_loss: 33747.1758\n",
      "Epoch 2056/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42706.9290 - val_loss: 29469.8438\n",
      "Epoch 2057/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39526.0272 - val_loss: 31233.6211\n",
      "Epoch 2058/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36270.1022 - val_loss: 34687.4766\n",
      "Epoch 2059/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 44274.5122 - val_loss: 31034.4395\n",
      "Epoch 2060/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37364.6430 - val_loss: 36126.6484\n",
      "Epoch 2061/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 40798.3810 - val_loss: 41634.3242\n",
      "Epoch 2062/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 45677.3856 - val_loss: 39267.9141\n",
      "Epoch 2063/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 42809.4567 - val_loss: 35393.4453\n",
      "Epoch 2064/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37657.1568 - val_loss: 41014.7656\n",
      "Epoch 2065/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42859.3890 - val_loss: 50038.4297\n",
      "Epoch 2066/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 50485.7930 - val_loss: 57047.2031\n",
      "Epoch 2067/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 50526.2442 - val_loss: 54544.5781\n",
      "Epoch 2068/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 55469.2982 - val_loss: 52484.1406\n",
      "Epoch 2069/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 59276.7541 - val_loss: 43532.3047\n",
      "Epoch 2070/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 46832.1100 - val_loss: 45512.4180\n",
      "Epoch 2071/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800/2800 [==============================] - 0s 8us/step - loss: 45946.8665 - val_loss: 50297.8633\n",
      "Epoch 2072/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 54768.0223 - val_loss: 36542.3984\n",
      "Epoch 2073/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34909.9990 - val_loss: 40092.5430\n",
      "Epoch 2074/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 43861.1002 - val_loss: 40905.5430\n",
      "Epoch 2075/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 45941.1200 - val_loss: 37985.0352\n",
      "Epoch 2076/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 41945.0859 - val_loss: 40967.2773\n",
      "Epoch 2077/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 54319.7483 - val_loss: 29370.8086\n",
      "Epoch 2078/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39464.8402 - val_loss: 29497.7051\n",
      "Epoch 2079/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 37504.9054 - val_loss: 19658.6582\n",
      "Epoch 2080/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 26894.1937 - val_loss: 26045.6504\n",
      "Epoch 2081/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 29094.3200 - val_loss: 35428.8984\n",
      "Epoch 2082/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 41640.1571 - val_loss: 25025.6094\n",
      "Epoch 2083/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31929.4559 - val_loss: 27510.0527\n",
      "Epoch 2084/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33428.4429 - val_loss: 29294.6094\n",
      "Epoch 2085/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 36137.9719 - val_loss: 30237.7422\n",
      "Epoch 2086/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 30689.7806 - val_loss: 45967.5000\n",
      "Epoch 2087/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 48732.8625 - val_loss: 38803.3555\n",
      "Epoch 2088/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42005.5153 - val_loss: 35905.0781\n",
      "Epoch 2089/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 43469.4582 - val_loss: 32593.9883\n",
      "Epoch 2090/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 38616.0545 - val_loss: 32705.1504\n",
      "Epoch 2091/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40900.9437 - val_loss: 33239.7461\n",
      "Epoch 2092/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 38924.9722 - val_loss: 28988.1953\n",
      "Epoch 2093/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35413.0846 - val_loss: 33352.2500\n",
      "Epoch 2094/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 42272.2019 - val_loss: 27205.1152\n",
      "Epoch 2095/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30632.7237 - val_loss: 36238.1641\n",
      "Epoch 2096/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 45837.4366 - val_loss: 29534.4141\n",
      "Epoch 2097/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 38760.8773 - val_loss: 29305.0332\n",
      "Epoch 2098/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39398.7103 - val_loss: 23555.2402\n",
      "Epoch 2099/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32452.3503 - val_loss: 26608.3301\n",
      "Epoch 2100/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 30381.9662 - val_loss: 34441.0000\n",
      "Epoch 2101/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41934.6431 - val_loss: 32232.5879\n",
      "Epoch 2102/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37951.9599 - val_loss: 34076.3164\n",
      "Epoch 2103/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40466.3619 - val_loss: 30981.5762\n",
      "Epoch 2104/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 43263.9384 - val_loss: 28386.6152\n",
      "Epoch 2105/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36157.4363 - val_loss: 21616.5020\n",
      "Epoch 2106/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 25770.7648 - val_loss: 30058.0703\n",
      "Epoch 2107/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37136.8430 - val_loss: 23050.8594\n",
      "Epoch 2108/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 29893.7440 - val_loss: 25474.2773\n",
      "Epoch 2109/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 28936.0938 - val_loss: 40252.9805\n",
      "Epoch 2110/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 45350.4170 - val_loss: 30462.0859\n",
      "Epoch 2111/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 38527.6841 - val_loss: 25995.7266\n",
      "Epoch 2112/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 31027.5398 - val_loss: 25368.3203\n",
      "Epoch 2113/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34555.2658 - val_loss: 25467.9023\n",
      "Epoch 2114/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31127.2872 - val_loss: 27003.9512\n",
      "Epoch 2115/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31928.3275 - val_loss: 25634.7559\n",
      "Epoch 2116/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34608.0780 - val_loss: 25485.5508\n",
      "Epoch 2117/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30625.1585 - val_loss: 33809.7578\n",
      "Epoch 2118/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 38234.9160 - val_loss: 31644.8750\n",
      "Epoch 2119/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35098.7058 - val_loss: 35732.6484\n",
      "Epoch 2120/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41381.4212 - val_loss: 35625.6641\n",
      "Epoch 2121/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 41476.9816 - val_loss: 41705.1992\n",
      "Epoch 2122/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 43449.1496 - val_loss: 31726.6465\n",
      "Epoch 2123/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 37335.0329 - val_loss: 32598.2480\n",
      "Epoch 2124/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36121.1447 - val_loss: 37393.9219\n",
      "Epoch 2125/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 44852.0397 - val_loss: 33493.7422\n",
      "Epoch 2126/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 37089.1657 - val_loss: 39638.9023\n",
      "Epoch 2127/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 48078.7447 - val_loss: 32729.1680\n",
      "Epoch 2128/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 39634.9165 - val_loss: 23212.4824\n",
      "Epoch 2129/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 27806.8813 - val_loss: 27357.3867\n",
      "Epoch 2130/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 33761.4679 - val_loss: 25054.6152\n",
      "Epoch 2131/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30130.3299 - val_loss: 34606.3477\n",
      "Epoch 2132/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 36759.0154 - val_loss: 34491.8711\n",
      "Epoch 2133/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 38872.1357 - val_loss: 31707.8594\n",
      "Epoch 2134/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 35225.5955 - val_loss: 32527.7461\n",
      "Epoch 2135/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 34963.5454 - val_loss: 43921.2539\n",
      "Epoch 2136/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 44859.0000 - val_loss: 44663.7734\n",
      "Epoch 2137/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 49857.7132 - val_loss: 36151.5156\n",
      "Epoch 2138/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37973.4444 - val_loss: 30763.1602\n",
      "Epoch 2139/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40572.8234 - val_loss: 24592.7148\n",
      "Epoch 2140/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31808.1070 - val_loss: 23070.1621\n",
      "Epoch 2141/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 30857.1928 - val_loss: 30856.2148\n",
      "Epoch 2142/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800/2800 [==============================] - 0s 7us/step - loss: 30970.1998 - val_loss: 29735.5039\n",
      "Epoch 2143/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38645.4835 - val_loss: 20135.0332\n",
      "Epoch 2144/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 26913.8430 - val_loss: 16235.6719\n",
      "Epoch 2145/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 22221.7890 - val_loss: 21892.9336\n",
      "Epoch 2146/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 29931.7220 - val_loss: 26050.7500\n",
      "Epoch 2147/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35059.1163 - val_loss: 23018.7793\n",
      "Epoch 2148/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30431.6831 - val_loss: 26229.7754\n",
      "Epoch 2149/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32728.2903 - val_loss: 24448.0703\n",
      "Epoch 2150/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31061.0757 - val_loss: 30796.1250\n",
      "Epoch 2151/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37825.1390 - val_loss: 33145.7422\n",
      "Epoch 2152/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 36269.1514 - val_loss: 37578.1094\n",
      "Epoch 2153/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38738.4498 - val_loss: 35234.9336\n",
      "Epoch 2154/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 36562.4456 - val_loss: 30044.9043\n",
      "Epoch 2155/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 35415.6183 - val_loss: 27566.2344\n",
      "Epoch 2156/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 31558.6619 - val_loss: 21525.9902\n",
      "Epoch 2157/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 26033.7421 - val_loss: 28207.7422\n",
      "Epoch 2158/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36108.8434 - val_loss: 29408.2676\n",
      "Epoch 2159/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 37087.2039 - val_loss: 31541.4980\n",
      "Epoch 2160/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 40527.7361 - val_loss: 25603.5527\n",
      "Epoch 2161/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 35636.3648 - val_loss: 23773.8906\n",
      "Epoch 2162/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 30024.2255 - val_loss: 30282.4980\n",
      "Epoch 2163/2500\n",
      "2800/2800 [==============================] - 0s 10us/step - loss: 34630.8490 - val_loss: 36024.6250\n",
      "Epoch 2164/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 40159.6419 - val_loss: 34766.1992\n",
      "Epoch 2165/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 42547.5120 - val_loss: 30193.7500\n",
      "Epoch 2166/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 35510.0184 - val_loss: 33097.7617\n",
      "Epoch 2167/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 39423.0231 - val_loss: 35724.7656\n",
      "Epoch 2168/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 40568.9095 - val_loss: 32339.6582\n",
      "Epoch 2169/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36339.3756 - val_loss: 36762.0469\n",
      "Epoch 2170/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 43190.4546 - val_loss: 25851.8594\n",
      "Epoch 2171/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 32039.4733 - val_loss: 29228.4453\n",
      "Epoch 2172/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 35409.8315 - val_loss: 35624.3086\n",
      "Epoch 2173/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 41892.0262 - val_loss: 33971.0859\n",
      "Epoch 2174/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37542.9878 - val_loss: 36966.2266\n",
      "Epoch 2175/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 43747.4334 - val_loss: 23003.6055\n",
      "Epoch 2176/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 29146.9424 - val_loss: 25706.5234\n",
      "Epoch 2177/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 29786.2384 - val_loss: 29594.1816\n",
      "Epoch 2178/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34018.0669 - val_loss: 33062.5430\n",
      "Epoch 2179/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 39145.5519 - val_loss: 27720.8477\n",
      "Epoch 2180/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34231.8558 - val_loss: 30191.5859\n",
      "Epoch 2181/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38620.1621 - val_loss: 35045.1797\n",
      "Epoch 2182/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 40482.6431 - val_loss: 29579.8594\n",
      "Epoch 2183/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 36323.6382 - val_loss: 31058.5723\n",
      "Epoch 2184/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 37512.0182 - val_loss: 33346.0273\n",
      "Epoch 2185/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 41909.1720 - val_loss: 38419.1406\n",
      "Epoch 2186/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 43780.5399 - val_loss: 36572.4609\n",
      "Epoch 2187/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38329.5137 - val_loss: 43986.0898\n",
      "Epoch 2188/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 47606.5747 - val_loss: 34940.3945\n",
      "Epoch 2189/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 44836.9994 - val_loss: 28499.2500\n",
      "Epoch 2190/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33175.2829 - val_loss: 28992.1875\n",
      "Epoch 2191/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39837.7908 - val_loss: 28832.4688\n",
      "Epoch 2192/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32792.6470 - val_loss: 32967.7695\n",
      "Epoch 2193/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 36979.0206 - val_loss: 36587.2930\n",
      "Epoch 2194/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 41165.6600 - val_loss: 36550.0781\n",
      "Epoch 2195/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 44660.2637 - val_loss: 32801.9375\n",
      "Epoch 2196/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34816.9711 - val_loss: 44675.7539\n",
      "Epoch 2197/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 52021.7865 - val_loss: 38570.1250\n",
      "Epoch 2198/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42699.8501 - val_loss: 38706.2188\n",
      "Epoch 2199/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 47075.0517 - val_loss: 32813.7891\n",
      "Epoch 2200/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 33967.2484 - val_loss: 38503.7422\n",
      "Epoch 2201/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 41135.9586 - val_loss: 36443.7422\n",
      "Epoch 2202/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35649.4220 - val_loss: 40470.9414\n",
      "Epoch 2203/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 44083.5453 - val_loss: 39467.2773\n",
      "Epoch 2204/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42539.7371 - val_loss: 30163.9277\n",
      "Epoch 2205/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 32282.2037 - val_loss: 28889.4336\n",
      "Epoch 2206/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36042.3664 - val_loss: 28134.5703\n",
      "Epoch 2207/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 29583.0190 - val_loss: 30009.2871\n",
      "Epoch 2208/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 36771.2596 - val_loss: 35108.1211\n",
      "Epoch 2209/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40342.4282 - val_loss: 25436.3730\n",
      "Epoch 2210/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33746.4832 - val_loss: 28515.9941\n",
      "Epoch 2211/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35684.3830 - val_loss: 24233.3672\n",
      "Epoch 2212/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 30502.8735 - val_loss: 33096.8281\n",
      "Epoch 2213/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800/2800 [==============================] - 0s 8us/step - loss: 35921.2686 - val_loss: 37915.4180\n",
      "Epoch 2214/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 46929.7347 - val_loss: 25806.3008\n",
      "Epoch 2215/2500\n",
      "2800/2800 [==============================] - ETA: 0s - loss: 27916.169 - 0s 8us/step - loss: 26587.2328 - val_loss: 38109.6602\n",
      "Epoch 2216/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 48807.0870 - val_loss: 22215.4629\n",
      "Epoch 2217/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 26973.1848 - val_loss: 27098.3828\n",
      "Epoch 2218/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 27619.8263 - val_loss: 33633.4141\n",
      "Epoch 2219/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 36810.7596 - val_loss: 27292.7559\n",
      "Epoch 2220/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 32926.2953 - val_loss: 20232.9453\n",
      "Epoch 2221/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 26413.4998 - val_loss: 20368.9121\n",
      "Epoch 2222/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 24590.7242 - val_loss: 32255.6289\n",
      "Epoch 2223/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37363.5333 - val_loss: 29958.0781\n",
      "Epoch 2224/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32088.1799 - val_loss: 33175.2773\n",
      "Epoch 2225/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33609.5681 - val_loss: 44337.5234\n",
      "Epoch 2226/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 43136.6193 - val_loss: 44076.3633\n",
      "Epoch 2227/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 46741.3786 - val_loss: 39032.4062\n",
      "Epoch 2228/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40413.4940 - val_loss: 39154.3711\n",
      "Epoch 2229/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 40960.3227 - val_loss: 35812.2188\n",
      "Epoch 2230/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 39363.4731 - val_loss: 29392.0293\n",
      "Epoch 2231/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 37534.5751 - val_loss: 29389.1367\n",
      "Epoch 2232/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31293.9821 - val_loss: 33487.9531\n",
      "Epoch 2233/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 38696.9743 - val_loss: 24919.3711\n",
      "Epoch 2234/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32231.9011 - val_loss: 20090.5293\n",
      "Epoch 2235/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 28371.9001 - val_loss: 20015.4668\n",
      "Epoch 2236/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 23707.9939 - val_loss: 27292.7383\n",
      "Epoch 2237/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 30401.8623 - val_loss: 39014.6602\n",
      "Epoch 2238/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42175.7683 - val_loss: 36372.9180\n",
      "Epoch 2239/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 39767.9708 - val_loss: 35642.5469\n",
      "Epoch 2240/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 44078.9292 - val_loss: 25991.0684\n",
      "Epoch 2241/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 29429.0528 - val_loss: 24542.9688\n",
      "Epoch 2242/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31012.8296 - val_loss: 27295.4297\n",
      "Epoch 2243/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33223.6998 - val_loss: 25070.6582\n",
      "Epoch 2244/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30977.3975 - val_loss: 20771.2324\n",
      "Epoch 2245/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 24775.8137 - val_loss: 27953.0586\n",
      "Epoch 2246/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 31963.8529 - val_loss: 33763.2148\n",
      "Epoch 2247/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 36448.0080 - val_loss: 38705.3594\n",
      "Epoch 2248/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 43248.4272 - val_loss: 39411.1445\n",
      "Epoch 2249/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 44168.1345 - val_loss: 38387.4062\n",
      "Epoch 2250/2500\n",
      "2800/2800 [==============================] - 0s 10us/step - loss: 49025.3877 - val_loss: 31993.3457\n",
      "Epoch 2251/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33077.4375 - val_loss: 31969.7539\n",
      "Epoch 2252/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 34242.3053 - val_loss: 34380.7422\n",
      "Epoch 2253/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37353.8231 - val_loss: 42806.3828\n",
      "Epoch 2254/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 52403.9985 - val_loss: 29478.8516\n",
      "Epoch 2255/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40589.0394 - val_loss: 16601.1621\n",
      "Epoch 2256/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 23054.7697 - val_loss: 18777.4316\n",
      "Epoch 2257/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 25931.9276 - val_loss: 19917.1992\n",
      "Epoch 2258/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 25586.0185 - val_loss: 26889.1973\n",
      "Epoch 2259/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34475.9569 - val_loss: 27988.2891\n",
      "Epoch 2260/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30947.7286 - val_loss: 29058.4648\n",
      "Epoch 2261/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36466.2549 - val_loss: 27131.6191\n",
      "Epoch 2262/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 32207.6729 - val_loss: 28590.7461\n",
      "Epoch 2263/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 29934.9564 - val_loss: 40534.3711\n",
      "Epoch 2264/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39750.4029 - val_loss: 38312.8125\n",
      "Epoch 2265/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37367.2642 - val_loss: 33057.9180\n",
      "Epoch 2266/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 35019.0405 - val_loss: 36718.2461\n",
      "Epoch 2267/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 45548.6020 - val_loss: 23875.7773\n",
      "Epoch 2268/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 31245.2096 - val_loss: 25214.4609\n",
      "Epoch 2269/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 27487.7943 - val_loss: 25928.2305\n",
      "Epoch 2270/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30568.7881 - val_loss: 28403.6699\n",
      "Epoch 2271/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31219.1181 - val_loss: 26253.1680\n",
      "Epoch 2272/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 29469.2689 - val_loss: 28620.6602\n",
      "Epoch 2273/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34589.4322 - val_loss: 22554.5918\n",
      "Epoch 2274/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 23635.8107 - val_loss: 31982.3086\n",
      "Epoch 2275/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36246.1739 - val_loss: 32172.1133\n",
      "Epoch 2276/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 34341.6920 - val_loss: 41752.1406\n",
      "Epoch 2277/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37569.0924 - val_loss: 49382.0820\n",
      "Epoch 2278/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 45682.6717 - val_loss: 41199.1328\n",
      "Epoch 2279/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38831.0959 - val_loss: 40212.1484\n",
      "Epoch 2280/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 44851.8210 - val_loss: 32740.5820\n",
      "Epoch 2281/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33912.8202 - val_loss: 25221.6484\n",
      "Epoch 2282/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32813.5936 - val_loss: 23683.6211\n",
      "Epoch 2283/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 25882.0355 - val_loss: 26035.2344\n",
      "Epoch 2284/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800/2800 [==============================] - 0s 6us/step - loss: 28311.5366 - val_loss: 29681.3984\n",
      "Epoch 2285/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 36041.4967 - val_loss: 20149.8340\n",
      "Epoch 2286/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 24915.5233 - val_loss: 21839.7324\n",
      "Epoch 2287/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 29100.1657 - val_loss: 21520.8281\n",
      "Epoch 2288/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 26960.3206 - val_loss: 23750.3809\n",
      "Epoch 2289/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 29416.6871 - val_loss: 27243.2324\n",
      "Epoch 2290/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30297.2774 - val_loss: 30926.9023\n",
      "Epoch 2291/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32591.0161 - val_loss: 33721.2695\n",
      "Epoch 2292/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33076.2548 - val_loss: 38549.5430\n",
      "Epoch 2293/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 35571.6608 - val_loss: 39194.9570\n",
      "Epoch 2294/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35242.3125 - val_loss: 43246.2891\n",
      "Epoch 2295/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 37360.8928 - val_loss: 45011.5312\n",
      "Epoch 2296/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 48023.9282 - val_loss: 32803.4766\n",
      "Epoch 2297/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 34743.4891 - val_loss: 29927.8359\n",
      "Epoch 2298/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32676.2027 - val_loss: 27584.0000\n",
      "Epoch 2299/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30682.4389 - val_loss: 25321.3164\n",
      "Epoch 2300/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 29190.2711 - val_loss: 26299.2695\n",
      "Epoch 2301/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33919.6577 - val_loss: 21884.4297\n",
      "Epoch 2302/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 25948.1375 - val_loss: 23435.6328\n",
      "Epoch 2303/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 24271.5449 - val_loss: 34403.6602\n",
      "Epoch 2304/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 39251.9702 - val_loss: 27801.8008\n",
      "Epoch 2305/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 32748.0905 - val_loss: 30435.1152\n",
      "Epoch 2306/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 34907.4492 - val_loss: 33740.7148\n",
      "Epoch 2307/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 33512.2597 - val_loss: 26106.0156\n",
      "Epoch 2308/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 32968.5842 - val_loss: 27253.7754\n",
      "Epoch 2309/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 32599.2920 - val_loss: 30450.2578\n",
      "Epoch 2310/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35067.7358 - val_loss: 30838.9805\n",
      "Epoch 2311/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35168.8652 - val_loss: 29300.6289\n",
      "Epoch 2312/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 30672.7973 - val_loss: 33794.6953\n",
      "Epoch 2313/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33248.1617 - val_loss: 42775.7812\n",
      "Epoch 2314/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42264.0595 - val_loss: 34940.2266\n",
      "Epoch 2315/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 36712.1172 - val_loss: 28742.0176\n",
      "Epoch 2316/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33929.5596 - val_loss: 25724.6055\n",
      "Epoch 2317/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 28825.8103 - val_loss: 27700.0742\n",
      "Epoch 2318/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31706.7679 - val_loss: 27893.8672\n",
      "Epoch 2319/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34194.3478 - val_loss: 25933.9961\n",
      "Epoch 2320/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33295.2300 - val_loss: 23808.9395\n",
      "Epoch 2321/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 29741.6170 - val_loss: 21683.4844\n",
      "Epoch 2322/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 25250.5072 - val_loss: 28997.3379\n",
      "Epoch 2323/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30394.9010 - val_loss: 33289.5273\n",
      "Epoch 2324/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35528.7846 - val_loss: 34240.4688\n",
      "Epoch 2325/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 45074.4394 - val_loss: 24098.2578\n",
      "Epoch 2326/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 30677.1240 - val_loss: 23719.2598\n",
      "Epoch 2327/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 28415.9191 - val_loss: 23449.1914\n",
      "Epoch 2328/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 26869.1676 - val_loss: 27134.2383\n",
      "Epoch 2329/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31532.8429 - val_loss: 29948.6172\n",
      "Epoch 2330/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34535.9463 - val_loss: 24906.0273\n",
      "Epoch 2331/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 30714.0932 - val_loss: 28497.1328\n",
      "Epoch 2332/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33603.4983 - val_loss: 27327.8379\n",
      "Epoch 2333/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 34756.4857 - val_loss: 22083.0352\n",
      "Epoch 2334/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 28754.4105 - val_loss: 25488.3281\n",
      "Epoch 2335/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31029.7902 - val_loss: 23675.3594\n",
      "Epoch 2336/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 25267.2139 - val_loss: 28107.5664\n",
      "Epoch 2337/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33895.2769 - val_loss: 32295.6367\n",
      "Epoch 2338/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 37272.1677 - val_loss: 31136.4844\n",
      "Epoch 2339/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33116.1403 - val_loss: 32609.7852\n",
      "Epoch 2340/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39191.9658 - val_loss: 27903.1680\n",
      "Epoch 2341/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30772.4439 - val_loss: 29402.2656\n",
      "Epoch 2342/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34564.1990 - val_loss: 30045.6504\n",
      "Epoch 2343/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30924.9156 - val_loss: 30094.5586\n",
      "Epoch 2344/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 35938.9817 - val_loss: 23098.8008\n",
      "Epoch 2345/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 27017.6715 - val_loss: 29699.8965\n",
      "Epoch 2346/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 33677.9736 - val_loss: 31248.3828\n",
      "Epoch 2347/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 33616.4392 - val_loss: 36976.2891\n",
      "Epoch 2348/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 37170.3461 - val_loss: 31937.7266\n",
      "Epoch 2349/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38393.5779 - val_loss: 27966.6348\n",
      "Epoch 2350/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 34278.4491 - val_loss: 27162.0430\n",
      "Epoch 2351/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 33962.1146 - val_loss: 21011.2891\n",
      "Epoch 2352/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 26624.0724 - val_loss: 27228.5234\n",
      "Epoch 2353/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 29561.0964 - val_loss: 35201.2227\n",
      "Epoch 2354/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 38961.7474 - val_loss: 34529.3672\n",
      "Epoch 2355/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800/2800 [==============================] - 0s 7us/step - loss: 34755.3495 - val_loss: 38010.9492\n",
      "Epoch 2356/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 36702.7748 - val_loss: 45152.7734\n",
      "Epoch 2357/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 44193.7763 - val_loss: 36900.5820\n",
      "Epoch 2358/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 39329.1087 - val_loss: 33754.0312\n",
      "Epoch 2359/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 39672.3161 - val_loss: 30515.7539\n",
      "Epoch 2360/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35224.5824 - val_loss: 33405.1133\n",
      "Epoch 2361/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36603.5878 - val_loss: 28936.1914\n",
      "Epoch 2362/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34672.6111 - val_loss: 26955.1992\n",
      "Epoch 2363/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 29556.0797 - val_loss: 26632.2227\n",
      "Epoch 2364/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 29096.2274 - val_loss: 19495.6680\n",
      "Epoch 2365/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 26589.7798 - val_loss: 16350.5781\n",
      "Epoch 2366/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 19623.6513 - val_loss: 22821.8301\n",
      "Epoch 2367/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 28547.8403 - val_loss: 22864.8164\n",
      "Epoch 2368/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 29910.4135 - val_loss: 25205.4941\n",
      "Epoch 2369/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 33239.0825 - val_loss: 21915.2090\n",
      "Epoch 2370/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 26120.9350 - val_loss: 27261.6445\n",
      "Epoch 2371/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34161.1198 - val_loss: 20342.5449\n",
      "Epoch 2372/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 25149.4494 - val_loss: 31464.3047\n",
      "Epoch 2373/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33927.3515 - val_loss: 30341.7422\n",
      "Epoch 2374/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35822.1508 - val_loss: 21509.2969\n",
      "Epoch 2375/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 30505.0983 - val_loss: 19674.4414\n",
      "Epoch 2376/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 23079.2786 - val_loss: 27718.9570\n",
      "Epoch 2377/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35554.1897 - val_loss: 27901.0508\n",
      "Epoch 2378/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 31928.4597 - val_loss: 26336.5938\n",
      "Epoch 2379/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 31223.6242 - val_loss: 30471.0762\n",
      "Epoch 2380/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 34066.5068 - val_loss: 30660.0430\n",
      "Epoch 2381/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 32800.9904 - val_loss: 30509.5488\n",
      "Epoch 2382/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37382.1324 - val_loss: 26146.7266\n",
      "Epoch 2383/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 29972.9420 - val_loss: 33357.7578\n",
      "Epoch 2384/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38171.8322 - val_loss: 34177.8672\n",
      "Epoch 2385/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37370.8512 - val_loss: 33026.8750\n",
      "Epoch 2386/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35245.1064 - val_loss: 38737.6562\n",
      "Epoch 2387/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 44611.9862 - val_loss: 28403.6504\n",
      "Epoch 2388/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33962.9978 - val_loss: 32796.6406\n",
      "Epoch 2389/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 38186.6527 - val_loss: 30618.0059\n",
      "Epoch 2390/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31633.1613 - val_loss: 34215.9883\n",
      "Epoch 2391/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 39312.3237 - val_loss: 24579.3379\n",
      "Epoch 2392/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 27408.7671 - val_loss: 38014.1875\n",
      "Epoch 2393/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 44580.2500 - val_loss: 34847.5000\n",
      "Epoch 2394/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 39638.2610 - val_loss: 33380.4141\n",
      "Epoch 2395/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41025.5555 - val_loss: 17817.3477\n",
      "Epoch 2396/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 21211.6188 - val_loss: 26241.6562\n",
      "Epoch 2397/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 32088.2684 - val_loss: 16012.5215\n",
      "Epoch 2398/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 21966.6606 - val_loss: 24632.5371\n",
      "Epoch 2399/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 30118.3765 - val_loss: 23988.2168\n",
      "Epoch 2400/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 27918.9777 - val_loss: 28799.4883\n",
      "Epoch 2401/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34923.2345 - val_loss: 21779.6211\n",
      "Epoch 2402/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 26081.5988 - val_loss: 26869.8320\n",
      "Epoch 2403/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 28125.2745 - val_loss: 34363.2695\n",
      "Epoch 2404/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38995.9197 - val_loss: 29568.2559\n",
      "Epoch 2405/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 30505.9192 - val_loss: 29336.0859\n",
      "Epoch 2406/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33561.4869 - val_loss: 23044.9492\n",
      "Epoch 2407/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 26561.2888 - val_loss: 26887.7422\n",
      "Epoch 2408/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 33861.5169 - val_loss: 18535.0078\n",
      "Epoch 2409/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 25714.5692 - val_loss: 19975.9746\n",
      "Epoch 2410/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 26738.7628 - val_loss: 20842.2441\n",
      "Epoch 2411/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 24475.9638 - val_loss: 28279.5547\n",
      "Epoch 2412/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 34571.8328 - val_loss: 29622.9219\n",
      "Epoch 2413/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 35167.6338 - val_loss: 28696.3906\n",
      "Epoch 2414/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 27959.1519 - val_loss: 33512.8672\n",
      "Epoch 2415/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 37115.1745 - val_loss: 21253.4961\n",
      "Epoch 2416/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 23718.3400 - val_loss: 23519.8281\n",
      "Epoch 2417/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 27632.9774 - val_loss: 32252.5840\n",
      "Epoch 2418/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 34427.4450 - val_loss: 34009.1797\n",
      "Epoch 2419/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32031.1908 - val_loss: 35032.8828\n",
      "Epoch 2420/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 39538.1155 - val_loss: 30398.1836\n",
      "Epoch 2421/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 36632.4033 - val_loss: 28175.0508\n",
      "Epoch 2422/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 30873.6195 - val_loss: 26525.0664\n",
      "Epoch 2423/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36027.8056 - val_loss: 17071.3516\n",
      "Epoch 2424/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 23428.6581 - val_loss: 20601.8945\n",
      "Epoch 2425/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 25380.0580 - val_loss: 18918.9414\n",
      "Epoch 2426/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800/2800 [==============================] - 0s 6us/step - loss: 24314.0621 - val_loss: 23172.3301\n",
      "Epoch 2427/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 26681.5750 - val_loss: 19439.5938\n",
      "Epoch 2428/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 24510.4344 - val_loss: 24099.6914\n",
      "Epoch 2429/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 28999.4100 - val_loss: 33424.7969\n",
      "Epoch 2430/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 39153.4503 - val_loss: 29574.2168\n",
      "Epoch 2431/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32341.6083 - val_loss: 36576.3047\n",
      "Epoch 2432/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37817.4874 - val_loss: 29632.8477\n",
      "Epoch 2433/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 36984.6132 - val_loss: 35390.8516\n",
      "Epoch 2434/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 44799.7597 - val_loss: 24975.3613\n",
      "Epoch 2435/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30032.6184 - val_loss: 25893.0293\n",
      "Epoch 2436/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30610.0749 - val_loss: 26614.8379\n",
      "Epoch 2437/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 32507.9023 - val_loss: 31520.4609\n",
      "Epoch 2438/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33712.1134 - val_loss: 34835.8828\n",
      "Epoch 2439/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 44014.8953 - val_loss: 27302.9316\n",
      "Epoch 2440/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32126.1496 - val_loss: 26192.4648\n",
      "Epoch 2441/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 29672.9725 - val_loss: 24344.6309\n",
      "Epoch 2442/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 29564.7987 - val_loss: 34137.8984\n",
      "Epoch 2443/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39281.5590 - val_loss: 27258.1484\n",
      "Epoch 2444/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35668.3532 - val_loss: 25827.2656\n",
      "Epoch 2445/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31587.3718 - val_loss: 24941.6602\n",
      "Epoch 2446/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 27122.5134 - val_loss: 36237.0352\n",
      "Epoch 2447/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 45129.9816 - val_loss: 26756.8828\n",
      "Epoch 2448/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 30577.7498 - val_loss: 35584.9844\n",
      "Epoch 2449/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40464.2021 - val_loss: 33936.0195\n",
      "Epoch 2450/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 39100.7524 - val_loss: 34864.9453\n",
      "Epoch 2451/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 35793.7948 - val_loss: 43077.5859\n",
      "Epoch 2452/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 44761.6472 - val_loss: 28925.1250\n",
      "Epoch 2453/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 33056.5210 - val_loss: 36326.7734\n",
      "Epoch 2454/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 43882.3578 - val_loss: 27400.4082\n",
      "Epoch 2455/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33114.6579 - val_loss: 26749.4180\n",
      "Epoch 2456/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30689.1909 - val_loss: 27559.2070\n",
      "Epoch 2457/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 32060.7121 - val_loss: 32805.9492\n",
      "Epoch 2458/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 36469.3494 - val_loss: 32672.6875\n",
      "Epoch 2459/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37727.2440 - val_loss: 36847.9531\n",
      "Epoch 2460/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38574.6480 - val_loss: 39840.2500\n",
      "Epoch 2461/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40341.8922 - val_loss: 37147.6016\n",
      "Epoch 2462/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41414.4071 - val_loss: 33688.0469\n",
      "Epoch 2463/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41300.3154 - val_loss: 22436.9727\n",
      "Epoch 2464/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 27781.2175 - val_loss: 28950.0430\n",
      "Epoch 2465/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 33014.9088 - val_loss: 36027.1211\n",
      "Epoch 2466/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38288.1857 - val_loss: 35480.5312\n",
      "Epoch 2467/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38207.1576 - val_loss: 41875.7812\n",
      "Epoch 2468/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 44056.0011 - val_loss: 30407.6055\n",
      "Epoch 2469/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 38225.6783 - val_loss: 22215.4375\n",
      "Epoch 2470/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 24247.7348 - val_loss: 22635.7148\n",
      "Epoch 2471/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 27178.6943 - val_loss: 26094.8750\n",
      "Epoch 2472/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 27325.4875 - val_loss: 33311.2148\n",
      "Epoch 2473/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35367.8817 - val_loss: 30448.3848\n",
      "Epoch 2474/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 29499.9536 - val_loss: 38396.4844\n",
      "Epoch 2475/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 38563.9579 - val_loss: 34599.5156\n",
      "Epoch 2476/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 37545.4246 - val_loss: 36448.2422\n",
      "Epoch 2477/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 39242.9297 - val_loss: 29370.2812\n",
      "Epoch 2478/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 33247.6758 - val_loss: 36474.1367\n",
      "Epoch 2479/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37196.5823 - val_loss: 32301.5918\n",
      "Epoch 2480/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38985.7474 - val_loss: 28096.6504\n",
      "Epoch 2481/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31021.3460 - val_loss: 31878.8730\n",
      "Epoch 2482/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36212.6095 - val_loss: 32088.0078\n",
      "Epoch 2483/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41103.7602 - val_loss: 22458.0684\n",
      "Epoch 2484/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 25736.3316 - val_loss: 21180.8711\n",
      "Epoch 2485/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 23618.2757 - val_loss: 29246.9844\n",
      "Epoch 2486/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 29366.0636 - val_loss: 29422.5586\n",
      "Epoch 2487/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34461.8631 - val_loss: 30017.3438\n",
      "Epoch 2488/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33230.5228 - val_loss: 30677.6484\n",
      "Epoch 2489/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35627.2748 - val_loss: 28651.6680\n",
      "Epoch 2490/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 30192.6283 - val_loss: 33519.2812\n",
      "Epoch 2491/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32053.5253 - val_loss: 43936.2070\n",
      "Epoch 2492/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 44690.9030 - val_loss: 30155.7910\n",
      "Epoch 2493/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 37223.3445 - val_loss: 21548.2617\n",
      "Epoch 2494/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 29548.7191 - val_loss: 23530.6035\n",
      "Epoch 2495/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 28838.4047 - val_loss: 25835.0273\n",
      "Epoch 2496/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 29158.2006 - val_loss: 29251.2754\n",
      "Epoch 2497/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800/2800 [==============================] - 0s 6us/step - loss: 32135.2159 - val_loss: 21354.9688\n",
      "Epoch 2498/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 26652.5672 - val_loss: 22266.9414\n",
      "Epoch 2499/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 28188.3235 - val_loss: 26247.0156\n",
      "Epoch 2500/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 31550.9950 - val_loss: 29037.9414\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f9bcc480c40>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=2500,\n",
    "                batch_size=512,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_games_df = raw_df[raw_df.game_start > datetime.datetime(2020, 1, 1)]\n",
    "encoded_space = encoder.predict(cluster_games_df[data_columns].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_elements, _ = encoded_space.shape\n",
    "distance_matrix = np.ndarray(shape=(num_elements, num_elements), dtype=np.float32)\n",
    "single_row_item = np.ndarray(shape=encoded_space.shape, dtype=encoded_space.dtype)\n",
    "\n",
    "for i in range(num_elements):\n",
    "    single_row_item[:] = encoded_space[i, :] # broadcast single row to whole matrix\n",
    "\n",
    "    diffs = encoded_space - single_row_item\n",
    "    distance_matrix[i, :] = np.einsum(\"ij,ij->i\", diffs, diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05    0.030131\n",
       "0.10    0.126705\n",
       "0.15    0.304774\n",
       "0.20    0.595565\n",
       "0.25    1.062973\n",
       "dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_series = pd.Series(distance_matrix.reshape(-1))\n",
    "percentiles = distance_series.quantile([\n",
    "    0.05, 0.10, 0.15, 0.20, 0.25\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creativity_score(row):\n",
    "    base = 0.75\n",
    "    too_far = len(percentiles)\n",
    "    return sum(\n",
    "        base ** exponent if exponent < too_far else 0\n",
    "        for exponent in (\n",
    "            np.searchsorted(percentiles, x) for x in row\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_games_df['creativity'] = np.apply_along_axis(creativity_score, 1, distance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
