{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import sys\n",
    "import bisect\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [15, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import umap.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_start</th>\n",
       "      <th>game_duration</th>\n",
       "      <th>self_won</th>\n",
       "      <th>self_name</th>\n",
       "      <th>self_race_is_protoss</th>\n",
       "      <th>self_race_is_zerg</th>\n",
       "      <th>self_race_is_terran</th>\n",
       "      <th>opponent_name</th>\n",
       "      <th>opponent_race_is_protoss</th>\n",
       "      <th>opponent_race_is_zerg</th>\n",
       "      <th>...</th>\n",
       "      <th>ZergMeleeWeaponsLevel2_start</th>\n",
       "      <th>ZergMeleeWeaponsLevel2_weight</th>\n",
       "      <th>ZergMissileWeaponsLevel1_start</th>\n",
       "      <th>ZergMissileWeaponsLevel1_weight</th>\n",
       "      <th>ZergMissileWeaponsLevel2_start</th>\n",
       "      <th>ZergMissileWeaponsLevel2_weight</th>\n",
       "      <th>Zergling_start</th>\n",
       "      <th>Zergling_weight</th>\n",
       "      <th>overlordspeed_start</th>\n",
       "      <th>overlordspeed_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>045eeb4f0df4c471d53c4f1db5eea0294279e0d69fad7af2c2624e914806a2ba_1</th>\n",
       "      <td>2020-02-02 14:59:40</td>\n",
       "      <td>318</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ragnarok</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DPGCure</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>2.234511</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6637fd076f528b86d4_0</th>\n",
       "      <td>2020-02-02 11:58:49</td>\n",
       "      <td>450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TSGSolar</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Ragnarok</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.038405</td>\n",
       "      <td>3.198894</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6637fd076f528b86d4_1</th>\n",
       "      <td>2020-02-02 11:58:49</td>\n",
       "      <td>450</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ragnarok</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TSGSolar</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.106736</td>\n",
       "      <td>9.517000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75172886d310ea051f49fa3751250afc4bab52ffae6b321413e9004424bacef9_0</th>\n",
       "      <td>2020-02-02 11:05:08</td>\n",
       "      <td>528</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ragnarok</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TSGSolar</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.973666</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.730920</td>\n",
       "      <td>3.489383</td>\n",
       "      <td>19.874607</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75172886d310ea051f49fa3751250afc4bab52ffae6b321413e9004424bacef9_1</th>\n",
       "      <td>2020-02-02 11:05:08</td>\n",
       "      <td>528</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TSGSolar</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Ragnarok</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.748239</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.038405</td>\n",
       "      <td>4.025389</td>\n",
       "      <td>20.024984</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            game_start  \\\n",
       "045eeb4f0df4c471d53c4f1db5eea0294279e0d69fad7af... 2020-02-02 14:59:40   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6... 2020-02-02 11:58:49   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6... 2020-02-02 11:58:49   \n",
       "75172886d310ea051f49fa3751250afc4bab52ffae6b321... 2020-02-02 11:05:08   \n",
       "75172886d310ea051f49fa3751250afc4bab52ffae6b321... 2020-02-02 11:05:08   \n",
       "\n",
       "                                                    game_duration  self_won  \\\n",
       "045eeb4f0df4c471d53c4f1db5eea0294279e0d69fad7af...            318       1.0   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...            450       0.0   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...            450       1.0   \n",
       "75172886d310ea051f49fa3751250afc4bab52ffae6b321...            528       1.0   \n",
       "75172886d310ea051f49fa3751250afc4bab52ffae6b321...            528       0.0   \n",
       "\n",
       "                                                   self_name  \\\n",
       "045eeb4f0df4c471d53c4f1db5eea0294279e0d69fad7af...  Ragnarok   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...  TSGSolar   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...  Ragnarok   \n",
       "75172886d310ea051f49fa3751250afc4bab52ffae6b321...  Ragnarok   \n",
       "75172886d310ea051f49fa3751250afc4bab52ffae6b321...  TSGSolar   \n",
       "\n",
       "                                                    self_race_is_protoss  \\\n",
       "045eeb4f0df4c471d53c4f1db5eea0294279e0d69fad7af...                   0.0   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                   0.0   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                   0.0   \n",
       "75172886d310ea051f49fa3751250afc4bab52ffae6b321...                   0.0   \n",
       "75172886d310ea051f49fa3751250afc4bab52ffae6b321...                   0.0   \n",
       "\n",
       "                                                    self_race_is_zerg  \\\n",
       "045eeb4f0df4c471d53c4f1db5eea0294279e0d69fad7af...                1.0   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                1.0   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                1.0   \n",
       "75172886d310ea051f49fa3751250afc4bab52ffae6b321...                1.0   \n",
       "75172886d310ea051f49fa3751250afc4bab52ffae6b321...                1.0   \n",
       "\n",
       "                                                    self_race_is_terran  \\\n",
       "045eeb4f0df4c471d53c4f1db5eea0294279e0d69fad7af...                  0.0   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                  0.0   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                  0.0   \n",
       "75172886d310ea051f49fa3751250afc4bab52ffae6b321...                  0.0   \n",
       "75172886d310ea051f49fa3751250afc4bab52ffae6b321...                  0.0   \n",
       "\n",
       "                                                   opponent_name  \\\n",
       "045eeb4f0df4c471d53c4f1db5eea0294279e0d69fad7af...       DPGCure   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...      Ragnarok   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...      TSGSolar   \n",
       "75172886d310ea051f49fa3751250afc4bab52ffae6b321...      TSGSolar   \n",
       "75172886d310ea051f49fa3751250afc4bab52ffae6b321...      Ragnarok   \n",
       "\n",
       "                                                    opponent_race_is_protoss  \\\n",
       "045eeb4f0df4c471d53c4f1db5eea0294279e0d69fad7af...                       0.0   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                       0.0   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                       0.0   \n",
       "75172886d310ea051f49fa3751250afc4bab52ffae6b321...                       0.0   \n",
       "75172886d310ea051f49fa3751250afc4bab52ffae6b321...                       0.0   \n",
       "\n",
       "                                                    opponent_race_is_zerg  \\\n",
       "045eeb4f0df4c471d53c4f1db5eea0294279e0d69fad7af...                    0.0   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                    1.0   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                    1.0   \n",
       "75172886d310ea051f49fa3751250afc4bab52ffae6b321...                    1.0   \n",
       "75172886d310ea051f49fa3751250afc4bab52ffae6b321...                    1.0   \n",
       "\n",
       "                                                    ...  \\\n",
       "045eeb4f0df4c471d53c4f1db5eea0294279e0d69fad7af...  ...   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...  ...   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...  ...   \n",
       "75172886d310ea051f49fa3751250afc4bab52ffae6b321...  ...   \n",
       "75172886d310ea051f49fa3751250afc4bab52ffae6b321...  ...   \n",
       "\n",
       "                                                    ZergMeleeWeaponsLevel2_start  \\\n",
       "045eeb4f0df4c471d53c4f1db5eea0294279e0d69fad7af...                        1000.0   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                        1000.0   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                        1000.0   \n",
       "75172886d310ea051f49fa3751250afc4bab52ffae6b321...                        1000.0   \n",
       "75172886d310ea051f49fa3751250afc4bab52ffae6b321...                        1000.0   \n",
       "\n",
       "                                                    ZergMeleeWeaponsLevel2_weight  \\\n",
       "045eeb4f0df4c471d53c4f1db5eea0294279e0d69fad7af...                            0.0   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                            0.0   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                            0.0   \n",
       "75172886d310ea051f49fa3751250afc4bab52ffae6b321...                            0.0   \n",
       "75172886d310ea051f49fa3751250afc4bab52ffae6b321...                            0.0   \n",
       "\n",
       "                                                    ZergMissileWeaponsLevel1_start  \\\n",
       "045eeb4f0df4c471d53c4f1db5eea0294279e0d69fad7af...                     1000.000000   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                     1000.000000   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                     1000.000000   \n",
       "75172886d310ea051f49fa3751250afc4bab52ffae6b321...                       18.973666   \n",
       "75172886d310ea051f49fa3751250afc4bab52ffae6b321...                       17.748239   \n",
       "\n",
       "                                                    ZergMissileWeaponsLevel1_weight  \\\n",
       "045eeb4f0df4c471d53c4f1db5eea0294279e0d69fad7af...                              0.0   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                              0.0   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                              0.0   \n",
       "75172886d310ea051f49fa3751250afc4bab52ffae6b321...                              1.0   \n",
       "75172886d310ea051f49fa3751250afc4bab52ffae6b321...                              1.0   \n",
       "\n",
       "                                                    ZergMissileWeaponsLevel2_start  \\\n",
       "045eeb4f0df4c471d53c4f1db5eea0294279e0d69fad7af...                          1000.0   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                          1000.0   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                          1000.0   \n",
       "75172886d310ea051f49fa3751250afc4bab52ffae6b321...                          1000.0   \n",
       "75172886d310ea051f49fa3751250afc4bab52ffae6b321...                          1000.0   \n",
       "\n",
       "                                                    ZergMissileWeaponsLevel2_weight  \\\n",
       "045eeb4f0df4c471d53c4f1db5eea0294279e0d69fad7af...                              0.0   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                              0.0   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                              0.0   \n",
       "75172886d310ea051f49fa3751250afc4bab52ffae6b321...                              0.0   \n",
       "75172886d310ea051f49fa3751250afc4bab52ffae6b321...                              0.0   \n",
       "\n",
       "                                                    Zergling_start  \\\n",
       "045eeb4f0df4c471d53c4f1db5eea0294279e0d69fad7af...       13.000000   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...       13.038405   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...       14.106736   \n",
       "75172886d310ea051f49fa3751250afc4bab52ffae6b321...       14.730920   \n",
       "75172886d310ea051f49fa3751250afc4bab52ffae6b321...       13.038405   \n",
       "\n",
       "                                                    Zergling_weight  \\\n",
       "045eeb4f0df4c471d53c4f1db5eea0294279e0d69fad7af...         2.234511   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...         3.198894   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...         9.517000   \n",
       "75172886d310ea051f49fa3751250afc4bab52ffae6b321...         3.489383   \n",
       "75172886d310ea051f49fa3751250afc4bab52ffae6b321...         4.025389   \n",
       "\n",
       "                                                    overlordspeed_start  \\\n",
       "045eeb4f0df4c471d53c4f1db5eea0294279e0d69fad7af...          1000.000000   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...          1000.000000   \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...          1000.000000   \n",
       "75172886d310ea051f49fa3751250afc4bab52ffae6b321...            19.874607   \n",
       "75172886d310ea051f49fa3751250afc4bab52ffae6b321...            20.024984   \n",
       "\n",
       "                                                    overlordspeed_weight  \n",
       "045eeb4f0df4c471d53c4f1db5eea0294279e0d69fad7af...                   0.0  \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                   0.0  \n",
       "ec5459a85c6c9a22024fee37d2f1f23c4f15e0720dc14e6...                   0.0  \n",
       "75172886d310ea051f49fa3751250afc4bab52ffae6b321...                   1.0  \n",
       "75172886d310ea051f49fa3751250afc4bab52ffae6b321...                   1.0  \n",
       "\n",
       "[5 rows x 85 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df = pd.read_hdf(\"../data/processed/summaries_zerg.hdf\", \"summaries\")\n",
    "raw_df = raw_df[raw_df.game_duration > 280]\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_columns = \"\"\"\n",
    "self_won\n",
    "game_start\n",
    "game_duration\n",
    "self_name self_race_is_protoss self_race_is_zerg self_race_is_terran\n",
    "opponent_name\n",
    "\"\"\".split()\n",
    "weight_columns = [col for col in raw_df.columns if col.endswith(\"_weight\")]\n",
    "\n",
    "data_columns = [col for col in raw_df.columns if col not in metadata_columns and col not in weight_columns]\n",
    "\n",
    "df = raw_df[data_columns]\n",
    "\n",
    "encoding_dim = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.sort_values('DarkTemplar_start').tail(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = Input(shape=(len(df.columns),))\n",
    "\n",
    "encoded = Dense(64, activation='relu')(input_data)\n",
    "encoded = Dense(24, activation='relu')(input_data)\n",
    "#encoded = Dense(24, activation='relu')(input_data)\n",
    "\n",
    "encoded = Dense(encoding_dim, activation='relu',\n",
    "                    activity_regularizer=regularizers.l1(10e-3))(encoded)\n",
    "\n",
    "\n",
    "#decoded = Dense(24, activation='relu')(encoded)\n",
    "decoded = Dense(24, activation='relu')(encoded)\n",
    "decoded = Dense(64, activation='relu')(decoded)\n",
    "decoded = Dense(len(df.columns), activation='linear')(decoded)\n",
    "\n",
    "autoencoder = Model(input_data, decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(input_data, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 2800 samples. Testing on 312.\n"
     ]
    }
   ],
   "source": [
    "x_all = df.sample(frac=1.0).values\n",
    "num_samples = int(0.9 * x_all.shape[0])\n",
    "x_train, x_test = x_all[:num_samples, :], x_all[num_samples:, :]\n",
    "print(\"Training on {} samples. Testing on {}.\".format(\n",
    "    num_samples, x_all.shape[0] - num_samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2800 samples, validate on 312 samples\n",
      "Epoch 1/2500\n",
      "2800/2800 [==============================] - 0s 58us/step - loss: 602299.3361 - val_loss: 504602.5625\n",
      "Epoch 2/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 356371.4312 - val_loss: 136127.3594\n",
      "Epoch 3/2500\n",
      "2800/2800 [==============================] - 0s 10us/step - loss: 136386.8679 - val_loss: 98141.6562\n",
      "Epoch 4/2500\n",
      "2800/2800 [==============================] - 0s 11us/step - loss: 103193.8375 - val_loss: 81162.8438\n",
      "Epoch 5/2500\n",
      "2800/2800 [==============================] - 0s 10us/step - loss: 88357.1212 - val_loss: 74725.5859\n",
      "Epoch 6/2500\n",
      "2800/2800 [==============================] - 0s 10us/step - loss: 82508.0351 - val_loss: 72881.3047\n",
      "Epoch 7/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 80557.7396 - val_loss: 71066.0156\n",
      "Epoch 8/2500\n",
      "2800/2800 [==============================] - ETA: 0s - loss: 79574.125 - 0s 10us/step - loss: 78495.3185 - val_loss: 70079.0391\n",
      "Epoch 9/2500\n",
      "2800/2800 [==============================] - 0s 10us/step - loss: 76999.2270 - val_loss: 68288.3594\n",
      "Epoch 10/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 75337.5041 - val_loss: 68103.7266\n",
      "Epoch 11/2500\n",
      "2800/2800 [==============================] - 0s 11us/step - loss: 74666.5537 - val_loss: 66809.4922\n",
      "Epoch 12/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 73382.4106 - val_loss: 66070.9375\n",
      "Epoch 13/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 72805.2311 - val_loss: 65074.4219\n",
      "Epoch 14/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 72238.4800 - val_loss: 65634.2891\n",
      "Epoch 15/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 72802.0087 - val_loss: 64942.0352\n",
      "Epoch 16/2500\n",
      "2800/2800 [==============================] - 0s 12us/step - loss: 71298.5336 - val_loss: 64334.2344\n",
      "Epoch 17/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 70603.4117 - val_loss: 63248.1875\n",
      "Epoch 18/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 69922.6294 - val_loss: 62682.3516\n",
      "Epoch 19/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 69409.3418 - val_loss: 62424.1172\n",
      "Epoch 20/2500\n",
      "2800/2800 [==============================] - 0s 10us/step - loss: 68584.1457 - val_loss: 62017.7188\n",
      "Epoch 21/2500\n",
      "2800/2800 [==============================] - 0s 10us/step - loss: 68339.5977 - val_loss: 61058.3945\n",
      "Epoch 22/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 66830.1323 - val_loss: 59995.8203\n",
      "Epoch 23/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 66223.0154 - val_loss: 60004.8516\n",
      "Epoch 24/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 65902.2378 - val_loss: 58464.2305\n",
      "Epoch 25/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 64730.9928 - val_loss: 58258.1914\n",
      "Epoch 26/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 64514.3902 - val_loss: 58540.8359\n",
      "Epoch 27/2500\n",
      "2800/2800 [==============================] - 0s 12us/step - loss: 64674.6470 - val_loss: 57006.5820\n",
      "Epoch 28/2500\n",
      "2800/2800 [==============================] - 0s 13us/step - loss: 62562.3568 - val_loss: 55935.8398\n",
      "Epoch 29/2500\n",
      "2800/2800 [==============================] - 0s 11us/step - loss: 62275.0929 - val_loss: 56239.2891\n",
      "Epoch 30/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 61859.6243 - val_loss: 53309.1133\n",
      "Epoch 31/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 60737.8790 - val_loss: 55981.4727\n",
      "Epoch 32/2500\n",
      "2800/2800 [==============================] - 0s 10us/step - loss: 60838.6937 - val_loss: 53044.5039\n",
      "Epoch 33/2500\n",
      "2800/2800 [==============================] - 0s 12us/step - loss: 59937.6141 - val_loss: 50138.4375\n",
      "Epoch 34/2500\n",
      "2800/2800 [==============================] - 0s 12us/step - loss: 55532.7047 - val_loss: 51698.7695\n",
      "Epoch 35/2500\n",
      "2800/2800 [==============================] - 0s 14us/step - loss: 60704.0654 - val_loss: 51030.4023\n",
      "Epoch 36/2500\n",
      "2800/2800 [==============================] - 0s 11us/step - loss: 56834.8922 - val_loss: 50968.9141\n",
      "Epoch 37/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 56337.9074 - val_loss: 50260.6328\n",
      "Epoch 38/2500\n",
      "2800/2800 [==============================] - 0s 10us/step - loss: 58495.4235 - val_loss: 53876.8359\n",
      "Epoch 39/2500\n",
      "2800/2800 [==============================] - 0s 12us/step - loss: 55034.2545 - val_loss: 48728.2969\n",
      "Epoch 40/2500\n",
      "2800/2800 [==============================] - 0s 11us/step - loss: 55692.0370 - val_loss: 47765.0078\n",
      "Epoch 41/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 54421.4843 - val_loss: 51766.0391\n",
      "Epoch 42/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 57751.0673 - val_loss: 49658.5156\n",
      "Epoch 43/2500\n",
      "2800/2800 [==============================] - 0s 10us/step - loss: 54720.6879 - val_loss: 46974.2969\n",
      "Epoch 44/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 53063.7580 - val_loss: 49640.5820\n",
      "Epoch 45/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 56278.9069 - val_loss: 48839.4961\n",
      "Epoch 46/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 54286.0724 - val_loss: 49912.1406\n",
      "Epoch 47/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 53010.1555 - val_loss: 46945.2188\n",
      "Epoch 48/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 51942.7042 - val_loss: 52066.2188\n",
      "Epoch 49/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 56065.1554 - val_loss: 47971.9805\n",
      "Epoch 50/2500\n",
      "2800/2800 [==============================] - 0s 12us/step - loss: 52507.6201 - val_loss: 46321.7930\n",
      "Epoch 51/2500\n",
      "2800/2800 [==============================] - 0s 14us/step - loss: 51131.2996 - val_loss: 50380.8203\n",
      "Epoch 52/2500\n",
      "2800/2800 [==============================] - 0s 12us/step - loss: 54444.6654 - val_loss: 47848.6094\n",
      "Epoch 53/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 52547.1485 - val_loss: 47135.3242\n",
      "Epoch 54/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 50944.2581 - val_loss: 45206.8750\n",
      "Epoch 55/2500\n",
      "2800/2800 [==============================] - 0s 10us/step - loss: 53578.8571 - val_loss: 47966.7383\n",
      "Epoch 56/2500\n",
      "2800/2800 [==============================] - 0s 10us/step - loss: 51374.2044 - val_loss: 45895.3906\n",
      "Epoch 57/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 51779.9572 - val_loss: 48109.7148\n",
      "Epoch 58/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 50996.8262 - val_loss: 46957.4062\n",
      "Epoch 59/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 50735.9346 - val_loss: 44386.1094\n",
      "Epoch 60/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 49935.4714 - val_loss: 44846.5312\n",
      "Epoch 61/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 50923.9351 - val_loss: 45297.9102\n",
      "Epoch 62/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 50525.9690 - val_loss: 51507.9961\n",
      "Epoch 63/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 49653.7312 - val_loss: 46327.9375\n",
      "Epoch 64/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 48467.8645 - val_loss: 42012.6992\n",
      "Epoch 65/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 46694.3483 - val_loss: 43812.1719\n",
      "Epoch 66/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 50308.5458 - val_loss: 43744.1055\n",
      "Epoch 67/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 48605.6246 - val_loss: 43421.6953\n",
      "Epoch 68/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 47527.8525 - val_loss: 41945.7891\n",
      "Epoch 69/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 47151.5087 - val_loss: 44339.6484\n",
      "Epoch 70/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 45595.3810 - val_loss: 41153.9609\n",
      "Epoch 71/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 46874.5008 - val_loss: 41661.9453\n",
      "Epoch 72/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800/2800 [==============================] - 0s 8us/step - loss: 46207.2817 - val_loss: 39866.4023\n",
      "Epoch 73/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 44173.6558 - val_loss: 37748.4062\n",
      "Epoch 74/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 41957.6835 - val_loss: 39180.1719\n",
      "Epoch 75/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 41354.0406 - val_loss: 42183.5430\n",
      "Epoch 76/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 46994.1842 - val_loss: 50110.6445\n",
      "Epoch 77/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 48951.4042 - val_loss: 45792.6172\n",
      "Epoch 78/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 46801.3646 - val_loss: 43626.9609\n",
      "Epoch 79/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 43276.9596 - val_loss: 37484.4688\n",
      "Epoch 80/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 40362.4173 - val_loss: 35968.4570\n",
      "Epoch 81/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 39827.7884 - val_loss: 37247.9688\n",
      "Epoch 82/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42475.4937 - val_loss: 39952.4453\n",
      "Epoch 83/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 43974.5523 - val_loss: 41367.9180\n",
      "Epoch 84/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 46113.9854 - val_loss: 41741.5039\n",
      "Epoch 85/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 44609.0843 - val_loss: 36888.5156\n",
      "Epoch 86/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 43579.3747 - val_loss: 40355.6250\n",
      "Epoch 87/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 44644.4280 - val_loss: 39826.6562\n",
      "Epoch 88/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 44698.9435 - val_loss: 38219.3594\n",
      "Epoch 89/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42897.1318 - val_loss: 38243.0820\n",
      "Epoch 90/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 41671.5030 - val_loss: 37912.1641\n",
      "Epoch 91/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 39723.7678 - val_loss: 33703.4180\n",
      "Epoch 92/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 38500.3740 - val_loss: 40434.8203\n",
      "Epoch 93/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 43594.0656 - val_loss: 45672.2422\n",
      "Epoch 94/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 43967.0799 - val_loss: 42877.4453\n",
      "Epoch 95/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 43234.1049 - val_loss: 37942.5078\n",
      "Epoch 96/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 42013.7945 - val_loss: 38810.0391\n",
      "Epoch 97/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41165.2799 - val_loss: 41976.7461\n",
      "Epoch 98/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 43470.4407 - val_loss: 42070.0430\n",
      "Epoch 99/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 40378.0789 - val_loss: 34715.0898\n",
      "Epoch 100/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 36972.6144 - val_loss: 34260.6250\n",
      "Epoch 101/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39550.2101 - val_loss: 33569.0586\n",
      "Epoch 102/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 37362.1969 - val_loss: 37929.9492\n",
      "Epoch 103/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 42427.9195 - val_loss: 39116.2852\n",
      "Epoch 104/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 42277.3970 - val_loss: 35256.0820\n",
      "Epoch 105/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 39882.6824 - val_loss: 35756.4492\n",
      "Epoch 106/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 41405.6253 - val_loss: 33550.2344\n",
      "Epoch 107/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 38436.2068 - val_loss: 33711.1992\n",
      "Epoch 108/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 38507.8625 - val_loss: 33619.7734\n",
      "Epoch 109/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 35633.9277 - val_loss: 31800.7402\n",
      "Epoch 110/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35064.6349 - val_loss: 35783.4609\n",
      "Epoch 111/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36891.1338 - val_loss: 36740.3164\n",
      "Epoch 112/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 41498.6785 - val_loss: 40948.7070\n",
      "Epoch 113/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 40654.8065 - val_loss: 36695.6992\n",
      "Epoch 114/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 38746.5930 - val_loss: 36415.9375\n",
      "Epoch 115/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39273.7447 - val_loss: 33581.2031\n",
      "Epoch 116/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 37540.2473 - val_loss: 33681.6719\n",
      "Epoch 117/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 36642.3732 - val_loss: 32934.1836\n",
      "Epoch 118/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36517.5917 - val_loss: 35616.5859\n",
      "Epoch 119/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 39073.0000 - val_loss: 36041.0742\n",
      "Epoch 120/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38119.2705 - val_loss: 32853.0039\n",
      "Epoch 121/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36364.8303 - val_loss: 35185.1055\n",
      "Epoch 122/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 37270.8219 - val_loss: 34507.0977\n",
      "Epoch 123/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 39018.8406 - val_loss: 34538.6641\n",
      "Epoch 124/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 38169.9566 - val_loss: 35671.8203\n",
      "Epoch 125/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 36895.6713 - val_loss: 34496.2461\n",
      "Epoch 126/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 35859.6207 - val_loss: 33752.6328\n",
      "Epoch 127/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35093.0637 - val_loss: 37609.0625\n",
      "Epoch 128/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 37037.6012 - val_loss: 36850.9805\n",
      "Epoch 129/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38546.9520 - val_loss: 35769.6680\n",
      "Epoch 130/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37902.2024 - val_loss: 35560.1719\n",
      "Epoch 131/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 34393.0638 - val_loss: 30315.0586\n",
      "Epoch 132/2500\n",
      "2800/2800 [==============================] - ETA: 0s - loss: 34406.425 - 0s 7us/step - loss: 32969.7884 - val_loss: 29936.9395\n",
      "Epoch 133/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 33158.6827 - val_loss: 31296.6816\n",
      "Epoch 134/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35631.8750 - val_loss: 32965.4961\n",
      "Epoch 135/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 38454.7362 - val_loss: 33725.3867\n",
      "Epoch 136/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36545.3171 - val_loss: 33723.6641\n",
      "Epoch 137/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36721.6473 - val_loss: 31883.2754\n",
      "Epoch 138/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 35569.1732 - val_loss: 31974.7539\n",
      "Epoch 139/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 36163.2260 - val_loss: 32564.5898\n",
      "Epoch 140/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36998.4661 - val_loss: 33432.6133\n",
      "Epoch 141/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 37010.2998 - val_loss: 32530.0117\n",
      "Epoch 142/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 36083.1980 - val_loss: 33710.4375\n",
      "Epoch 143/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 35828.5534 - val_loss: 34638.4414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 32426.9815 - val_loss: 27489.5312\n",
      "Epoch 145/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31607.9200 - val_loss: 29607.4668\n",
      "Epoch 146/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32080.1755 - val_loss: 32246.9160\n",
      "Epoch 147/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34853.0358 - val_loss: 33887.8164\n",
      "Epoch 148/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 37136.4760 - val_loss: 33199.8828\n",
      "Epoch 149/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34062.1241 - val_loss: 31614.0117\n",
      "Epoch 150/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34430.1691 - val_loss: 34210.3125\n",
      "Epoch 151/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 34363.1934 - val_loss: 32802.7734\n",
      "Epoch 152/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 34305.3112 - val_loss: 31943.1797\n",
      "Epoch 153/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 35414.9598 - val_loss: 33045.6875\n",
      "Epoch 154/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31954.0718 - val_loss: 26865.4902\n",
      "Epoch 155/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 30184.2864 - val_loss: 27997.1621\n",
      "Epoch 156/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 31366.0693 - val_loss: 28320.9375\n",
      "Epoch 157/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33096.3064 - val_loss: 31365.6035\n",
      "Epoch 158/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 34437.8235 - val_loss: 30634.4902\n",
      "Epoch 159/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 34465.3153 - val_loss: 31971.3711\n",
      "Epoch 160/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 35121.4717 - val_loss: 31773.7969\n",
      "Epoch 161/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34410.9091 - val_loss: 31237.4590\n",
      "Epoch 162/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 35090.1404 - val_loss: 32187.5332\n",
      "Epoch 163/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 35935.6403 - val_loss: 30565.7051\n",
      "Epoch 164/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34127.0873 - val_loss: 30505.9785\n",
      "Epoch 165/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33437.8662 - val_loss: 31938.1504\n",
      "Epoch 166/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33744.5340 - val_loss: 30270.2930\n",
      "Epoch 167/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32994.4761 - val_loss: 27676.4023\n",
      "Epoch 168/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 32010.6877 - val_loss: 28371.5176\n",
      "Epoch 169/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32965.7843 - val_loss: 28897.5234\n",
      "Epoch 170/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33405.6394 - val_loss: 30385.6309\n",
      "Epoch 171/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 32454.0135 - val_loss: 28810.6641\n",
      "Epoch 172/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 32484.6877 - val_loss: 29674.6797\n",
      "Epoch 173/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 32959.4000 - val_loss: 30798.1387\n",
      "Epoch 174/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 33486.7029 - val_loss: 31335.9570\n",
      "Epoch 175/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 34503.3480 - val_loss: 31358.8652\n",
      "Epoch 176/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 33683.2169 - val_loss: 30336.0254\n",
      "Epoch 177/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 34088.7198 - val_loss: 27110.3340\n",
      "Epoch 178/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 29155.7881 - val_loss: 27586.9570\n",
      "Epoch 179/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 30698.0870 - val_loss: 28450.3438\n",
      "Epoch 180/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 30459.5506 - val_loss: 27383.7637\n",
      "Epoch 181/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31471.4349 - val_loss: 29482.1133\n",
      "Epoch 182/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 33150.5402 - val_loss: 29119.5273\n",
      "Epoch 183/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32755.5227 - val_loss: 30636.9766\n",
      "Epoch 184/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32703.4861 - val_loss: 28587.4199\n",
      "Epoch 185/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31221.2600 - val_loss: 28875.1328\n",
      "Epoch 186/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32205.8216 - val_loss: 27457.2031\n",
      "Epoch 187/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 30501.9715 - val_loss: 27855.4609\n",
      "Epoch 188/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31127.6247 - val_loss: 29175.1953\n",
      "Epoch 189/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32387.6059 - val_loss: 28387.7793\n",
      "Epoch 190/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31458.7476 - val_loss: 27947.5859\n",
      "Epoch 191/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 31032.6751 - val_loss: 29238.0898\n",
      "Epoch 192/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32614.9950 - val_loss: 27954.0996\n",
      "Epoch 193/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 32184.4411 - val_loss: 30764.0469\n",
      "Epoch 194/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 33593.8635 - val_loss: 29160.2988\n",
      "Epoch 195/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 29888.7491 - val_loss: 28148.6895\n",
      "Epoch 196/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 30977.3003 - val_loss: 29491.9609\n",
      "Epoch 197/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 32743.3022 - val_loss: 28416.8789\n",
      "Epoch 198/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 32187.6825 - val_loss: 29505.6680\n",
      "Epoch 199/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31975.9006 - val_loss: 29753.4043\n",
      "Epoch 200/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31352.8681 - val_loss: 27451.2988\n",
      "Epoch 201/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30483.4045 - val_loss: 28047.5469\n",
      "Epoch 202/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31520.6166 - val_loss: 28498.3125\n",
      "Epoch 203/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30947.7567 - val_loss: 27284.8379\n",
      "Epoch 204/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 29560.9351 - val_loss: 29128.5156\n",
      "Epoch 205/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31996.5169 - val_loss: 28396.4629\n",
      "Epoch 206/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 30970.8602 - val_loss: 28481.7109\n",
      "Epoch 207/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 32372.7587 - val_loss: 30013.1328\n",
      "Epoch 208/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 31545.5093 - val_loss: 30313.3750\n",
      "Epoch 209/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 28787.3278 - val_loss: 23708.6934\n",
      "Epoch 210/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 25999.7121 - val_loss: 24145.0449\n",
      "Epoch 211/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 26854.1388 - val_loss: 24443.1055\n",
      "Epoch 212/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 27698.7545 - val_loss: 27527.3438\n",
      "Epoch 213/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31213.1418 - val_loss: 27744.9980\n",
      "Epoch 214/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31239.6994 - val_loss: 27650.1250\n",
      "Epoch 215/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 30168.2892 - val_loss: 27360.1562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 216/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30195.3752 - val_loss: 28588.3027\n",
      "Epoch 217/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 31163.7008 - val_loss: 26846.8301\n",
      "Epoch 218/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 29538.4624 - val_loss: 27850.3281\n",
      "Epoch 219/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30003.7187 - val_loss: 26593.9121\n",
      "Epoch 220/2500\n",
      "2800/2800 [==============================] - ETA: 0s - loss: 28821.962 - 0s 7us/step - loss: 28282.9384 - val_loss: 25198.9648\n",
      "Epoch 221/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 28781.0937 - val_loss: 27653.6055\n",
      "Epoch 222/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30286.4625 - val_loss: 26889.8281\n",
      "Epoch 223/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 29808.9669 - val_loss: 26733.6816\n",
      "Epoch 224/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 29117.6095 - val_loss: 25377.6895\n",
      "Epoch 225/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 28437.1182 - val_loss: 27617.9609\n",
      "Epoch 226/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 29667.9172 - val_loss: 27092.3555\n",
      "Epoch 227/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 29884.0427 - val_loss: 26209.8535\n",
      "Epoch 228/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 28870.0665 - val_loss: 25941.1484\n",
      "Epoch 229/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 29057.2697 - val_loss: 26966.6543\n",
      "Epoch 230/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 29656.7161 - val_loss: 25828.0566\n",
      "Epoch 231/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 29261.0912 - val_loss: 26370.6797\n",
      "Epoch 232/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 29040.5098 - val_loss: 26169.2539\n",
      "Epoch 233/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 29069.5807 - val_loss: 24481.2227\n",
      "Epoch 234/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 27243.9124 - val_loss: 24662.6387\n",
      "Epoch 235/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 27946.1934 - val_loss: 26896.3477\n",
      "Epoch 236/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 29203.9162 - val_loss: 26745.0234\n",
      "Epoch 237/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 30416.5715 - val_loss: 27072.2227\n",
      "Epoch 238/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 28501.6901 - val_loss: 25603.1367\n",
      "Epoch 239/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 25981.0264 - val_loss: 23732.3926\n",
      "Epoch 240/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 25559.5621 - val_loss: 25194.6250\n",
      "Epoch 241/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 28100.6715 - val_loss: 28659.6602\n",
      "Epoch 242/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 29580.6561 - val_loss: 29085.1621\n",
      "Epoch 243/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 29559.5996 - val_loss: 28434.7656\n",
      "Epoch 244/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 28222.5020 - val_loss: 27877.0078\n",
      "Epoch 245/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 29089.3295 - val_loss: 27682.6094\n",
      "Epoch 246/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 28543.2808 - val_loss: 27260.0273\n",
      "Epoch 247/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 27696.1360 - val_loss: 25645.7188\n",
      "Epoch 248/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 27790.4455 - val_loss: 23403.7402\n",
      "Epoch 249/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 24719.5628 - val_loss: 22740.6758\n",
      "Epoch 250/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 24243.7090 - val_loss: 25064.7344\n",
      "Epoch 251/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 26596.3773 - val_loss: 25924.5059\n",
      "Epoch 252/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 28809.1716 - val_loss: 27915.1055\n",
      "Epoch 253/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 28580.2179 - val_loss: 23356.8418\n",
      "Epoch 254/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 24156.5738 - val_loss: 21080.6719\n",
      "Epoch 255/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 23827.9979 - val_loss: 22858.6172\n",
      "Epoch 256/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 25972.4959 - val_loss: 24701.2383\n",
      "Epoch 257/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 27634.8646 - val_loss: 25075.2578\n",
      "Epoch 258/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 27919.2078 - val_loss: 24937.1680\n",
      "Epoch 259/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 27506.8890 - val_loss: 25065.1699\n",
      "Epoch 260/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 27577.9061 - val_loss: 24268.4551\n",
      "Epoch 261/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 26741.7777 - val_loss: 24002.1289\n",
      "Epoch 262/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 26233.8101 - val_loss: 23752.6816\n",
      "Epoch 263/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 26375.6602 - val_loss: 24362.8047\n",
      "Epoch 264/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 27208.3235 - val_loss: 21801.0801\n",
      "Epoch 265/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 23507.9213 - val_loss: 21031.5664\n",
      "Epoch 266/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 23403.7005 - val_loss: 22263.8047\n",
      "Epoch 267/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 25028.9430 - val_loss: 24186.0781\n",
      "Epoch 268/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 26992.2562 - val_loss: 24619.5801\n",
      "Epoch 269/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 26820.3064 - val_loss: 23915.2637\n",
      "Epoch 270/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 25683.3057 - val_loss: 22824.9277\n",
      "Epoch 271/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 25460.4922 - val_loss: 23741.6777\n",
      "Epoch 272/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 26370.1233 - val_loss: 23314.3105\n",
      "Epoch 273/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 25395.4899 - val_loss: 23360.6387\n",
      "Epoch 274/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 26030.0504 - val_loss: 23640.9043\n",
      "Epoch 275/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 26174.6429 - val_loss: 23845.0117\n",
      "Epoch 276/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 26687.9650 - val_loss: 22728.9512\n",
      "Epoch 277/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 24906.2819 - val_loss: 21223.4727\n",
      "Epoch 278/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 23179.7446 - val_loss: 21278.7344\n",
      "Epoch 279/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 23781.1466 - val_loss: 23653.4961\n",
      "Epoch 280/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 26844.4632 - val_loss: 23646.4297\n",
      "Epoch 281/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 25088.8536 - val_loss: 22313.6191\n",
      "Epoch 282/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 24080.4782 - val_loss: 21467.8105\n",
      "Epoch 283/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 22666.6618 - val_loss: 21139.3359\n",
      "Epoch 284/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 23586.6183 - val_loss: 21350.0879\n",
      "Epoch 285/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 23568.3114 - val_loss: 22911.7168\n",
      "Epoch 286/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 25885.5887 - val_loss: 23766.7988\n",
      "Epoch 287/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800/2800 [==============================] - 0s 7us/step - loss: 25819.5004 - val_loss: 23128.4746\n",
      "Epoch 288/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 25270.9233 - val_loss: 23074.9336\n",
      "Epoch 289/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 26102.6480 - val_loss: 22282.6465\n",
      "Epoch 290/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 24185.0418 - val_loss: 23123.1270\n",
      "Epoch 291/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 25836.9760 - val_loss: 22119.6191\n",
      "Epoch 292/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 24051.6175 - val_loss: 22432.2305\n",
      "Epoch 293/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 23797.6831 - val_loss: 21044.6172\n",
      "Epoch 294/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 23038.6625 - val_loss: 21687.5859\n",
      "Epoch 295/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 24138.5443 - val_loss: 22088.6035\n",
      "Epoch 296/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 24425.1402 - val_loss: 22486.8750\n",
      "Epoch 297/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 25411.8544 - val_loss: 21990.3359\n",
      "Epoch 298/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 23943.8349 - val_loss: 22704.7148\n",
      "Epoch 299/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 24207.0441 - val_loss: 22633.0000\n",
      "Epoch 300/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 26057.4789 - val_loss: 21945.4395\n",
      "Epoch 301/2500\n",
      "2800/2800 [==============================] - 0s 10us/step - loss: 23730.3739 - val_loss: 20616.2539\n",
      "Epoch 302/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 22959.2863 - val_loss: 22220.2812\n",
      "Epoch 303/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 25401.3881 - val_loss: 23908.3809\n",
      "Epoch 304/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 25569.6656 - val_loss: 21920.4863\n",
      "Epoch 305/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 23496.4916 - val_loss: 20405.9219\n",
      "Epoch 306/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 22323.4141 - val_loss: 22789.5000\n",
      "Epoch 307/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 24871.8084 - val_loss: 21039.0059\n",
      "Epoch 308/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 22569.0552 - val_loss: 20008.6543\n",
      "Epoch 309/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 22930.7594 - val_loss: 22375.1504\n",
      "Epoch 310/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 24208.9588 - val_loss: 22129.3770\n",
      "Epoch 311/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 23890.5767 - val_loss: 21138.9238\n",
      "Epoch 312/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 23291.4727 - val_loss: 22806.4043\n",
      "Epoch 313/2500\n",
      "2800/2800 [==============================] - 0s 11us/step - loss: 24755.9979 - val_loss: 22115.8223\n",
      "Epoch 314/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 23457.8616 - val_loss: 21586.6777\n",
      "Epoch 315/2500\n",
      "2800/2800 [==============================] - 0s 11us/step - loss: 23809.2208 - val_loss: 21221.4902\n",
      "Epoch 316/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 24093.1876 - val_loss: 22609.5820\n",
      "Epoch 317/2500\n",
      "2800/2800 [==============================] - 0s 10us/step - loss: 24534.9180 - val_loss: 21663.3105\n",
      "Epoch 318/2500\n",
      "2800/2800 [==============================] - 0s 10us/step - loss: 23534.4319 - val_loss: 21899.7754\n",
      "Epoch 319/2500\n",
      "2800/2800 [==============================] - 0s 10us/step - loss: 24284.7916 - val_loss: 21427.6797\n",
      "Epoch 320/2500\n",
      "2800/2800 [==============================] - 0s 10us/step - loss: 21735.2982 - val_loss: 19233.1758\n",
      "Epoch 321/2500\n",
      "2800/2800 [==============================] - 0s 10us/step - loss: 20723.7789 - val_loss: 19903.9551\n",
      "Epoch 322/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 22414.1265 - val_loss: 21008.3516\n",
      "Epoch 323/2500\n",
      "2800/2800 [==============================] - 0s 10us/step - loss: 23368.3986 - val_loss: 21342.9746\n",
      "Epoch 324/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 23705.3701 - val_loss: 21491.3750\n",
      "Epoch 325/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 23468.0138 - val_loss: 20474.6055\n",
      "Epoch 326/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 22980.2827 - val_loss: 21754.1445\n",
      "Epoch 327/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 24124.6673 - val_loss: 21345.9648\n",
      "Epoch 328/2500\n",
      "2800/2800 [==============================] - 0s 10us/step - loss: 23029.3601 - val_loss: 19876.6602\n",
      "Epoch 329/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 21585.8361 - val_loss: 20213.5430\n",
      "Epoch 330/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 22529.4259 - val_loss: 22264.8203\n",
      "Epoch 331/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 24708.1000 - val_loss: 21560.6348\n",
      "Epoch 332/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 23732.3444 - val_loss: 21463.0742\n",
      "Epoch 333/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 23266.9124 - val_loss: 21013.3867\n",
      "Epoch 334/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 23494.2908 - val_loss: 21434.7734\n",
      "Epoch 335/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 23032.5492 - val_loss: 21007.5312\n",
      "Epoch 336/2500\n",
      "2800/2800 [==============================] - 0s 10us/step - loss: 22961.9555 - val_loss: 21340.4219\n",
      "Epoch 337/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 24269.4269 - val_loss: 19920.4062\n",
      "Epoch 338/2500\n",
      "2800/2800 [==============================] - 0s 10us/step - loss: 20971.9915 - val_loss: 19791.5000\n",
      "Epoch 339/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 21317.5886 - val_loss: 18877.2598\n",
      "Epoch 340/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 20314.4944 - val_loss: 17928.8281\n",
      "Epoch 341/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 19290.7389 - val_loss: 17974.1387\n",
      "Epoch 342/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 19763.6843 - val_loss: 18704.9199\n",
      "Epoch 343/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 20321.8586 - val_loss: 19208.7051\n",
      "Epoch 344/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 20992.8879 - val_loss: 19691.0098\n",
      "Epoch 345/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 21694.3928 - val_loss: 20676.8574\n",
      "Epoch 346/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 22247.4506 - val_loss: 20639.1953\n",
      "Epoch 347/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 22644.1361 - val_loss: 21218.3926\n",
      "Epoch 348/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 23215.0471 - val_loss: 20910.0840\n",
      "Epoch 349/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 22676.1246 - val_loss: 20193.3418\n",
      "Epoch 350/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 22389.1181 - val_loss: 20573.4668\n",
      "Epoch 351/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 21929.0305 - val_loss: 19906.0215\n",
      "Epoch 352/2500\n",
      "2800/2800 [==============================] - 0s 10us/step - loss: 21206.0274 - val_loss: 19611.6309\n",
      "Epoch 353/2500\n",
      "2800/2800 [==============================] - 0s 10us/step - loss: 21809.5809 - val_loss: 20547.2617\n",
      "Epoch 354/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 22410.4576 - val_loss: 19774.6738\n",
      "Epoch 355/2500\n",
      "2800/2800 [==============================] - 0s 10us/step - loss: 21748.7721 - val_loss: 19753.9121\n",
      "Epoch 356/2500\n",
      "2800/2800 [==============================] - 0s 10us/step - loss: 22053.2028 - val_loss: 21364.6328\n",
      "Epoch 357/2500\n",
      "2800/2800 [==============================] - 0s 11us/step - loss: 23322.0729 - val_loss: 20834.5176\n",
      "Epoch 358/2500\n",
      "2800/2800 [==============================] - 0s 10us/step - loss: 22596.6239 - val_loss: 20636.9336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 22212.9169 - val_loss: 19789.6934\n",
      "Epoch 360/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 22211.1423 - val_loss: 21176.3672\n",
      "Epoch 361/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 22944.8688 - val_loss: 20493.7578\n",
      "Epoch 362/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 21866.6209 - val_loss: 19054.4355\n",
      "Epoch 363/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 20689.1798 - val_loss: 18257.7832\n",
      "Epoch 364/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 19714.6584 - val_loss: 17806.9824\n",
      "Epoch 365/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 20013.6401 - val_loss: 19495.4336\n",
      "Epoch 366/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 21626.7805 - val_loss: 20638.8945\n",
      "Epoch 367/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 21961.4227 - val_loss: 21697.4727\n",
      "Epoch 368/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 22065.1057 - val_loss: 21187.6562\n",
      "Epoch 369/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 22200.6322 - val_loss: 20305.2324\n",
      "Epoch 370/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 20844.3527 - val_loss: 19477.0605\n",
      "Epoch 371/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 21094.8495 - val_loss: 20464.6953\n",
      "Epoch 372/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 21108.2273 - val_loss: 18930.3652\n",
      "Epoch 373/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 20195.4214 - val_loss: 18807.1641\n",
      "Epoch 374/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 19902.4294 - val_loss: 19041.6914\n",
      "Epoch 375/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 21337.7081 - val_loss: 21601.8340\n",
      "Epoch 376/2500\n",
      "2800/2800 [==============================] - 0s 10us/step - loss: 22551.5784 - val_loss: 18828.3633\n",
      "Epoch 377/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 20409.5372 - val_loss: 19929.2012\n",
      "Epoch 378/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 21443.7016 - val_loss: 20693.1367\n",
      "Epoch 379/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 22074.6928 - val_loss: 20433.0312\n",
      "Epoch 380/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 21433.0950 - val_loss: 20679.7383\n",
      "Epoch 381/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 21658.4975 - val_loss: 21366.6914\n",
      "Epoch 382/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 22105.1953 - val_loss: 21081.5312\n",
      "Epoch 383/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 21899.2784 - val_loss: 20466.3281\n",
      "Epoch 384/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 20852.7220 - val_loss: 19130.3223\n",
      "Epoch 385/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 20313.4854 - val_loss: 19873.6699\n",
      "Epoch 386/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 22046.9895 - val_loss: 22029.1230\n",
      "Epoch 387/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 22268.0739 - val_loss: 19535.3184\n",
      "Epoch 388/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 20134.8529 - val_loss: 18195.5098\n",
      "Epoch 389/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 20161.2651 - val_loss: 20055.2480\n",
      "Epoch 390/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 21940.6361 - val_loss: 19879.8047\n",
      "Epoch 391/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 20970.2970 - val_loss: 20585.7266\n",
      "Epoch 392/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 21270.5923 - val_loss: 20526.6953\n",
      "Epoch 393/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 21970.8872 - val_loss: 20882.4648\n",
      "Epoch 394/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 22729.2082 - val_loss: 22172.3535\n",
      "Epoch 395/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 21838.0476 - val_loss: 20073.7852\n",
      "Epoch 396/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 21055.4497 - val_loss: 18953.3672\n",
      "Epoch 397/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 20208.8430 - val_loss: 19350.7539\n",
      "Epoch 398/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 20687.9057 - val_loss: 20023.9570\n",
      "Epoch 399/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 20098.5185 - val_loss: 16925.3125\n",
      "Epoch 400/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 18792.5668 - val_loss: 18034.4648\n",
      "Epoch 401/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 20740.6728 - val_loss: 19474.9609\n",
      "Epoch 402/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 21972.8300 - val_loss: 20329.4082\n",
      "Epoch 403/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 22629.5394 - val_loss: 19582.3535\n",
      "Epoch 404/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 21878.6946 - val_loss: 20476.5742\n",
      "Epoch 405/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 22413.5618 - val_loss: 19768.6875\n",
      "Epoch 406/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 22137.4539 - val_loss: 18963.9258\n",
      "Epoch 407/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 21413.5682 - val_loss: 18922.2578\n",
      "Epoch 408/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 21188.1197 - val_loss: 19497.0898\n",
      "Epoch 409/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 22075.2320 - val_loss: 19646.6309\n",
      "Epoch 410/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 21274.9593 - val_loss: 19066.0195\n",
      "Epoch 411/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 21598.2404 - val_loss: 18687.8945\n",
      "Epoch 412/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 20371.6031 - val_loss: 19737.8164\n",
      "Epoch 413/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 21821.9192 - val_loss: 19945.9805\n",
      "Epoch 414/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 21651.2435 - val_loss: 17674.3809\n",
      "Epoch 415/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 19332.3842 - val_loss: 18349.1289\n",
      "Epoch 416/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 20925.5906 - val_loss: 19753.0898\n",
      "Epoch 417/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 21715.4594 - val_loss: 19613.7832\n",
      "Epoch 418/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 20659.7271 - val_loss: 18105.4316\n",
      "Epoch 419/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 20235.0087 - val_loss: 19310.4414\n",
      "Epoch 420/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 21493.9587 - val_loss: 18608.9648\n",
      "Epoch 421/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 20444.8844 - val_loss: 18090.5781\n",
      "Epoch 422/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 20283.3956 - val_loss: 18699.7441\n",
      "Epoch 423/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 21404.5320 - val_loss: 20156.1309\n",
      "Epoch 424/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 22112.2375 - val_loss: 19065.9824\n",
      "Epoch 425/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 19984.3676 - val_loss: 17744.7129\n",
      "Epoch 426/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 19903.1359 - val_loss: 19329.9980\n",
      "Epoch 427/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 21664.9852 - val_loss: 19350.0898\n",
      "Epoch 428/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 21148.2532 - val_loss: 19705.5840\n",
      "Epoch 429/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 22058.2889 - val_loss: 19606.2734\n",
      "Epoch 430/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 20953.3041 - val_loss: 18384.5469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 431/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 20271.2393 - val_loss: 18854.7070\n",
      "Epoch 432/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 20675.4535 - val_loss: 19366.7812\n",
      "Epoch 433/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 21294.3792 - val_loss: 19235.5977\n",
      "Epoch 434/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 21504.7999 - val_loss: 17622.7598\n",
      "Epoch 435/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 19622.7512 - val_loss: 17453.1016\n",
      "Epoch 436/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 19199.0348 - val_loss: 18209.5547\n",
      "Epoch 437/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 20761.4603 - val_loss: 19013.4512\n",
      "Epoch 438/2500\n",
      "2800/2800 [==============================] - 0s 10us/step - loss: 20670.9160 - val_loss: 18238.5703\n",
      "Epoch 439/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 19547.0465 - val_loss: 17893.3516\n",
      "Epoch 440/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 19905.6360 - val_loss: 18682.1152\n",
      "Epoch 441/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 20774.7956 - val_loss: 18005.3555\n",
      "Epoch 442/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 20064.7614 - val_loss: 17905.7734\n",
      "Epoch 443/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 19764.5051 - val_loss: 18494.7695\n",
      "Epoch 444/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 20562.0241 - val_loss: 19309.3770\n",
      "Epoch 445/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 21030.9235 - val_loss: 18219.7656\n",
      "Epoch 446/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 20565.0651 - val_loss: 18430.5781\n",
      "Epoch 447/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 21134.2460 - val_loss: 18682.5742\n",
      "Epoch 448/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 20165.1435 - val_loss: 16681.4707\n",
      "Epoch 449/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 19147.4351 - val_loss: 18467.8711\n",
      "Epoch 450/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 20647.4190 - val_loss: 18413.5840\n",
      "Epoch 451/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 19714.6315 - val_loss: 17650.0957\n",
      "Epoch 452/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 19940.0474 - val_loss: 18402.4805\n",
      "Epoch 453/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 20986.7491 - val_loss: 19537.9414\n",
      "Epoch 454/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 21405.6388 - val_loss: 18917.3281\n",
      "Epoch 455/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 21052.4160 - val_loss: 18785.2188\n",
      "Epoch 456/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 20694.7101 - val_loss: 17817.5312\n",
      "Epoch 457/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 20433.2046 - val_loss: 19399.1836\n",
      "Epoch 458/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 21939.9509 - val_loss: 20087.4473\n",
      "Epoch 459/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 21067.0970 - val_loss: 16781.0469\n",
      "Epoch 460/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 17658.3259 - val_loss: 15987.5068\n",
      "Epoch 461/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 17599.8604 - val_loss: 16605.1699\n",
      "Epoch 462/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 19270.3508 - val_loss: 17848.9238\n",
      "Epoch 463/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 20725.9038 - val_loss: 17624.7969\n",
      "Epoch 464/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 19536.9896 - val_loss: 17637.8691\n",
      "Epoch 465/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 20025.3109 - val_loss: 18213.0137\n",
      "Epoch 466/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 20333.7072 - val_loss: 18775.8223\n",
      "Epoch 467/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 21119.3148 - val_loss: 18599.9648\n",
      "Epoch 468/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 19245.8646 - val_loss: 16928.1250\n",
      "Epoch 469/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 19010.3953 - val_loss: 18486.6836\n",
      "Epoch 470/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 20565.8555 - val_loss: 17782.1953\n",
      "Epoch 471/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 19475.7750 - val_loss: 17538.9980\n",
      "Epoch 472/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 19951.4421 - val_loss: 18406.4258\n",
      "Epoch 473/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 20833.6530 - val_loss: 18632.6895\n",
      "Epoch 474/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 20861.2873 - val_loss: 17885.9648\n",
      "Epoch 475/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 20062.8739 - val_loss: 17751.9902\n",
      "Epoch 476/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 19291.8066 - val_loss: 18076.9121\n",
      "Epoch 477/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 20408.7629 - val_loss: 18339.3848\n",
      "Epoch 478/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 20203.1675 - val_loss: 18229.2949\n",
      "Epoch 479/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 20626.2119 - val_loss: 17871.3105\n",
      "Epoch 480/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 19585.3543 - val_loss: 17277.1855\n",
      "Epoch 481/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 19197.7919 - val_loss: 17941.6523\n",
      "Epoch 482/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 20980.5968 - val_loss: 19086.2871\n",
      "Epoch 483/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 20329.6279 - val_loss: 17178.0859\n",
      "Epoch 484/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 19708.9582 - val_loss: 18000.6035\n",
      "Epoch 485/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 20532.4272 - val_loss: 19367.0352\n",
      "Epoch 486/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 21064.3546 - val_loss: 17859.4746\n",
      "Epoch 487/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 19329.9814 - val_loss: 17129.6328\n",
      "Epoch 488/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 19887.8769 - val_loss: 19752.4199\n",
      "Epoch 489/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 20863.6211 - val_loss: 16865.3633\n",
      "Epoch 490/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 18379.2521 - val_loss: 16327.8105\n",
      "Epoch 491/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 18623.4734 - val_loss: 17916.0234\n",
      "Epoch 492/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 20060.9443 - val_loss: 18438.3379\n",
      "Epoch 493/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 20392.0829 - val_loss: 18587.6875\n",
      "Epoch 494/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 20134.9691 - val_loss: 17089.7617\n",
      "Epoch 495/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 19134.2461 - val_loss: 17695.4375\n",
      "Epoch 496/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 19962.4663 - val_loss: 18271.2969\n",
      "Epoch 497/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 20146.8655 - val_loss: 18520.4863\n",
      "Epoch 498/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 20195.8349 - val_loss: 18413.9434\n",
      "Epoch 499/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 19980.0858 - val_loss: 17505.0293\n",
      "Epoch 500/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 19984.6328 - val_loss: 17977.8105\n",
      "Epoch 501/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 19555.8922 - val_loss: 17784.7227\n",
      "Epoch 502/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 19999.4436 - val_loss: 18355.2227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 503/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 20031.9130 - val_loss: 18322.7461\n",
      "Epoch 504/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 20145.4759 - val_loss: 17625.6543\n",
      "Epoch 505/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 20114.8216 - val_loss: 17977.7422\n",
      "Epoch 506/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 20415.5935 - val_loss: 19044.5156\n",
      "Epoch 507/2500\n",
      "2800/2800 [==============================] - 0s 6us/step - loss: 21437.0012 - val_loss: 18926.9453\n",
      "Epoch 508/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 19848.3967 - val_loss: 16188.2803\n",
      "Epoch 509/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 17865.8160 - val_loss: 16554.6699\n",
      "Epoch 510/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 18748.9204 - val_loss: 17795.8438\n",
      "Epoch 511/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 19854.6895 - val_loss: 17649.6445\n",
      "Epoch 512/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 20638.0998 - val_loss: 17801.7305\n",
      "Epoch 513/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 19894.3283 - val_loss: 16369.4297\n",
      "Epoch 514/2500\n",
      "2800/2800 [==============================] - 0s 7us/step - loss: 18628.1217 - val_loss: 17017.4922\n",
      "Epoch 515/2500\n",
      "2800/2800 [==============================] - 0s 8us/step - loss: 19467.8924 - val_loss: 18890.5957\n",
      "Epoch 516/2500\n",
      "2800/2800 [==============================] - 0s 9us/step - loss: 20505.9281 - val_loss: 18052.7168\n",
      "Epoch 517/2500\n",
      " 512/2800 [====>.........................] - ETA: 0s - loss: 20164.7305"
     ]
    }
   ],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=2500,\n",
    "                batch_size=512,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_games_df = raw_df[raw_df.game_start > datetime.datetime(2020, 1, 1)]\n",
    "encoded_space = encoder.predict(cluster_games_df[data_columns].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_elements, _ = encoded_space.shape\n",
    "distance_matrix = np.ndarray(shape=(num_elements, num_elements), dtype=np.float32)\n",
    "single_row_item = np.ndarray(shape=encoded_space.shape, dtype=encoded_space.dtype)\n",
    "# 1170 records\n",
    "for i in range(num_elements):\n",
    "    # 1170 x 8  = 1 x 8\n",
    "    single_row_item[:] = encoded_space[i, :] # broadcast single row to whole matrix\n",
    "    # [\n",
    "    #    [ record i],\n",
    "    #   [record i],\n",
    "    #   [record i],\n",
    "    #   . . .\n",
    "    #]\n",
    "    # [\n",
    "    #  [ record a ]\n",
    "    #  [ record b ]\n",
    "    #  [ record c ]\n",
    "    #  ...\n",
    "    #]\n",
    "    #\n",
    "    # \n",
    "    diffs = encoded_space - single_row_item\n",
    "    # [ \n",
    "    #   [record a ] - [record i]\n",
    "    #   [ delta b ]\n",
    "    #  [ delta c ]\n",
    "    # ...\n",
    "    #]\n",
    "    # (1170 x 8)\n",
    "    distance_matrix[i, :] = np.einsum(\"ij,ij->i\", diffs, diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_series = pd.Series(distance_matrix.reshape(-1))\n",
    "percentiles = distance_series.quantile([\n",
    "   0.05, 0.10, 0.15, 0.20, 0.25, 0.5, 0.75\n",
    "])\n",
    "distance_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creativity_score(row):\n",
    "    base = 0.75\n",
    "    too_far = len(percentiles)\n",
    "    return 1000 - sum(\n",
    "        base ** exponent if exponent < too_far else 0\n",
    "        for exponent in (\n",
    "            np.searchsorted(percentiles, x) for x in row\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_games_df['creativity'] = np.apply_along_axis(creativity_score, 1, distance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(cluster_games_df.creativity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cluster_games_df.sort_values('creativity').head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_games_df.sort_values('creativity').tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
